{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다 유의미하고 활용도 높은 유저의 몰입도(인게이지먼)를 산출하기 위해 다양한 시도를 하고 있습니다.    \n",
    "\n",
    "얼마전부터 Variational Auto-Encoder를 이용해 이 지표를 개선하려는 작업을 진행해왔고    \n",
    "작업 내용들을 공유해드도록 하겠습니다.\n",
    "\n",
    "다소 테크니컬한 내용이 포함되어 있어서 지루할 수 있음을 미리 말씀드립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 인게이지먼트(몰입도)\n",
    "- VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리에게 주어진 다양한 시점의 로그 데이터를 이용해 '유저의 몰입도 혹은 인게이지먼트'를 구한다는건, 말 그대로 정보의 축약/압축을 의미합니다.\n",
    "\n",
    "이런 일을 하기 위한 다양한 차원 축소 방법들이 존재합니다. feature selection을 할수도 있고, PCA나 Kernel PCA, NMF(Non-negative matrix factorization), LDA(Linear discriminant analysis), GDA(Generalized discriminant analysis) 혹은 곧 소개해드릴 Autoencoder류의 방법을 사용할 수도 있습니다.\n",
    "\n",
    "여러 방법들 중 저희가 갖고 있는 데이터의 특성에 가장 잘 맞는 방법을 선택하면 되겠습니다.\n",
    "\n",
    "저희가 갖고 있는 데이터의 특성은 우선 양이 많고, feature가 상당히 가변적입니다. 예를들어 map별 플레이 횟수라는 더미 변수들이 있다면 기간마다 유저들이 플레이하는 map의 종류가 달라질 수 있습니다. 이밖에도 이렇게 가변적인 feature가 상당히 많이 존재합니다. 또한 변수의 수 또한 상당히 많을 수 있습니다. 예를들어 아이템별 획득 수량을 더미 변수로 사용한다면 몇십에서 몇천개의 feature가 존재할 수 있습니다. 또한 입력 변수간 그리고 입력 변수와 출력변수의 관계가 선형적이리라고 보장할 수 없습니다. 마지막으로 단순히 차원 축소만 할게 아니라 몰입도가 낮은 유저를 기준으로 상대적인 몰입도를 정량화 하고 싶은 니즈 또한 존재합니다.\n",
    "- 대용량 데이터\n",
    "- 많은 feature 수\n",
    "- 가변적인 feature 수\n",
    "- 비선형성\n",
    "- 축소된 공간에서 거리의 정량화 필요성\n",
    "\n",
    "이런 요구사항을 만족하는 방법을 찾고 있었고, Autoencoder와 Variational Bayes가 혼합된 모형이라 할 수 있는 Variational Auto-Encoder가 그나마 가장 적절하다는 판단으로 작업을 진행하고 있습니다.\n",
    "\n",
    "그럼 왜 Variational Auto-Encoder가 여기에 사용되었는지 설명드리겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 차원축소\n",
    " - PCA, Kernel PCA, NMF, LDA, GDA, Autoencoder, ...\n",
    "\n",
    "> - 우리 데이터\n",
    " - 대용량\n",
    " - 많은 feature 수\n",
    " - 가변적 feature 수\n",
    " - 비선형성\n",
    " - 지표로서 거리의 정량화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Theoretical perspective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝을 공부해보신 분들은 옵티마이져로 아담 옵티마이져를 많이 사용하는데요. 이 아담 옵티마이져를 만든 Kingma와 그의 지도교수인 Max Welling이 2013년에 발표한 'Auto-Encoding Variational Bayes'라는 논문에 VAE가 처음 소개됩니다.\n",
    "\n",
    "이 논문에서 풀려는 문제를 간단히 말하자면 z가 원인이 되어 x가 결과가 되는 어떤 인과관계 p(z|x)를 기존 방법들보다 쉽게 구해보자는건데요. 이 문제에 대한 접근법으로 확률적 변분 추론과 학습(stochastic variational inference & learning) 방법을 사용합니다. 그리고 이 접근법의 한 예시가 VAE라고 할 수 있습니다.\n",
    "\n",
    "여기서 결과 x라는건 우리가 관찰하는 데이터, 로그 데이터, nxlog라고 할 수 있습니다.      \n",
    "그리고 원인 z라는건 유저마다의 어떤 특성, 이 특성이 몰입도 혹은 인게이지먼트를 나타낼 수 있다면 참 좋을것 같습니다.     \n",
    "그리고 p(z|x)는 데이터가 주어졌을 때 원인 z의 확률 분포를 의미하기 때문에, nxlog가 주어졌을 때 각 유저의 어떤 잠재적 특성을 찾는 것이라 할 수 있습니다.\n",
    "\n",
    "복잡한 p(z|x)를 구하는 방법은 MCMC와 같은 샘플링 방법이나 Variational Bayes와 추정 방법을 사용할 수 있습니다. 하지만 우리가 다루는 데이터 처럼 양이 많고 복잡한 상황에서는 이런 방법들을 사용할수가 없습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Variational Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "오토 인코더는 기본적으로 두개의 네트워크가 서로 마주보고 붙어 있는 구조 입니다.     \n",
    "각 네트워크는 내부적으로 feed-forward로 연결되어 있고, 입력 데이터의 종류에 따라서 다양한 구조로 변형할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// simple autoencoder picture here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터가 x가 d차원이고 가운데 레이어 z가 p 차원이라면,     \n",
    "d차원 데이터가 들어가서 어떤 좁은 차원 p로 축소되었다가     \n",
    "다시 d차원 출력 x'로 나오는 구조 입니다.\n",
    "\n",
    "이런 네트워크의 학습 목표는     \n",
    "입력 데이터 x가 들어가서 나오는 출력 x'가 최대한 입력과 같아지는 것 입니다.\n",
    "즉 목적함수가 $\\mid x - \\hat{x}\\mid$와 같은 형태라고 할 수 있습니다.\n",
    "\n",
    "이런 구조에서 만약 hidden layer가 인코더, 디코어에 각각 하나식만 있고      \n",
    "activation function을 사용하지 않으면(즉 입력을 그대로 bypass)      \n",
    "z 레이어의 출력값은 잘 알려진 PCA류의 방법과 같습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// simple autoencoder and U animation below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA에서는 기본적으로      \n",
    "입력데이터가 d차원($x \\in \\mathbb{R}^d$)의 어떤 점일때      \n",
    "$p \\times d$ 차원의 $U^\\intercal$라는 어떤 transformation을 해서 $p$차원의 어떤 점 $z$를 얻는 방식입니다.    \n",
    "$$z = U^\\intercal x$$\n",
    "\n",
    "$y$는 $x$의 축약된 혹은 변형된 표현이라 할 수 있고,   \n",
    "matrix $U$를 이용해 $z$에서 다시 $x$를 복원할수도 있습니다.\n",
    "$$\\hat{x} = Uz $$\n",
    "\n",
    "그리고 이 두 관계는 아래 관계를 의미합니다.\n",
    "$$\\hat{x} = UU^\\intercal x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder에서 이 관계를 생각해보면       \n",
    "만약 첫 히든 레이어와 z 레이어 사이의 weight matrix가 $U^\\intercal$이면\n",
    "$$z = U^\\intercal x$$\n",
    "이 되고\n",
    "\n",
    "z 레이어와 뒷단 히든 레이어 사이의 weight matrix가 $U$라면 \n",
    "$$\\hat{x} = Uz $$\n",
    "인 관계가 성립합니다.\n",
    "또한 이때의 objective function은 $\\mid x - U^\\intercal U x \\mid$이고 이를 최소화 하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA와 방금 말씀드린 초간단 autoencoder의 차이점이라면, PCA에서는 $U^\\intercal U$가 identity matrix $I$라는 제약조건이 추가된것 뿐입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 autoencoder에 히든 레이어를 더 추가하고, activation function으로 RELU같은 non-linear한 함수를 사용하면 흔히 말하는 deep autoencoder가 되는 거고, 좀더 복잡한 데이터의 비선형적 관계를 축약하는 역할을 하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Remote image](https://upload.wikimedia.org/wikipedia/commons/2/28/Autoencoder_structure.png \"Tooltip for remote image\")\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder에서는 이 앞단을 encoder라 하고, 뒷단을 decoder 부르고, z 레이어는 일종의 '잠재변수 공간' 혹은 'latent space'라 할 수 있다.\n",
    "\n",
    "물론 autoencoder를 차원축소가 아니라 다른 목적으로도 사용할 수 있는데, 여기서 설명드리지는 않겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autoencoder의 다양한 목적의 다양한 변형이 있는데, 지금 소개드릴건 Variational AutoEncoder 혹은 약어로 VAE입니다.   \n",
    "\n",
    "VAE는 autoencoder + deep neural network + variational Inference가 혼합된 방법입니다.   \n",
    "autoencoder는 방금전에 말씀드렸고    \n",
    "변분추론 혹은 variational inference에 대해 간단히 소개해드리겠습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정보이론으로 유명한 클로드 새넌에 따르면    \n",
    "\n",
    "정보을 아래와 같이 정량화할 수 있습니다.\n",
    "$$I(m) = -\\log\\big( p(m) \\big)$$\n",
    "$m$은 어떤 메시지를 의미하고 $p(m)$은 이 메시지가 일어날 확률을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// http://fooplot.com/#W3sidHlwZSI6MCwiZXEiOiItbG9nKHgpIiwiY29sb3IiOiIjMDAwMDAwIn0seyJ0eXBlIjoxMDAwLCJ3aW5kb3ciOlsiLTEuODYyODYwOCIsIjIuMzk2OTc5MTk5OTk5OTk5NiIsIi0wLjUzNTkyMDYzOTk5OTk5OTgiLCIyLjA4NTUxOTM2Il19XQ--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림과 같이 일어날 확률이 높을수록 정보량이 작아집니다.\n",
    "\n",
    "예를들어 '내일 삼성전자 주식이 몇만원 오를것이다'라는 메시지와 '내일 누구 누구는 회사에 출근할거야'라는 정보가 있다면, 주식 오를거라는 정보의 확률이 더 낮고 정보의 양이 더 크다고 할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균 정보량을 엔트로피라고 한다.\n",
    "$$H(M) = \\mathbb{E}[I(M)] =  - \\sum_{i=1}^n p(m_i) \\log p(m_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KL divergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분포 $p$와 $q$가 있을 때 이 둘의 평균 정보량 차이, 즉 엔트로피 차이는 아래와 같다.\n",
    "$$\\begin{align}\n",
    " -\\sum \\color{red}{q(x)} \\log q(x) + \\sum p(x) \\log p(x)\n",
    " \\end{align}$$\n",
    " \n",
    "위 식에서 기댓값의 기준 확률을 $p$로 통일하면 아래와 같이 $KL(p \\Vert q)$가 된다.\n",
    "$$\\begin{align}\n",
    "& -\\sum \\color{red}{p(x)} \\log q(x) + \\sum p(x) \\log p(x) \\\\\n",
    "& = \\sum_x p(x) \\log \\frac{p(x)}{q(x)} \\\\\n",
    "& = KL(p \\Vert q)\n",
    "\\end{align}$$\n",
    "\n",
    "KL divergence는 두 분포의 차이를 나타내는 지표이고 0보다 큰 특성을 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Variational inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로그 혹은 관측 데이터를 통해 알고 싶은건,    \n",
<<<<<<< HEAD:_chaos/20181004_engagement_tutorial(0).ipynb
    "데이터 $x$가 주어졌을 때 각 유저의 특성을 표현하는 변수 $z$의 확률 분포 $p(z \\mid x)$ 입니다.\n",
    "\n",
    "그런데 $p(z \\mid x)$를 알기 어렵기 때문에, $p$에 가깝고 다루기 쉬운 $q(z \\mid x)$를 구하는 방식으로 문제에 접근할 수 있습니다. \n",
    "\n",
    "최대한 $p$에 가까운 $q$를 찾기 위해 $p$와 $q$의 차이를 정의하고, 이 값을 최소화 하는 방향으로 최적화한다면 $q$를 구할 수 있을지도 모릅니다.\n",
    "\n",
    "$p ~ (=p(z \\mid x))$와 $q ~ (=p(z \\mid x))$의 차이를 앞서 다뤘던 KL divergence를 이용해 아래와 같이 표현할 수 있습니다.\n",
    "\n",
    "$$KL\\big(q \\Vert p \\big) = \\sum_z q(z \\mid x)\\log \\frac{q(z \\mid x)}{p(z \\mid x)}$$\n",
    "\n",
    "하지만 위 식에서 $p(z \\mid x)$를 계산하는게 어렵기 때문에, 아래와 같이 $p(z\\mid x)$대신 $p(z, x)$와 $q(z \\mid x)$와의 차이를 목적함수로 사용합니다.\n",
    "\n",
    "$$\\begin{align}\n",
    "J(q) &= KL\\big(q(z \\mid x) \\Vert p(z, x) \\big) \\\\\n",
    "&= \\sum_z q(z \\mid x)\\log \\frac{q(z \\mid x)}{p(z, x)} \\\\\n",
    "&= \\sum_z q(z \\mid x) \\frac{q(z \\mid x)}{p(z \\mid x)} - \\log p(x) \\\\\n",
    "&= KL(q \\Vert p) - \\log p(x) \\\\\n",
    "\\end{align}$$\n",
    "\n",
    "$\\log p(x)$는 normalizing constant로서 상수이므로 $J(q)$를 최소화하면,     \n",
    "$KL(q \\Vert p)$가 최대화되므로 우리가 원하는 것 처럼 $p$에 가까운 $q$를 찾을 수 있게 됩니다.\n",
    "\n",
    "$-J(q)$를 evidence lower bound(ELBO)라 부르고           \n",
    "이걸 최대화하는 형태로 $q$의 파라미터를 찾는게 일반적인 Variational inference의 방법들입니다."
=======
    "데이터 $x$가 주어졌을 때 각 유저의 특성을 표현하는 변수 $z$의 확률 분포 $p(z \\mid x)$ 입니다."
>>>>>>> aab9a594d67e137d92a3dfc7f4a3eace4b2a6548:_chaos/.ipynb_checkpoints/20181004_engagement_tutorial-checkpoint.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD:_chaos/20181004_engagement_tutorial(0).ipynb
    "###### reparameterization trick"
=======
    "그런데 $p(z \\mid x)$를 알기 어렵기 때문에, $p$에 가깝고 다루기 쉬운 $q(z \\mid x)$를 구하는 방식으로 문제에 접근할 수 있습니다. "
>>>>>>> aab9a594d67e137d92a3dfc7f4a3eace4b2a6548:_chaos/.ipynb_checkpoints/20181004_engagement_tutorial-checkpoint.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD:_chaos/20181004_engagement_tutorial(0).ipynb
=======
    "최대한 $p$에 가까운 $q$를 찾기 위해 $p$와 $q$의 차이를 정의하고, 이 값을 최소화 하는 방향으로 최적화한다면 $q$를 구할 수 있을지도 모릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p ~ (=p(z \\mid x))$와 $q ~ (=p(z \\mid x))$의 차이를 앞서 다뤘던 KL divergence를 이용해 아래와 같이 표현할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$KL\\big(q \\Vert p \\big) = \\sum_z q(z \\mid x)\\log \\frac{q(z \\mid x)}{p(z \\mid x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 위 식에서 $p(z \\mid x)$를 계산하는게 어렵기 때문에, 아래와 같이 $p(z\\mid x)$대신 $p(z, x)$와 $q(z \\mid x)$와의 차이를 목적함수로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "J(q) &= KL\\big(q(z \\mid x) \\Vert p(z, x) \\big) \\\\\n",
    "&= \\sum_z q(z \\mid x)\\log \\frac{q(z \\mid x)}{p(z, x)} \\\\\n",
    "&= \\sum_z q(z \\mid x) \\frac{q(z \\mid x)}{p(z \\mid x)} - \\log p(x) \\\\\n",
    "&= KL(q \\Vert p) - \\log p(x) \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\log p(x)$는 normalizing constant로서 상수이므로 $J(q)$를 최소화하면,     \n",
    "$KL(q \\Vert p)$가 최대화되므로 우리가 원하는 것 처럼 $p$에 가까운 $q$를 찾을 수 있게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-J(q)$를 evidence lower bound(ELBO)라 부르고           \n",
    "이걸 최대화하는 형태로 $q$의 파라미터를 찾는게 일반적인 Variational inference의 방법들입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### reparameterization trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
>>>>>>> aab9a594d67e137d92a3dfc7f4a3eace4b2a6548:_chaos/.ipynb_checkpoints/20181004_engagement_tutorial-checkpoint.ipynb
    "ELBO를 최대화하는 다양한 방법들이 있는데,      \n",
    "VAE에서는 reparameterization trick과 신경망을 이용해서 보다 쉽게 ELBO를 최대화 하는 파라미터를 찾는게 핵심 아이디어 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 여기서 말하는 reparameterization trick은       \n",
    "어떤 확률변수의 expectation을 empirical하게 구하고 싶은데, 이 확률변수로부터 샘플링이 어렵다면     \n",
    "샘플링이 쉬운 다른 확률 변수를 이용해서 empirical하게 expectation을 구하겠다는 아이디어입니다.\n",
    "\n",
    "예를들어 $\\mathbb{E}_{q_{\\phi}(z \\mid x)} \\big[ f(z) \\big]$를 구하고 싶은데,             \n",
    "$q_{\\phi}(z \\mid x)$에서 $z$를 샘플링할 수 없다면 expectation을 산술평균으로 대체하는게 불가능합니다.     \n",
    "\n",
    "그렇다면 샘플링이 쉽고 다루기 쉬운 $\\epsilon \\sim p(\\epsilon)$이란 확률 변수를 이용해서   \n",
    "$z$를 $g_\\phi (\\epsilon, x)$라 표현하고, 원래 구하려던 expectation을 아래와 같이 구하게 됩니다.\n",
    "\n",
    "$$\\mathbb{E}_{q_{\\phi}(z \\mid x)} \\big[ f(z) \\big] = \\mathbb{E}_{p(\\epsilon)} \\big[ f(g_\\phi(\\epsilon, x)) \\big] \\simeq \\frac{1}{L} \\sum_{l=1}^L f(g_\\phi(\\epsilon, x))$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 ELBO는 $q(z \\mid x)$와 $p(z, x)$의 minus KL divergence였습니다.\n",
    "\n",
    "$q(z \\mid x)$가 확률분포이므로 $J(q)$를 expectation으로 표현할 수 있습니다.(아래 3번째 식)\n",
    "혹은 잘 정리하면 아래 4번째 식 같이 표현할수도 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "-J(q) &= -KL\\big(q(z \\mid x) \\Vert p(z, x) \\big) \\\\\n",
    "&= -\\sum_z q(z \\mid x)\\log \\frac{q(z \\mid x)}{p(z, x)} \\\\\n",
    "&= \\mathbb{E}_{q(z \\mid x)} \\big[ - \\log q(z \\mid x) + \\log p(z, x) \\big] \\label{eq:A}\\\\\n",
    "&= -KL\\big( q(z \\mid x) \\Vert p(z) \\big) + \\mathbb{E}_{q(z \\mid x)} \\big[ \\log p(x \\mid z) \\big]\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 4번재 식을 reparameterization trick을 이용해 아래와 같습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\mathcal{\\tilde{L}}^B(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}^{(i)}) &= -  KL\\big (q_\\phi (\\mathbf{z}^{(i, l)} \\mid \\mathbf{x}^{(i)}) \\Vert p_\\theta(\\mathbf{z}^{(i, l)}) \\big) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\boldsymbol{\\theta}(\\mathbf{x}^{(i)}, \\mathbf{z}^{(i, l)}) \\\\\n",
    "~~~ \\text{where} ~~ \\mathbf{z}^{(i, l)} &= g_\\phi(\\boldsymbol{\\epsilon}^{(i, l)}, \\mathbf{x}^{(i)}) ~ \\text{and} ~ \\boldsymbol{\\epsilon}^{(l)} \\sim p(\\boldsymbol{\\epsilon})\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE에서는 $p(z \\mid x)$가 정규 분포 $\\mathcal{N}(\\mu, \\sigma^2)$이고, $\\epsilon$은 표준 정규분포 $\\mathcal{N}(0, 1)$라 가정하고 있습니다. 이렇게되면 위 식은 아래와 같이 정리됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\mathcal{\\tilde{L}}^B(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}^{(i)}) &= -  KL\\big (q_\\phi (\\mathbf{z}^{(i, l)} \\mid \\mathbf{x}^{(i)}) \\Vert p_\\theta(\\mathbf{z}^{(i, l)}) \\big) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\boldsymbol{\\theta}(\\mathbf{x}^{(i)}, \\mathbf{z}^{(i, l)}) \\\\\n",
    "&=\\frac{1}{2} \\sum_{j=1}^J \\bigg( 1 + \\log( (\\sigma_j^{(i)})^2 - (\\mu_j^{(i)})^2) - (\\sigma_j^{(i)})^2 \\bigg) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\theta (\\mathbf{x}^{(i)} \\mid \\mathbf{z}^{(i, l)} ) \\\\\n",
    "~~~ \\text{where} ~~ \\mathbf{z}^{(i, l)} &= \\boldsymbol{\\mu}^{(i)} + \\boldsymbol{\\sigma}^{(l)} ~ \\text{and} ~ \\epsilon^{(l)} \\sim \\mathcal{N}(0, \\mathbf{I}) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE에서는 위 함수를 초소화 하는 형태로 학습이 진행됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 loss-function의 의미를 생각해볼 수 있는데요, 앞쪽의 KL divergence 항은 $p(z \\mid x)$가 $\\mathcal{N}(0, 1)$에 가까워지도록하는 역할을 하며, 뒤쪽의 $\\sum$항은 인코더의 입력과 디코더의 출력이 가능한 같아지도록 하는 역할을 합니다. 기존의 AutoEncoder와 비교한다면 KL divergence 항이 추가된 점이 다르며 네트워크 구조적으로는 $p(z \\mid x)$에 대한 정규분포 조건을 반영하기 위한 부분이 달라지게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 적용 사례"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z$가 원인이고 $x$가 결과가 되는 상황($z \\rightarrow x$)에서 우리는 $x$를 데이터로 관찰하게 되고,      \n",
    "이에 대한 marginal likelihood를 구하기 위해 베이지안 접근법에서는 아래와 같은 방식을 취한다.\n",
    "$$p(\\mathbf{x}) = \\int_\\mathbf{z} p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) ~ d\\mathbf{z}$$\n",
    "\n",
    "하지만 latent $\\mathbf{z}$가 고차원인경우 이 적분을 계산하는 것이 어려워진다.      \n",
    "대신 아래와 같이 베이즈룰과 Kullback-Leibler divergence를 이용한 근사를 이용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(\\mathbf{x})$를 잘 정리하면 아래와 같이 표현할 수 있고, marginal likelihood를 최대화 하는 \n",
    "\n",
    "$$\\begin{align}\n",
    "\\log p(\\mathbf{x}) &= KL\\big( q(\\mathbf{z}|\\mathbf{x}) \\Vert p(\\mathbf{z} \\mid \\mathbf{x}) \\big) - \\mathbb{E}_{q(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log q(\\mathbf{z}|\\mathbf{x}) - \\log p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) \\bigg] \\\\\n",
    "&\\geq \\mathbb{E}_{q(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p(\\mathbf{x} \\mid \\mathbf{z}) p(\\mathbf{z}) - \\log q(\\mathbf{z}|\\mathbf{x}) \\bigg] \\\\\n",
    "&= \\mathbb{E}_{q(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p(\\mathbf{x} \\mid \\mathbf{z}) - \\log \\frac{q(\\mathbf{z}|\\mathbf{x})}{p(\\mathbf{z})} \\bigg] \\\\\n",
    "&= \\mathbb{E}_{q(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p(\\mathbf{x} \\mid \\mathbf{z}) \\bigg] - KL\\big( q(\\mathbf{z}|\\mathbf{x}) \\Vert p(\\mathbf{z}) \\big)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_\\theta(\\mathbf{x})$를 잘 정리하면 아래와 같이 표현할 수 있고,               \n",
    "marginal likelihood를 최대화 하는 $q_\\phi(\\mathbf{z}|\\mathbf{x})$의 파라미터 $\\theta$와             \n",
    "$q_\\phi(\\mathbf{z}|\\mathbf{x})$의 파라미터 $\\phi$를 찾을 수 있다면 $x$와 $z$에 대한 많은걸 알게 된다.\n",
    "\n",
    "$$\\begin{align}\n",
    "\\log p_\\theta(\\mathbf{x}) &= KL\\big( q_\\phi(\\mathbf{z}|\\mathbf{x}) \\Vert p_\\theta(\\mathbf{z} \\mid \\mathbf{x}) \\big) - \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log q_\\phi(\\mathbf{z}|\\mathbf{x}) - \\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z}) \\bigg] \\\\\n",
    "&\\geq_\\phi \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\theta(\\mathbf{z}) - \\log q_\\phi(\\mathbf{z}|\\mathbf{x}) \\bigg] \\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) - \\log \\frac{q_\\phi(\\mathbf{z}|\\mathbf{x})}{p_\\theta(\\mathbf{z})} \\bigg] \\\\\n",
    "&= \\mathbb{E}_{q_\\phi(\\mathbf{z}|\\mathbf{x})} \\bigg[ \\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) \\bigg] - KL\\big( q_\\phi(\\mathbf{z}|\\mathbf{x}) \\Vert p_\\theta(\\mathbf{z}) \\big)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Variational autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational inference를 이용해서 이 위 문제를 다뤄볼수도 있지만, 샘플 사이즈가 커지거나 분포에 대한 몇가지 조건이 필요하므로 현실적이지 않고, VAE에서 제시하는 reparameterization trick을 이용해 효과적으로 풀어볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAE에서는 잠재변수 분포 $p(z\\mid x)$가 정규분포로 모델링하며, 디코더 입력으로 사용될 $p(z\\mid x)$에서의 샘플을 얻기 위해서 $\\mu + \\sigma \\cdot \\epsilon, ~ \\epsilon \\sim N(0, 1)$에서 대신 샘플링하는 트릭을 이용한다. 이런 트릭을 을 이용해 marginal likelihood를 다시 정리하면 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\log p_\\theta(\\mathbf{x}) &\\geq \\frac{1}{L} \\sum_{l=1}^L \\log p_\\boldsymbol{\\theta}(\\mathbf{x}^{(i)}, \\mathbf{z}^{(i, l)}) - KL\\big( q_\\phi(\\mathbf{z}|\\mathbf{x}) \\Vert p_\\theta(\\mathbf{z}) \\big) \\\\\n",
    "&\\approx -  KL\\big (q_\\phi (\\mathbf{z}^{(i, l)} \\mid \\mathbf{x}^{(i)}) \\Vert p_\\theta(\\mathbf{z}^{(i, l)}) \\big) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\boldsymbol{\\theta}(\\mathbf{x}^{(i)}, \\mathbf{z}^{(i, l)}) \\\\\n",
    "&=\\frac{1}{2} \\sum_{j=1}^J \\bigg( 1 + \\log( (\\sigma_j^{(i)})^2 - (\\mu_j^{(i)})^2) - (\\sigma_j^{(i)})^2 \\bigg) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\theta (\\mathbf{x}^{(i)} \\mid \\mathbf{z}^{(i, l)} ) \\\\\n",
    "~~~ &\\text{where} ~~ \\mathbf{z}^{(i, l)} = \\boldsymbol{\\mu}^{(i)} + \\boldsymbol{\\sigma}^{(l)} ~ \\text{and} ~ \\epsilon^{(l)} \\sim \\mathcal{N}(0, \\mathbf{I}) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3번째 식을 objective function으로 네트워크를 학습시키는데,       \n",
    "이 loss function의 의미를 생각해보면 첫번째 항은 잠재변수가 각각 정규분포(N(0, 1))에 가까워지도록 하는 역할을 하고, 두번째 항은 autoencoder의 기본적인 특성인 입력과 출력이 같아져야 한다는 조건을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "네트워크 구조는 아래 우측과 같다. 좌측의 기본적인 autoencoder와 조금 달라진 부분을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Remote image](https://www.renom.jp/notebooks/tutorial/generative-model/VAE/fig4.png \"Tooltip for remote image\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space and dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\t* https://arxiv.org/pdf/1706.05148.pdf\n",
    "\t* \n",
    "connection to PCA in the https://www.youtube.com/watch?v=uaaqyVS9-rM\n",
    "\t* \n",
    "shortcommings : randomness but data\n",
    "\n",
    "\n",
    "> this is much better dimensionality reduction methodology for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative point of view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
