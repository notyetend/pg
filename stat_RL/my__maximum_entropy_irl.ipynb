{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custum_frozen_lake_env import CustumFrozenLakeEnv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space\n",
      "Total 64 states\n",
      "Action space\n",
      "Total 4 actions\n"
     ]
    }
   ],
   "source": [
    "env = CustumFrozenLakeEnv(map_name=\"8x8\")\n",
    "\n",
    "obs_space = env.observation_space\n",
    "n_state = obs_space.n\n",
    "print('Observation space')\n",
    "print(\"Total {} states\".format(n_state))\n",
    "\n",
    "act_space = env.action_space\n",
    "n_act = act_space.n\n",
    "print('Action space')\n",
    "print(\"Total {} actions\".format(n_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(x, scale = 1):\n",
    "    x = np.array(x)/scale\n",
    "    max_x = np.max(x,axis=1,keepdims=True)\n",
    "    lse_x = max_x[:,0] + np.log(np.exp(x-max_x).sum()) # Numerical Stability\n",
    "    lse_x = scale*lse_x\n",
    "    return lse_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x, scale = 1):\n",
    "    x = np.array(x)/scale\n",
    "    max_x = np.max(x,axis=1,keepdims=True)\n",
    "    e_x = np.exp(x - max_x) # Numerical Stability\n",
    "    p = e_x/np.sum(e_x,axis=1,keepdims=True)\n",
    "    p = p/np.sum(p,axis=1,keepdims=True)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### soft_value_iteration\n",
    " > - 그냥 q-learning과 같고 policy를 구할때 q-value를 입력으로하는 softmax를 쓴것만 다르다.\n",
    "- 그리고 q-function으로 value-function구할때 numerical stability를 위한 trick이 들어갔다.(logsumexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_value_iteration(env,rewards=None,gamma=0.99,epsilon=1e-6,scale=1e-5):\n",
    "    obs_space = env.observation_space\n",
    "    n_state = obs_space.n\n",
    "    act_space = env.action_space\n",
    "    n_act = act_space.n\n",
    "    \n",
    "        \n",
    "    P = np.zeros((n_state,n_act,n_state))\n",
    "    r = np.zeros((n_state,n_act,n_state))\n",
    "    \n",
    "    for s in env.unwrapped.P.keys(): # For all states s, update v(s)\n",
    "        for a in env.unwrapped.P[s].keys(): # For all actions a\n",
    "            for prob, next_s, reward, done in env.unwrapped.P[s][a]: # For all possible transitions (s,a,s')\n",
    "                P[s][a][next_s]=prob\n",
    "                if rewards is None:\n",
    "                    r[s][a][next_s]=reward\n",
    "                else:\n",
    "                    r[s][a][next_s]=rewards[s][a][next_s]\n",
    "        \n",
    "    value = np.random.uniform(size=(n_state,))\n",
    "    \n",
    "    if debug:\n",
    "        print('Obs space:', obs_space, 'N_state:', n_state)\n",
    "        print('Act_space:', act_space, 'N_act:', n_act)\n",
    "        print(\"Transition prob P's shape:\", P.shape)\n",
    "        print(\"Reward func r's shape:\", r.shape)\n",
    "        print(\"Value function's shape:\", value.shape)    \n",
    "            \n",
    "    while True:\n",
    "        q = np.sum((r + gamma * np.tile(value[np.newaxis,np.newaxis,:],reps=(n_state,n_act,1)))*P,axis=2)\n",
    "        v_prime = logsumexp(q, scale=scale)\n",
    "        dist = np.max(np.abs(value-v_prime))\n",
    "        value = v_prime\n",
    "        if dist < epsilon:\n",
    "            break\n",
    "            \n",
    "    policy = softmax(q, scale=scale)\n",
    "    return policy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs space: Discrete(64) N_state: 64\n",
      "Act_space: Discrete(4) N_act: 4\n",
      "Transition prob P's shape: (64, 4, 64)\n",
      "Reward func r's shape: (64, 4, 64)\n",
      "Value function's shape: (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+000, 5.00000000e-001, 5.00000000e-001,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 8.56593352e-193, 1.00000000e+000,\n",
       "         3.72155633e-109],\n",
       "        [0.00000000e+000, 1.18885622e-254, 1.00000000e+000,\n",
       "         3.11647434e-137],\n",
       "        [0.00000000e+000, 3.97971473e-296, 1.00000000e+000,\n",
       "         1.85911350e-160],\n",
       "        [0.00000000e+000, 2.47032823e-323, 1.00000000e+000,\n",
       "         2.33207439e-189],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         9.76535595e-250],\n",
       "        [0.00000000e+000, 3.99441317e-289, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [5.00000000e-001, 5.00000000e-001, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.37289602e-298, 1.00000000e+000, 2.95953672e-056,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 2.55025419e-130, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [3.91044810e-102, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [8.36566340e-225, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 5.92795861e-001, 0.00000000e+000,\n",
       "         4.07204139e-001],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [6.32251150e-001, 0.00000000e+000, 0.00000000e+000,\n",
       "         3.67748850e-001],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 6.32251150e-001, 3.67748850e-001,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         1.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 7.44977097e-001, 2.55022903e-001,\n",
       "         0.00000000e+000],\n",
       "        [9.71382203e-001, 0.00000000e+000, 0.00000000e+000,\n",
       "         2.86177965e-002],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [5.05566376e-001, 0.00000000e+000, 4.94433624e-001,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [1.00000000e+000, 0.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001],\n",
       "        [0.00000000e+000, 9.71382203e-001, 2.86177965e-002,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 0.00000000e+000, 1.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [0.00000000e+000, 1.00000000e+000, 0.00000000e+000,\n",
       "         0.00000000e+000],\n",
       "        [2.50000000e-001, 2.50000000e-001, 2.50000000e-001,\n",
       "         2.50000000e-001]]),\n",
       " array([ 0.38331903,  0.39672058,  0.41443826,  0.4350499 ,  0.45755959,\n",
       "         0.48063284,  0.50075594,  0.50633588,  0.3813932 ,  0.39088472,\n",
       "         0.40624535,  0.42558352,  0.44821177,  0.47493437,  0.51021041,\n",
       "         0.52711932,  0.35176118,  0.33264855,  0.26523993,  0.00464909,\n",
       "         0.26007475,  0.41356461,  0.51807689,  0.55986152,  0.28411422,\n",
       "         0.22493667,  0.0647233 , -0.33474802, -0.07381129,  0.00462319,\n",
       "         0.49971801,  0.60942923,  0.21786093,  0.04908823, -0.29418577,\n",
       "         0.00466036, -0.14913783, -0.00551355,  0.38665081,  0.6773245 ,\n",
       "         0.15806936,  0.00470402,  0.00467662, -0.72618321, -0.37274861,\n",
       "        -0.25436117,  0.00469685,  0.76560477,  0.10292762,  0.00470878,\n",
       "        -0.76107997, -0.82252384,  0.00461962, -0.39266978,  0.00461895,\n",
       "         0.8769452 ,  0.05076474, -0.21062051, -0.47852904,  0.00472536,\n",
       "        -0.46073914,  0.06979391,  0.53423243,  0.00461876]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = CustumFrozenLakeEnv(map_name=\"8x8\")\n",
    "\n",
    "obs_space = env.observation_space\n",
    "n_state = obs_space.n\n",
    "act_space = env.action_space\n",
    "n_act = act_space.n\n",
    "\n",
    "soft_value_iteration(env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### get_visitation\n",
    "> - visitation\n",
    " - state visitation: $\\rho_{\\pi_\\theta}(s) = \\sum_t^\\infty \\gamma^t P_{\\pi_\\theta}(S_t = s)$\n",
    " - action visitation: $\\rho_{\\pi_\\theta}(s, a) = \\sum_t^\\infty \\gamma^t P_{\\pi_\\theta}(S_t = s, A_t = a)$\n",
    "- feature expectation\n",
    " $$\\mu(\\pi) = \\sum_s \\rho_\\pi(s) \\phi(s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_visitation(env, policy, gamma=0.99, epsilon=1e-6):\n",
    "    obs_space = env.observation_space\n",
    "    n_state = obs_space.n\n",
    "    act_space = env.action_space\n",
    "    n_act = act_space.n\n",
    "    \n",
    "    P = np.zeros((n_state,n_act,n_state))\n",
    "    for s in env.unwrapped.P.keys(): # For all states s, update v(s)\n",
    "        for a in env.unwrapped.P[s].keys(): # For all actions a\n",
    "            for prob, next_s, reward, done in env.unwrapped.P[s][a]: # For all possible transitions (s,a,s')\n",
    "                P[s][a][next_s]=prob\n",
    "    \n",
    "    d = np.zeros((n_state,))  # vector with n_state length\n",
    "    d[0] = 1  # \n",
    "    \n",
    "    mu_s = np.zeros((n_state,))\n",
    "    mu_s[0] = 1\n",
    "    while True:\n",
    "        mu_sa = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\gamma  \\sum_a \\sum_s P(s' \\mid s, a) \\mu(s, a)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
