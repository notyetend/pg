{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> reference\n",
    "- paper: https://arxiv.org/abs/1704.03477\n",
    "- drawing test: https://magenta.tensorflow.org/assets/sketch_rnn_demo/index.html\n",
    "- blogs: \n",
    " - https://magenta.tensorflow.org/sketch-rnn-demo\n",
    " - https://ai.googleblog.com/2017/04/teaching-machines-to-draw.html\n",
    " - https://magenta.tensorflow.org/sketch_rnn\n",
    " - https://experiments.withgoogle.com/sketch-rnn-demo\n",
    "- github repo: https://github.com/tensorflow/magenta/blob/master/magenta/models/sketch_rnn/README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그림, 그중에서도 펜으로 그리는 그림(stoke-based drawings)을 생성하는 sketch-rnn이란 모델을 소개한다. \n",
    "- 이 모델은조건부 스케치 생성 모델(conditional sketch generation model)과 무-조건부 스케치 생성 모형(unconditional sketch generation model)으로 나뉜다.\n",
    "- 벡터 형식으로 된 스케치 데이터를 잘 학습시키기 위한 방법을 소개한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 요즘 GAN, Variational Inference(VI), Autoregressive(AR)과 같은 이미지를 생성하는 아래와 같은 모형이 붐이다. 그런데 이런 모형들은 픽셀 이미지를 생성하는 것들이다. 반면 이 논문에서는 펜 스트록 이미지(스케치)와 같은 벡터 이미지를 학습하고 생성하는 모형을 소개한다.\n",
    " - Figure 1\n",
    "\n",
    "- 펜으로 그린 그림 데이터는 각 선을 (이전 점으로부터 움직인 xy값, 현재 점 이후 펜을 종이에서 뗄 것인지, 현재 점을 마지막으로 그림을 다 그렸는지)로 표현하며 이런 선들이 모여 하나의 그림 데이터가 된다.(3.1에서 자세히 설명)\n",
    "\n",
    "- Contributions\n",
    " - 조건부 생성 모형(conditional generation model)과 무-조건부 생성 모형(unconditional generation model)\n",
    " - 벡터 형식의 데이터를 생성하는 RNN 베이스 모형(LSTM, HyperLSTM이 사용됨)\n",
    " - 벡터 이미지를 잘(robust) 학습시키기 위한 학습 과정을 제시\n",
    " - 조건부 생성 모형을 이용해 잠재공간(latent space)의 각 점에 해당하는 이미지 생성\n",
    " - 사용된 데이터셋 공개(https://github.com/googlecreativelab/quickdraw-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "화가를 따라하는 아래 알고리즘들은 생성 모형이라기보다 그림을 따라 그리려는 시도였음.\n",
    "- 그림을 주면 로봇 팔을 컨트롤해서 그림을 그림 그리게 하는 방법\n",
    "- 사진을 주면 강화학습을 이용해 붓의 움직임을 찾아내는 방법\n",
    "\n",
    "픽셀로 구성된 이미지를 학습하는 신경망 기반의 생성 모형이 많이 개발됨.\n",
    "\n",
    "벡터 이미지를 이용하는 접근법은 아래와 같은 것들이 있었음. \n",
    "- HMM을 이용해 선과 곡선을 생성하는 모형\n",
    "- 그림의 각 점을 Mixture Density Network로 모델링하고 RNN으로 학습시키는 모형\n",
    "- 한자를 조건부/무-조건부로 생성하는 모형\n",
    "\n",
    "(후략)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- QuickDraw라는 데이터셋을 만듬\n",
    "- pen stroke action을 표현하는 데이터 포멧을 정의함, $(\\Delta x, \\Delta y, p_1, p_2, p_3)$\n",
    " - $\\Delta x$: 이전 점으로부터 $x$ 좌표 변화량\n",
    " - $\\Delta y$: 이전 점으로부터 $y$ 좌표 변화량\n",
    " - $p_1$: 펜의 상태로서 펜이 지금 종이에 닿아 있는지를 표시 (1이면 닿아 있고, 다음 점과 연결되는 선이 그려질 것임.)\n",
    " - $p_2$: 펜이 현재점 이후 뜰 것임을 표시 (1이면 현재점 이후 좋이에 펜이 떨어질 것이므로 다음 점과 선이 그려지지 않을 것임)... ?? 그럼 $p_1$과 $p_2$중 하나만 1인가??\n",
    " - $p_3$: 그림 다 그렸음을 표시 (1이면 다 그렸다.)\n",
    " - 예를들어 (3, 2, 1, 0, 0) 이면 이전 좌표에서 $x$축으로 3만큼, $y$축으로 2만큼 움직였고, 현재 펜이 종이에 닿아 있고, 이후 다음 점과 선이 열결될 것이며, 아직 그림이 끝나지 않았음을 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-21   7   0]\n",
      " [-66   9   0]\n",
      " [-30  11   0]\n",
      " [  5  -3   0]\n",
      " [ 75 -11   0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with np.load('/Users/notyetend/Downloads/sketch-rnn-data/sketchrnn%2Fbird.npz', encoding='latin1') as a:\n",
    "    train = a['train']\n",
    "    print(train[:1][0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sketch-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Sequence-to-Sequence VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델은 Sequence-to-Sequence Variational Autoencoder 이다.(참고 논문: S. R. Bowman, L. Vilnis, O. Vinyals, A. M. Dai, R. Józefowicz, and S. Bengio. Generating Sentences from a Continuous Space. CoRR, abs/1511.06349, 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Encoder RNN and VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Forward Encoder RNN(LSTM)은 순방향 스케치 데이터 $S$를 입력으로 받아 $h_{\\rightarrow}$를 출력으로 내놓고, Backward Encoder RNN(LSTM)은 역방향 스케치 데이터 $S_{\\text{reverse}}$를 입력으로 받아 $h_{\\leftarrow}$를 출력으로 내놓는다. 두 출력을 병합한 출력을 $h = [ h_{\\rightarrow}; h_{\\leftarrow} ]$라 한다. ($h_{\\rightarrow}$과 $h_{\\leftarrow}$ 모두 크기가 $N_z$인 벡터이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 병합된 출력 $h$를 VAE의 중앙 히든 레이어의 입력으로 넣는데, 이 중앙 히든 레이어는 각각 크기가 $N_z$인 $\\mu$와 $\\sigma$로 구성된다. 이후 $z \\sim p(z \\mid x)$를 샘플링하는 과정은 VAE의 문법을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Decoder RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoder는 autoregressive RNN으로서 $z$가 주어졌을 때 스케치 데이터($S_1, \\cdots, S_{N_{\\text{max}}}$)를 생성하는 역할을 한다.\n",
    " - 첫 decoder RNN의 히든 입력은 $[h_0; c_0] = \\tanh(W_z z + b_z)$이다. ($c_0$은 없을수도 있다.) Q) $c_0$는 뭐지?: cell state of LSTM\n",
    " - $i$번째 decoder RNN에는 $i-1$번째 decoder RNN-GMM-Softmax의 출력 $S_{i-1}$와 잠재 벡터 $z$을 병합한 $x_i = [S_{i-1}; z]$를 입력으로 넣는다. \n",
    " - 첫번째 decoder RNN의 입력의 $S_0$는 $(0, 0, 1, 0, 0)$을 사용한다.\n",
    " - $i$번째 decoder RNN-GMM-Softmax의 출력 $S_i$는 $i$ 번째 그릴 점에 대한 확률 분포를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 스케치를 구성하는 선을 $(\\Delta x, \\Delta y, p_1, p_2, p_3)$와 같이 표현한다.\n",
    " - $\\Delta x$와 $\\Delta y$에 대한 결합 확률 분포를 $M$개의 2변수 정규 분포(bivariate normal distribution)의 mixture로 표현한다.  이는 3번 수식에 해당하며, $M$개의 bivariate normal dist를 표현하기 위해 $5M$개의 파라미터가 필요하며 mixture weight $\\Pi$를 표현하기 위해 $M$개의 파라미터가 필요하다.    \n",
    " // equation 3\n",
    " \n",
    " - $(p_1, p_2, p_3)$를 각각 $(q_1, q_2, q_3)$라는 범주형(categorical) 확률 변수로 표현하며 $q_1 + q_2 + q_3 = 1$이라는 제약조건이 있다.\n",
    " - 따라서 $(\\Delta x, \\Delta y, p_1, p_2, p_3)$ 한 쌍을 표현하기 위해서는 $5M + M + 3$개의 파라미터가 필요하다.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " - decoder RNN의 출력 $y_i$는 길이가 $6M + 3$인 벡터인데, 앞부분의 $6M$만큼은 $(\\Delta x, \\Delta y)$ 분포의 파라미터로 사용되고, 뒷부분 3만큼은 $(q_1, q_2, q_3)$를 표현하는데 사용된다. decoder RNN의 출력은 $\\hat{y}$이고 그 형태는 아래와 같다.\n",
    " $$\\big[ (\\hat{\\Pi}_1, \\mu_x, \\mu_y, \\hat{\\sigma}_x, \\hat{\\sigma}_y, \\hat{\\rho}_{xy})_1, \\dots (\\hat{\\Pi}_1, \\mu_x, \\mu_y, \\hat{\\sigma}_x, \\hat{\\sigma}_y, \\hat{\\rho}_{xy})_M,  ~ (\\hat{q}_1, \\hat{q}_2, \\hat{q}_3) \\big] = y_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - decoder RNN은 $[S_{i-1}; z]$를 입력으로, $[h_{i-1}; c_{i-1}]$을 히든 입력으로 받아 히든 출력 $h_i$와 셀 상태 $c_i$를 만들고, 히든 출력은 다음 decoder RNN으로 보내고, $y_i = W_y h_i + b_y, ~ y_i \\in \\mathbb{R}^{6M + 3}$는 GMM-Softmax 레이어로 보낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $y_i$가 GMM-softmax의 입력으로 사용되기 전에 수식 6과 같이 표준편차로 사용되는 파라미터가 0보다 크게 하기 위한 장치가 들어간다. 또한 수식 (7)과 같이 logit $\\hat{q}_k$를 확률 값 $q_k$로 변환하는 과정도 포함된다.\n",
    " - 또한 수식 (7)과 같이 mixture weight 벡터를 결정하기 위해 $\\hat{\\Pi}$를 softmax로 변환하여 categorical 확률 분포를 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - autoregressive RNN, time-series forecasting, LSTM, ARIMA\n",
    " - https://datascience.stackexchange.com/questions/12721/time-series-prediction-using-arima-vs-lstm\n",
    " - https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    " - https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
    " - https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    " - https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    " - https://blog.statsbot.co/time-series-prediction-using-recurrent-neural-networks-lstms-807fa6ca7f\n",
    " - https://arxiv.org/abs/1803.06386\n",
    " - https://www.quora.com/Can-recurrent-neural-networks-with-LSTM-be-used-for-time-series-prediction\n",
    " - https://ccc.inaoep.mx/~pgomez/conferences/PggISCI14.pdf\n",
    " - http://www.felixgers.de/papers/phd.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Hard to train when to stop drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델을 학습시킬 때 어려운 점은 3가지 펜의 움직임 $p_1, p_2, p_3$에 대한 확률이 매우 불균형하다는 것이다. $p_1$에 대한 확률은 $p_2$에 대한 확률보다 월등히 높으며, $p_3$ 이벤트는 그림을 그리는 동한 단 한번만 발생한다. 이런 상황에 대한 접근법으로 $p_1, p_2, p_3$ 각각의 loss에 서로 다른 가중치를 부여하는 것이다. 예를들어 (1, 10, 100)와 같은 가중치를 사용한다면, 그림을 그리는 동안 한번만 발생하여 전체 loss에 별 영향을 주지 못하는 $p_3$에 대한 loss가 적절히 보정된다.\n",
    " - 하지만 지금 다루려는 데이터는 다양한 종류의 이미지를 다뤄야하기 때문에 이 접근접이 적절하지 않다는걸 확인할 수 있었다.\n",
    "\n",
    "- 대신 위 방법을 조금 변형했는데, 모든 스케치 데이터의 길이를 $N_\\max$(training set 각 그림의 길이중 최대값)가 되도록 가공했다. 대부분 스케치 시퀀스의 길이가 $N_\\max$보다 작기 때문에, 실제 $S$ 시퀀스 종료부터 $N_\\max$까지 (0, 0, 0, 0, 1)로 체워 넣었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 후 스케치를 생성하는 과정은 우선 (첫 시작점을 생성하는 부분은 명확히 나와 있지 않음) 첫 시작점 $S^{'}_1$를 생성하고, 이를 인코더의 입력으로 넣어 GMM-softmax에서 두번째 점 $S^{'}_2$을 얻고, 이를 다시 네트워크의 입력으로 넣는 과정을 $p_3=1$일 때까지 혹은 $i=N_{\\text{max}}$일때까지 반복한다.\n",
    "- 스케치를 샘플링하는건 중간의 VAE 때문에 deterministic하지 않다. 이런 randomness를 파라미터로 조절할 수 있는데, 온도와 같은 역할을 하는 파라미터 $\\tau$를 도입해서 이 값이 크면 randomness가 커지도록 할 수 있다. $\\tau$는 0과 1 사이의 값을 사용한다. (이 파라미터를 조절했을 때 그림의 변화는 Figure3로 확인할 수 있으며, 파란색은 낮은 온도, 붉은 색은 높은 온도일때 생성된 그림이다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Unconditional Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3.2에서 설명한 구조는 latent vector $z$에 conditional한 출력을 내놓는다. 이 구조에서 앞단의 인코더를 없애고, 디코더 RNN만으로 학습시킬 수도 있는데, 이는 latent 변수가 없는 autoregressive model이라 할 수 있다. 이렇게 바꿨을 때 최초 hidden state과 cell state은 0값들을 사용한다. 그리고 각 time-step에 RNN의 입력은 (training time) $S_{i-1}$과 (inference time) $S^{'}_{i-1}$이다. 이렇게 unconditional하게 생성한 그림이 Figure3에 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이때의 loss function은???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- VAE에서 maximize하는 loss function은 아래와 같다. 즉 negative KL divergence와 MLE의 합인데, KL divergence를 최소화 하고, MLE(-reconstruction error)를 최대화 한다.(reconstruction error는 최소화)\n",
    "$$\\begin{align}\n",
    "\\mathcal{\\tilde{L}}^B(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}^{(i)}) &= -  KL\\big (q_\\phi (\\mathbf{z}^{(i, l)} \\mid \\mathbf{x}^{(i)}) \\Vert p_\\theta(\\mathbf{z}^{(i, l)}) \\big) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\boldsymbol{\\theta}(\\mathbf{x}^{(i)} \\mid \\mathbf{z}^{(i, l)}) \\\\\n",
    "&=\\frac{1}{2} \\sum_{j=1}^J \\bigg( 1 + \\log( (\\sigma_j^{(i)})^2 - (\\mu_j^{(i)})^2) - (\\sigma_j^{(i)})^2 \\bigg) + \\frac{1}{L} \\sum_{l=1}^L \\log p_\\theta (\\mathbf{x}^{(i)} \\mid \\mathbf{z}^{(i, l)} ) \\\\\n",
    "~~~ \\text{where} ~~ \\mathbf{z}^{(i, l)} &= \\boldsymbol{\\mu}^{(i)} + \\boldsymbol{\\sigma}^{(l)} ~ \\text{and} ~ \\epsilon^{(l)} \\sim \\mathcal{N}(0, \\mathbf{I}) \n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 논문에 최소화 하는 loss function은 VAE 논문에 등장하는 objective function, $\\mathcal{\\tilde{L}}^B(\\boldsymbol{\\theta}, \\boldsymbol{\\phi}; \\mathbf{x}^{(i)})$의 부호를 바꾼 것이며          \n",
    "KL divergence 항인 $K_{KL}$과       \n",
    "reconstruction loss 항인 $L_R(=L_s + L_p)$을 합한 것이다.         \n",
    "전체 loss를 최소화하므로 $K_{KL}$와 $L_R(=L_s + L_p)$ 모두 최소화 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $L_s$는 $\\Delta x$와 $\\Delta y$에 대한 loss인데, $N_S$이후(스케치가 끝나면) loss는 버린다. 반면 $L_p$는 $(p_1, p_2, p_3)$에대한 loss인데, $N_\\max$까지 모든 loss를 사용한다. 이렇게 하면 $(p_1, p_2, p_3)$ 각각에 대한 loss에 weight을 달리하는 것 보다 강건하다.\n",
    "- $L_{KL}$은 latent vector $z \\sim p(z \\mid x)$와 $z$의 prior $\\mathcal{N}(0, 1)$의 차이를 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q\n",
    " - reconstruction은 왜 joint prob 형태인가? 그리고 코딩할때는 단순히 mse인가? (작은 힌트: https://stats.stackexchange.com/questions/347378/variational-autoencoder-why-reconstruction-term-is-same-to-square-loss)\n",
    "\n",
    "- Q\n",
    " - Figure4 좌측 그림에서 standalone decoder이라서 $L_{KL}$이 없는데 $w_{KL}$이 무슨 의미가 있지? -> 좌측 그림의 실선은 encoder를 포함한 모델이고, 점선은 standalone 모델이다.\n",
    " - Figure4 우측 그림에서 $L_{KL}$은 왜 점차 증가하지? Validation loss라서 그런가??? -> 원 논문의 SGVB(maximize)의 부호를 바꿨다. 그래서 학습될수록 KL은 커진다. 그리고 L_R은 likelihood이므로 작아진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 전체 loss는 아래와 같이 $L_{KL}$에 가중치를 줄 수 있다. 즉 regularization 강도를 조절할 수 있다.\n",
    "$$Loss = L_R + w_{KL} L_{KL}$$\n",
    " - $w_{KL}$ 값이 0에 가까워질수록 기본적인 autoencoder에 가까워진다.\n",
    " - unconditional generation에는 $L_{KL}$이 없다.\n",
    " \n",
    "\n",
    "- Figure4(좌측): 점선은 standalone 모델로서 $L_{KL}$이 없는 모델이다. 그래서 encoder가 있는 모델 loss의 upper bound 쯤 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Q\n",
    " - 6페이지 첫머리에 breakdown of losses는 뭘까?\n",
    " - 6페이지 두번째 문단에 abstrct component???\n",
    "\n",
    "- sketch-rnn 모델에서는 RNN cell을 하나의 추상적인 구성요소로 사용한다.(빌딩 블록같은 역할을 한다.) \n",
    " - encoder에는 LSTM이 사용된다.\n",
    " - decoder에는 HyperLSTM이 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Conditional Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sketch Drawing Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Predicting Different Endings of Incomplete Sketches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applications and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
