{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- QuickDraw라는 데이터셋을 만듬\n",
    "- pen stroke action을 표현하는 데이터 포멧을 정의함, $(\\Delta x, \\Delta y, p_1, p_2, p_3)$\n",
    " - $\\Delta x$: 이전 점으로부터 $x$ 좌표 변화량\n",
    " - $\\Delta y$: 이전 점으로부터 $y$ 좌표 변화량\n",
    " - $p_1$: 펜의 상태로서 펜이 지금 종이에 닿아 있는지를 표시\n",
    " - $p_2$: 펜이 현재점 이후 뜰 것임을 표시\n",
    " - $p_3$: 그림 다 그렸음을 표시\n",
    " - 예를들어 (3, 2, 1, 1, 0) 이면 이전 좌표에서 $x$축으로 3만큼, $y$축으로 2만큼 움직였고, 현재 지점까지 선을 그렸고, 이후 다른 점에서 다시 시작할 것이며, 아직 그림이 끝나지 않았음을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Sketch-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델은 Sequence-to-Sequence Variational Autoencoder 이다.\n",
    "\n",
    "\n",
    "- Forward Encoder RNN은 순방향 스케치 데이터 $S$를 입력으로 받아 $h_{\\rightarrow}$를 출력으로 내놓고, Backward Encoder RNN은 역방향 스케치 데이터 $S_{\\text{reverse}}$를 입력으로 받아 $h_{\\leftarrow}$를 출력으로 내놓는다. 두 출력을 병합한 출력을 $h = [ h_{\\rightarrow}; h_{\\leftarrow} ]$라 한다.\n",
    "\n",
    "\n",
    "- 병합된 출력 $h$를 VAE의 중앙 히든 레이어의 입력으로 넣는데, 이 중앙 히든 레이어는 각각 크기가 $N_z$인 $\\mu$와 $\\sigma$로 구성된다. 이후 $z \\sim p(z \\mid x)$를 샘플링하는 과정은 VAE의 문법을 따른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Decoder는 **autoregressive RNN???** 로서 $z$가 주어졌을 때 스케치 데이터를 생성하는 역할을 한다.\n",
    " - 첫 decoder RNN의 히든 입력은 $[h_0; c_0] = \\tanh(W_z z + b_z)$이다. ($c_0$은 없을수도 있다.)\n",
    " - $i$번째 decoder RNN에는 $i-1$번째 decoder RNN-GMM-Softmax의 출력 $S_{i-1}$와 잠재 벡터 $z$을 병합한 $x_i$를 입력으로 넣는다. \n",
    " - 첫번째 decoder RNN의 입력 $S_0$는 $(0, 0, 1, 0, 0)$을 사용한다.\n",
    " - $i$번째 decoder RNN-GMM-Softmax의 출력 $S_i$는 $i$ 번째 그릴 점에 대한 확률 분포를 의미한다.\n",
    "\n",
    "- decoder RNN의 출력 $y_i$는 $(\\Delta x, \\Delta y)$를 $5M+M$개 차원 벡터로, $(p_1, p_2, p_3)$를 3개 차원 벡터로 표현한다. \n",
    " - 우선 $(\\Delta x, \\Delta y)$를 $M$개의 bivariate normal dist의 mixture로 표현한다. 이는 3번 수식에 해당하며, $M$개의 bivariate normal dist를 표현하기 위해 $5M$개의 파라미터가 필요하며 mixture weight $\\prod$를 표현하기 위해 $M$개의 파라미터가 필요하다.\n",
    " - 다음으로 $(p_1, p_2, p_3)$를 각각 $(q_1, q_2, q_3)$라는 categorical 변수로 표현하며 $q_1 + q_2 + q_3 = 1$이라는 제약조건이 있다.\n",
    " - 결국 decoder RNN은 $[S_{i-1}; z]$를 입력으로, $[h_{i-1}; c_{i-1}]$을 히든 입력으로 받아 히든 출력 $h_i$와 셀 상태 $c_i$를 만들고, 히든 출력은 다음 decoder RNN으로 보내고, $y_i = W_y h_i + b_y, ~ y_i \\in \\mathbb{R}^{6M + 3}$는 GMM-Softmax 레이어로 보낸다.\n",
    " \n",
    " - decoder RNN의 출력 $y_i$는 길이가 $6M + 3$인 벡터인데, 앞부분의 $6M$만큼은 $(\\Delta x, \\Delta y)$ 분포의 파라미터로 사용되고, 뒷부분 3만큼은 $(p_1, p_2, p_3)$를 표현하는데 사용된다.\n",
    " - 수식 6과 같이 표준편차로 사용되는 파라미터가 0보다 크게 하기 위한 장치가 들어간다.\n",
    " - categorical 변수 $(q_1, q_2, q_3)$는 softmax 연산으로 $p_1, p_2, p_3$에 대한 확률을 결정한다.\n",
    " - mixture weight 벡터 $\\prod$ 또한 categorical 값으로서 softmax 연산으로 $M$개 범주에 대한 확률을 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이 모델을 학습시킬 때 어려운 점은 3가지 펜의 움직임 $p_1, p_2, p_3$에 대한 확률이 매우 불균형하다는 것이다. $p_1$에 대한 확률은 $p_2$에 대한 확률보다 월등히 높으며, $p_3$ 이벤트는 그림을 그리는 동한 단 한번만 발생한다. 이런 상황에 대한 접근법으로 $p_1, p_2, p_3$ 각각의 loss에 서로 다른 가중치를 부여하는 것이다. 예를들어 (1, 10, 100)와 같은 가중치를 사용한다면, 그림을 그리는 동안 한번만 발생하여 전체 loss에 별 영향을 주지 못하는 $p_3$에 대한 loss가 적절히 보정된다.\n",
    " - 하지만 지금 다루려는 데이터는 다양한 종류의 이미지를 다뤄야하기 때문에 이 접근접이 적절하지 않다는걸 확인할 수 있었다.\n",
    "\n",
    "- 대신 위 방법을 조금 변형했는데, 모든 스케치 데이터의 길이를 $N_\\max$가 되도록 가공했다. 대부분 스케치 시퀀스의 길이가 $N_\\max$보다 작기 때문에, 실제 $S$ 시퀀스 종료부터 $N_\\max$까지 (0, 0, 0, 0, 1)로 체워 넣었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수식 7 다음부터 계속 (after training...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Unconditional Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Conditional Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sketch Drawing Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Predicting Different Endings of Incomplete Sketches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Applications and Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
