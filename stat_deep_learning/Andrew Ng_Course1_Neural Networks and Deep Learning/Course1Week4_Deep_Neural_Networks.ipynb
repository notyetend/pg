{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coursera  | Andrew Ng's Deep Learning Class | Course1. Neural Networks and Deep Learning | Week4. Deep_Neural_Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1]. Deep Neural Nework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-1]. Deep L-Layer neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로지스틱 회귀모형은 신경망 관점에서 출력 레이어 하나 뿐 이므로 매우 얕은(shallow) 신경망이라 할 수 있다. 여기에 히든 레이어가 추가될 수 있고 깊은 신경망을 구성할 수 있다. 보다 깊은 신경망 모형은 얕은 신경망이 학습하지 못하는 패턴을 학습할 있는 경우가 많다. 신경망의 레이어 수를 셀때는 입력에이어를 제외하고 세는 것이 전통이다. 아래 슬라이드의 우측 하단 레이어의 경우 입력 레이어를 제외하고 히든 레이어가 5개 출력 레이어가 1개인 6레이어 신경망이다.\n",
    "\n",
    "내 데이터를 위한 최적의 히든 레이어 수를 미리 알수는 없다. 최적의 히든 레이어 수를 찾기 위한 최선의 방법은 다양한 경우의 히든 레이어 수를 홀드 아웃 교차검증 데이터(hold-out cross validation set)에 적용해 보고 가장 좋은 성능을 보이는 레이어 수를 선택하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L01_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞으로 딥뉴러넷을 표현하기 위한 표기법을 정리하고 넘어간다.\n",
    "\n",
    "- $L$ : 레이어 수, 아래 슬라이드에서는 4개(입력 레이어는 세지 않는다. 혹은 입력 레이어는 0번째 레이어라 부르고, 출력 레이어는 $L$번째 레이어라 한다.)\n",
    "- $n^{[l]}$ : $l$번째 레이어의 유닛(동그라미)수, 가령 아래 예에서 $n^{[0]}=n_x=3$, $n^{[1]}=5$, $n^{[2]}=5$, $n^{[3]}=3$, $n^{[4]}=n^{[L]}=1$\n",
    "- $n_x$ : 입력 데이터의 변수 수, 혹은 입력 레이어의 유닛 수\n",
    "- $a^{[l]}$ : $l$번째 레이어의 활성값(activation value), $g^{[l]}(z^{[l]})$로 계산된다.\n",
    "- $w^{[l]}$ : $z^{[l]}$ 계산에 사용되는 가중치\n",
    "- $b^{[l]}$ : $z^{[l]}$ 계산에 사용되는 bias항\n",
    "- 입력값 $x$를 0번째 레이어의 활성값이라고 생각할수도 있다. $x=a^{[0]}$\n",
    "- 마지막 레이어(출력 레이어)의 활성값 $a^{[L]}$은 예측값으로 사용되며 $\\hat{y}$로도 표기한다. (일반적으로 예측값에 $\\hat{hat}$을 붙인다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L01_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-2]. Forward Propagation in a Deep Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "히든 레이어가 여럿일 경우 순전파(forward propagation) 과정아래와 같다. 사실 지난주 내용과 큰 차이는 없으며 입력값을 $a^{[0]}$을 표기 했다.\n",
    "$$\\begin{align}\n",
    "&\\textbf{for}\\text{ each samples}\\textbf{ do} \\\\\n",
    "&\\qquad z^{[1]} = W^{[1]}a^{[0]} + b^{[1]} \\\\\n",
    "&\\qquad a^{[1]}=g^{[1]}(z^{[1]}) \\\\\n",
    "&\\qquad z^{[2]} = W^{[2]}a^{[1]} + b^{[2]} \\\\\n",
    "&\\qquad a^{[2]}=g^{[2}(z^{[2]}) \\\\\n",
    "&\\qquad z^{[3]} = W^{[3]}a^{[2]} + b^{[3]} \\\\\n",
    "&\\qquad a^{[3]}=g^{[3}(z^{[3]}) \\\\\n",
    "&\\qquad z^{[4]} = W^{[4]}a^{[3]} + b^{[4]} \\\\\n",
    "&\\qquad a^{[4]}=g^{[4}(z^{[4]}) \\\\\n",
    "&\\textbf{end for}\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "각 샘플에 대한 for-loop를 아래와 같이 벡터화 할 수 있다.     \n",
    "위와 아래의 차이점은 $z^{[l]}$, $a^{[l]}$의 shape은 ($n^{[l]}$, $1$)이고 $Z^{[l]}$, $A^{[l]}$의 shape은 ($n^{[l]}$, $m$)이라는 것이다. $W^{[l]}$와 $b^{[l]}$의 shape은 각각 ($n^{[l]}$, $n^{[l-1]}$)와 ($n^{[l]}$, $1$)으로 변함 없다. 주의할 점은 아래의 벡터화된 버전에서는 $b^{[l]}$를 더할 때 $b^{[l]}$의 shape이 ($n^{[l]}$, $m$)으로 변환(broadcasting)된다는 것이다.\n",
    "$$\\begin{align}\n",
    "& Z^{[1]} = W^{[1]}A^{[0]} + b^{[1]} \\\\\n",
    "& A^{[1]}=g^{[1]}(Z^{[1]}) \\\\\n",
    "& Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]} \\\\\n",
    "& A^{[2]}=g^{[2}(Z^{[2]}) \\\\\n",
    "& Z^{[3]} = W^{[3]}A^{[2]} + b^{[3]} \\\\\n",
    "& A^{[3]}=g^{[3}(Z^{[3]}) \\\\\n",
    "& Z^{[4]} = W^{[4]}A^{[3]} + b^{[4]} \\\\\n",
    "& A^{[4]}=g^{[4}(Z^{[4]}) \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L01_03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-3]. Getting your matrix dimensions right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L02_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L02_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-4]. Why deep representations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L03_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-5]. Building blocks of deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L04_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L04_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-6]. Forward and Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L04_03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L04_04.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L04_05.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-7]. Parameters vs Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L05_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L05_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-8]. What does this have to do with the brain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C1W4L06_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/.PNG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
