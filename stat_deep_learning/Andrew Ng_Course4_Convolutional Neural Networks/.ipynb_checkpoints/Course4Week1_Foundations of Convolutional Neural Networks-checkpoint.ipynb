{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Coursera | Andrew Ng's Deep Learning Class | Course4. | Week1. Foundations of Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1]. Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-1]. Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 딥러닝이 컴퓨터 비전에 아주 큰 영향을 줬다. 또한 컴퓨터 비전 분야에서 딥러닝 방법론과 관련한 매우 다양한 아이디어들이 나오고 있다. 네가 하려는 분야가 컴퓨터 비전이 아니더라도 컴퓨터비전&딥러닝에서 등장한 여러 방법에서 좋은 아이디어를 얻을 수 있다.\n",
    "\n",
    "- 컴퓨터 비전 문제는 크게 Image Classification(이미지가 고양이인가 아닌가), Object detection(이미지에 자동차가 어디에 있는가?), Neural Style Transfer(그림을 피카소 스타일로 바꾸기)의 3가지로 나눌 수 있다. \n",
    "\n",
    "- 컴퓨터 비전 문제의 가장 큰 난관은 입력 feature의 수가 매우 많다는 것이다. 컬러 이미지라면 가로 픽셀 x 세로 픽셀 x 3개의 입력이 있다. 이걸 그대로 순전파 네트워크에 사용한다면 모형의 weight이 아주 아주 많을 것이고, 이런 모형의 과적합을 피하려면 정말 더 많은 데이터가 필요하다. 이를 해결할 수 있는 방법이 convolution operation이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-2]. Edge Detection Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convolution operation이란? 윈도우 같은 역할을 할 필터(=커널)을 만들고, 이미지의 모든 영역을 윈도우가 이동하면서 convolution 연산 결과를 다음 레이어의 값으로 이용한다.\n",
    "- tensorflow에서는 tf.nn.conv2d 함수를, Keras에서는 Conv2D 함수를 convolution을 위한 함수로 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 1,  0, -1],\n",
       "       [ 1,  0, -1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv_filter_vert = np.array([[1, 0, -1], [1, 0, -1], [1, 0, -1]])\n",
    "conv_filter_vert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위와 같은 형태의 3x3 행렬을 필터로 사용하면 이미지의 세로 경계를 찾아준다. 즉 원본 이미지에 가로 방향의 변화가 있을 경우 그 부분을 부각시킨다.\n",
    "\n",
    "- 반면 아래와 같은 필터를 사용하면 이미지의 가로 경계 측 세로 방향의 변화가 있는 부분을 부각시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  1,  1],\n",
       "       [ 0,  0,  0],\n",
       "       [-1, -1, -1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "conv_filter_hori = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]])\n",
    "conv_filter_hori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-3]. More Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컴퓨터 비전에서 연구된 다양한 종류의 필터가 있다. 아래 소벨 필터와 샤 필터와 같은 것들이 있으며 각기 다른 특성을 갖는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, -1],\n",
       "       [ 2,  0, -2],\n",
       "       [ 1,  0, -1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sobel filter\n",
    "np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3,   0,  -3],\n",
       "       [ 10,   0, -10],\n",
       "       [  3,   0,  -3]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scharr filter\n",
    "np.array([[3, 0, -3], [10, 0, -10], [3, 0, -3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그런데 딥러닝을 접목한 컴퓨터 비전에서는 필터의 각 픽셀값을 학습해야할 파라미터로 정의하고 좋은 값을 학습하도록 만든다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 원본 이미지의 가로 세로 픽셀 수가 $n$이고, 필터의 가로 세로 픽셀 수가 $f$라면 출력 이미지의 크기는 $(n-f+1) \\times (n-f+1)$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-4]. Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞서의 convolution operation을 그대로 적용하면 이미지의 경계 점들이 약하게 인지되는 문제점이 있다. (예를들어 이미지의 가운데 점은 필터가 여러번 지나가는데 비해 경계점은 상대적으로 필터의 이동 경로에 덜 포함된다.)\n",
    "- 이를 보완하기 위해 이미지의 경계 밖으로 빈 픽셀을 배치하는 방법을 사용한다.\n",
    "- Padding의 크기는 몇으로 해야할까?\n",
    " - 패딩의 크기가 $p$라면 출력 이미지의 크기는 $(n+2p-f+1) \\times (n+2p-f+1)$ 이다.\n",
    " - 만약 입력이미지와 출력이미지의 크기를 같게 해야한다면 $n+2p-f+1 = n$이므로, 이때 padding의 크기는 $p=\\frac{f-1}{2}$이다. (2로 나눠야 하기 때문에 혹은 필터의 중심을 표현하기 용이하므로 padding의 크기는 보통 홀수를 사용한다.)\n",
    " \n",
    "- Padding을 얼마나 주느냐는 크게 두가지 선택으로 나뉜다. \n",
    " - Valid convolution은 padding을 주지 않는 것이다.\n",
    " - Same convolution은 입력과 출력 이미지의 크기가 같아지도록 padding을 주는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-5]. Strided Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 필터를 이동할 때 몇칸식 이동하느냐를 stride라 표현한다. 한칸식 이동한다면 stride는 1이고 $s$칸식 이동한다면 stride는 $s$이다.\n",
    "- 이미지 크기 $n$, 필터 크기 $f$, 패딩 $p$, 스트라이드 $s$일 때 출력이미지의 크기는 $(\\frac{n+2p-f}{s}+1) \\times (\\frac{n+2p-f}{s}+1)$이다.\n",
    "- 만약 위와 같이 계산한 출력 이미지 크기가 정수가 아니라면 나머지 버림하여 $\\lfloor\\frac{n+2p-f}{s}+1\\rfloor \\times \\lfloor\\frac{n+2p-f}{s}+1\\rfloor$을 출력 이미지 크기로 한다. 즉 필터가 일부만 겹쳐 계산된 값은 사용하지 않는 것이다.\n",
    "- 엄밀히 말하면 딥러닝에서 말하는 convolution은 cross-correlation을 구하는 것이다. 엄밀한 convolution이 되기 위해서는 필터를 상하좌우로 뒤집는 과정이 선행되어야 한다. (하지만 딥러닝에서는 뒤집기 없는 이 연산을 그냥 convolution이라 한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-6]. Convolutions Over Volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 컬러이미지는 R B G 3개의 채널이 있으므로 convolution을 위한 필터 또한 3개의 층으로 구성되어야 한다. (즉 원본 이미지의 채널 수와 필터의 채널수는 같아야 한다. 채널 수를 depth라 부르기도 한다.)\n",
    "- 예를들어 6x6 크기의 컬러이미지는 6x6x3의 데이터이고, 필터는 3x3x3을 사용한다면 출력의 크기는 4x4이다.\n",
    "- 이미지의 다양한 패턴을 동시에 잡아내기 위해 여러개의 필터를 동시에 사용할 수 있다. 예를들어 3x3x3의 필터를 $k$개 사용할 수 있고, 이 경우 출력의 크기는 4x4x$k$ 가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-7]. One Layer of a Convolutional Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolutional network의 1개 층은 아래와 같이 구성된다.\n",
    " 1. 이전 레이어의 출력값에 $i \\in K$번째 필터를 이용해 convolution 출력값을 구하고, 여기에 bias를 더한 후 activation 함수를 통과 시킨다.\n",
    " 2. 전체 $K$개 필터에 대해 위 과정을 반복한다.\n",
    " \n",
    "- 사실 위 과정은 (convolution을 사용하지 않는) 일반적인 신경망과 유사한 부분이 많다. convolution 연산을 하는 부분은 이전 레이어의 출력값 $A^{[l-1]}$에 $l$번째 레이어의 weight $W^{[l]}$을 곱하는 것과 같고, bias를 더하고 activation 함수를 통과시켜서 $l$번째 레이어의 출력값을 구하는 것은 $A^{[l]} = \\sigma(W^{[l]} A^{[l-1]} + b^{[l]})$와 같다.\n",
    "\n",
    "- 예를들어 3x3x3크기의 필터를 10개 사용한다면 총 몇개의 파라미터가 필요한가? 우선 필터하나만 생각하면 3x3x3=27개의 파라미터와 bias를 위한 1개 파라미터가 필요하므로 28개 파라미터가 필요하고, 총 10개 필터가 있으므로 총 280개 파라미터가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $l$번째 convolution layer에 대한 표기법\n",
    " - filter size: $f^{[l]}$\n",
    " - padding: $p^{[l]}$\n",
    " - stride: $s^{[l]}$\n",
    " - number of filters: $n_c^{[l]}$\n",
    " ---\n",
    " - Input shape: $n_H^{[l-1]} \\times n_W^{[l-1]} \\times n_c^{[l-1]}$, ※ H:Height, W:Width\n",
    " - Output shape: $n_H^{[l]} \\times n_W^{[l]} \\times n_c^{[l]}$\n",
    " ---\n",
    " - Each filter size: $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]}$\n",
    " - Activations : $a^{[l]} \\rightarrow n_H^{[l]} \\times n_W^{[l]} \\times n_c^{[l]}$ \n",
    " - Activations vectorized : $A^{[l]} \\rightarrow m \\times n_H^{[l]} \\times n_W^{[l]} \\times n_c^{[l]}$ \n",
    " - Weights : $f^{[l]} \\times f^{[l]} \\times n_c^{[l-1]} \\times n_c^{[l]}$\n",
    " - bias : $n_c^{[l]}$,   ※ shape이 (1, 1, 1, $n_c^{[l]}$)인 행렬로 정의해 사용 \n",
    " \n",
    " \n",
    "- 주목할 점\n",
    " - $l$번째 레이어 필터의 채널수는 $l-1$번째 레이어 출력값의 채널수와 같다\n",
    " - $l$번째 레이어 필터의 수는 $l$번째 레이어 출력값의 채널수와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-8]. Simple Convolutional Network Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-9]. Pooling Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-10]. CNN Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-11]. Why Convolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
