{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera의 Neural Networks for Machine Learning 강의를 정리한 내용임.   \n",
    "2016.12.05. by Dongwan Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week9. Ways to make neural networks generalize better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작하기 전에 몇가지 용어에 대해서 알아보자. \n",
    "- generalization: training data로 학습한 모델이 training data가 아닌 다른 데이터에 대해서도 좋은 예측 성능을 보이는지에 관한 지표로서 generalization이 좋은 모델은 새로운 데이터에 대해서도 좋은 성능을 보인다. 반대의 경우 generalizatio이 좋지 않다고 말 하거나, training data에는 아주 잘 들어맞으나 다른 데이터에는 잘 적용되지 않는 경우 overfitting이 발생했다고 말한다.\n",
    "\n",
    "- capacity: 예를들어 sigmoid unit들로 구성된 최소한 하나 이상의 hidden layer가 있는 Neural network를 이용하여, 어떤 연속함수라도 근사할 수 있다. 이 말은 내가 담고자 하는 모든 정보를 이 neural network에 담을 수 있다는 뜻이다. 즉 이 neural network는 내가 모델링하고자 하는 대상에 대해 충분한 capacity를 갖는다는 것이다. capacity를 결정하는 것은 hidden unit의 수 인데, 무작정 이것을 늘린다면 capacity가 커 질 것이다. 하지만 너무 커질 경우 overfitting이 발생하게 된다. 따라서 적당한 capacity를 갖는 hidden unit의 수를 결정하는 것이 중요하다.\n",
    "\n",
    "- flexibility of model: 모델의 유연성, 직선과 곡선을 예로 들면 직선은 not flexible한 모델이고 곡선은 flexible한 모델이라 할 수 있다. 모델이 너무 flexible하다면 training data에 아주 잘 들어 맞아서 overfiting이 발생할 가능성이 커진다. 이럴 경우 generalization이 잘 되지 않을 것이다.(즉 training data이외의 데이터에는 잘 들어맞지 않을 것이다.)\n",
    "\n",
    "이 챕터에서는 network가 너무 큰 capacity를 갖을 때 overfitting을 줄이는 방법에 대해서 배워볼 것이다. 또한 capacity를 조절하는 다양한 방법에 대해서도 배워볼 것이다. 또한 capacity를 조절할 때 다양한 파라미터가 사용되는데 이들 파라미터(metric parameters)를 결정하는 방법에 대해서도 알아볼 것이다. 마지막으로 capacity를 조절하는 방법으로 학습을 조기에 멈추는 기법(stopping the learning early)에 대해서도 알아볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9a, Overview of ways to improve generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Overfitting</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 overfitting이 발생하는 원인에 대해서 생각해 보자.     \n",
    "\n",
    "training data를 이용한 model을 학습시키는데, 이 training data에는 모집단(혹은 어떤 실체)을 잘 표현하는 데이터 뿐만 아니라 어떤 편향(bias) 혹은 측정오류(sampling error)가 포함되어 있을 수 있다.    \n",
    "\n",
    "따라서 training data에 정말 잘 맞도록 모델을 학습시킨다 하더라도 이런 sampling error때문에, training data가 아닌 다른 데이터에는 이 모델이 잘 맞지 않을 수도 있다.   \n",
    "\n",
    "다른 관점에서 보면, training data에는 모집단을 잘 표현하는 규칙(good regularity)과 sampling error를 표현하는 규칙(bad regularity)이 공존한다는 것이다. 따라서 어떤 모델이 규칙을 학습했다 했면, 그 규칙속에는 good regularity와 bad regularity가 모두 포함되어 있다는 것이다. 따라서 training data에 정말 잘 들어맞는 모델이 다른 데이터에는 잘 들어맞지 않을 수도 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Preventing overfitting</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting을 줄이기 위한 방법으로는 \n",
    "- 더 많은 데이터를 확보\n",
    "- 적당한 capacity를 갖는 모델을 사용\n",
    "- 다른 여러 모델들을 평균, Model averaging(bagging: 여러 모델의 예측값의 평균을 사용하는 등의 방법)\n",
    "- Bayesian접근법을 사용 - weight의 분포를 구한 후 이 weight 분포에서 뽑은 weight을 사용하여 예측을 하고 그 예측값들의 평균을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Some ways to linit the capacity of a neural net</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN의 capacity를 제한하는 여러 방법들이 있음\n",
    "- 뉴러넷의 구조를 변경: hidden layer나 hidden layer내의 unit의 수를 컨트롤\n",
    "- early stopping: overfitting하기 전에 learning을 stop, 그런데 과연 언제 멈춰야 할지가 문제임.\n",
    "- weight-decay: weight이 지나치게 커지는 것을 제한하는 방법으로 weight의 제곱값을 constraint로 주는 L2 penalty와 weight의 절대값을 constranint로 주는 L1 penalty가 있음\n",
    "- weight 이나 activity에 noise를 주는 방법   \n",
    "\n",
    "보통 위의 방법들을 결합하여 사용함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>How to choose meta parameters that control capacity</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 모형의 weight을 제외한 (num of hidden layers, num of units in hidde layer) 여러 파라미터 값을 meta parameter라 함. 이런 파라미터를 조절하기 위해서 여러 값으로 시도해 보고 test set에 가장 성능이 좋은 파라미터 값을 고르기도 하는데, 이는 매주 좋지 않은 방법이다. test set이외의 데이터에는 잘 맞지 않을 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Cross-validation: A better way to choose meta parameters</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 데이터를 **training data, validation data, test data**의 3 그룹으로 나눈다. 우선 meta parameter들을 어떤 값($\\mathbf{p}_1$)으로 정하고 이 모델을 training data에 fitting 시킨다. 그러면 어떤 cost값 $E_{t1}$가 나오고, 이 모델로 validation data에 대한 cost를 구한다. 당연히 training data에 대한 예측을 할 때보다 큰 어떤 cost값 $E_{v1}$가 나올 것이다. 이제 meta parameter를 조금 변화시킨 후($\\mathbf{p}_2$) 다시 training data에 fitting시키고 training data와 validation data에 대한 cost를 각각 구한다. ($E_{t2}, E_{v2}$). 이런 과정을 어느정도 반복하여 $E_{vi}$가 최소가 되는 지점의 $\\mathbf{p}_i$를 최종의 meta parameter로 선택한다. 마지막으로 test data에 대한 여러 예측 성능 지표들을 구해서 이 모형의 일반적인 성능을 평가하게 된다.\n",
    "\n",
    "그런데 validation data는 training 과정에 포함되지 않으므로 데이터가 많이 않을 경우 편향된 학습 결과가 나올 수 있다. 이런 경우 N-fold cross-validation이란걸 사용하는 것이 좋을 수 있다. 이 방법에서는 training data + validation data를 $n$개의 동일 크기 그룹으로 나눈다. 각 그룹을 fold라 부르고 각각 $fold_1, fold_2, fold_3, \\cdots , fold_n$이라 하자.     \n",
    "우선 $fold_1$을 제외한 $n-1$개의 fold들을 training data로 이용하고 $fold_1$을 validation data로 사용하여 최적의 모형을 구하게 된다.    \n",
    "이번에는 $fold_2$를 제외한 $n-1$개의 fold들을 training data로 이용하고 $fold_1$을 validation data로 사용하여 최적의 모형을 구한다.    \n",
    "이렇게 한 fold를 제외하는 방법은 총 $n$가지이고, $n$가지의 좋은 모형을 구하게 된다. 이들 모형의 예측값을 averaging하거나 모형 파라미터를 averaging하여 최종의 더더욱 좋은 예측값을 얻을수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Preventing overfitting by early stopping</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "overfitting을 막기 위해, 작은 weight들로 training을 시작해서 일정 주기마다 validation set에 대한 error를 측정한다. 학습을 진행하다가 validation set에 대한 error가 증가하면 학습을 멈춘다. 그런데 squared error나 cross-entropy error를 사용하지 않고 단순히 error rate을 사용할 경우 특히 validation set에 대한 지표가 출렁일 수 있는데 이런 경우 error의 증가가 정말 계속될 것인지 혹은 증가 후 다시 많이 떨어질지는 알 수 없는 문제가 있다. 즉 언제 멈춰야 할지 확실하지 않다. 물론 좀더 학습을 진행한 후 지표가 좋았던 지점으로 돌아오는 방법을 사용하면 된다. 또한 이렇게 할 경우 model capacity가 제한되게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why early stopping works</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "early stopping이 동작하는 이유를 생각해보면, 예를들어 hidden layer의 unit들이 logictis function일 경우 weight들이 작을 때에는 logistic function의 linear한 부분에서 output 값을 내놓기 때문에, 이들은 model capacity의 변화에 큰 영향을 주지 않는다. 반면 weight이 커질 경우 logistic function의 non-linear한 부분을 지나기 때문에 model capacity가 커지게 된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9b, Limiting the size of the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 weight의 크기를 조절하여 capacity를 조절하는 방법에 대해서 알아본다. 일반적인 방법은 weight들이 커지면 그 크기가 커지는 'penalty term'을 cost function에 추가하는 것이다. 여기에서 기본적인 가정은 weight이 작을 수록 네트워크의 capacity가 작다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Limiting the size of the weights</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2 weight penalty**: weight의 제곱에 비례하는 penalty를 사용하는 방법인데, 이 penalty term의 미분항이 마치 weight을 0으로 유도하는 작용을 하기 때문에 neural network쪽에서는 **weight decay**라고 부르기도 한다.       \n",
    "$$C = E + \\frac{\\lambda}{2} \\sum_i w_i^2$$\n",
    "위와 같이 penalty term($\\frac{\\lambda}{2} \\sum_i w_i^2$)에 lambda($\\lambda$) 가 사용되는데 이를 weight cost라 부르고 이 값에 따라 weight에 얼마나 큰 penalty를 부여할지가 결정된다. ($\\lambda$가 크다면 전체 $C$값을 최소화 하기 위해서는 weight들이 더 작아질 것이고, $\\lambda$가 작다면 그 반대가 될 것이다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식을 미분하고 $C$가 최소가 될때 $w_i$에 대해 풀어보면 $\\frac{\\partial E}{\\partial w_i}$가 크거나 $\\lambda$가 작을때 $w_i$의 크기가 커진다는 것을 알 수 있다.\n",
    "$$\\frac{\\partial C}{\\partial w_i} = \\frac{\\partial E}{\\partial w_i} + \\lambda w_i$$\n",
    "$$when ~~ \\frac{\\partial C}{\\partial w_i} = 0, ~~ w_i = - \\frac{1}{\\lambda} \\frac{\\partial E}{\\partial w_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The effect of L2 weight cost</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**L2 weight penalty**를 사용했을 때 input에 대한 output은 기존과 어떻게 달라지게 될까? L2 weight penalty를 사용할 경우 weight이 클수록 penalty가 커지므로 크기가 큰 weight들은 거의 남지 않게 된다. 또한 많은 weight들이 0에 가까운 값을 갖게 된다. 결과적으로 예측 성능에 도움이 되지 않는 weight들은 0에 가까운 값으로 바뀌게 된다. 그 결과 model의 generalization이 나아지는 효과가 있다. 또한 input 증가에 따른 output의 변화가 좀더 둔하게 변하게 된다. 또한 squared weight을 penalty로 사용하므로 동일한 input이 들어가는 두개의 weight이 있을 때 ($w$, $0$)보다는 ($w/2$, $w/2$)가 선택된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_effect_of_l2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Other kinds of weight penalty</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 소개한 squared weight을 penalty로 사용하는 L2 weight penalty외에도 다양한 형태의 weight penalty가 있다. 대표적으로 sum of absolute value of weight을 penalty로 사용하는 **L1 weight penalty**가 있는데 weight의 크기에 비례하는 penalty를 부여한다. 이 경우 많은 weight들을 0으로 만들어버리는 효과가 있다. 다만 L2 weight penalty를 사용할 경우 큰 weight들이 사라지는 효과를 갖지만 L1 weight penalty의 경우 크기가 큰 weight들이 어느정도 살아남게 된다.(아래 그래프를 뒤집어 놓은 모양이 weight의 분포라고 생각하면 이해하기 쉬워짐)\n",
    "\n",
    "이밖에도 아래 그림과 같이 큰 weight에 대해 서는 좀더 너그러운 penalty를 주는 방법도 있다. 이 경우 아주 작은 weight들을 줄어들고 아주 큰 weight들은 살아남을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_weight_penalty2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Weight penelties vs weight constraints</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 L2 weight penalty를 다뤘었는데 이는 각각의 weight값 제곱에 비례하는 만큼의 벌금(penalty)을 부과하겠다는 아이디어(**weight penalty**)이다.     \n",
    "이와 다른 아이디어(**weight constraint**)로 각 unit에 들어오는 weight vector의 길이를 어느정도로 제한(constraint)하는 아이디어가 있다. 만약 input weight vector의 길이가 constraint(maximum squared length)를 초과한다면 weight vector를 정해진 length로 scale down하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9c, Using noise as a regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 overfitting을 해결하기 위해 weight penalty와 같은 regularization term을 사용하여 model capacity를 줄이는 방법에 대해 알아봤었다. 이번에는 random noise를 사용하여 regularization하는 방법에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>L2 weight-decay via noisy inputs</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**noisy input**방법에서는 각 unit의 input에 평균이 0이고 분산이 $\\sigma_i^2$인 정규분포에서 뽑은 어떤 값을 더하여 입력한다. 또한 이 분포의 분산은 다음 layer에서는 unit간 weight 값 만큼 증폭되어 noise의 분포가 바뀌게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_gaussian_noise.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 noise는 squared error에는 additive contribution을 하게 되는데, noisy input을 넣은 모형의 squared error를 최소화 하는 결은 결국 squared weight penalty를 넣은 모형을 최소화하는 것과 같다. 왜 그러한지 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림에서는 noise term하나만을 나타냈으나 hidden layer $L_i$에 $m$개의 unit이 있다면 output layer $L_j$의 특정 unit에는 $m$개의 noisy input이 들어올 것이다. 만약 output layer의 unit이 단순히 linear function이라면 output value $y^{noisy}$를 아래와 같이 표현할 수 있다. ($\\epsilon_{i} \\sim N(0, \\sigma_{i}^2)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "y^{noisy} &= \\sum_i^m w_i x_i + \\sum_i^m w_i \\epsilon_i \\\\\n",
    "&=y + \\sum_i^m w_i \\epsilon_i\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "squared error의 expected value를 구해보자.($\\epsilon_i$만이 random variable이고, $E[X^2] = V[X] + (E[X])^2$이므로 $X \\sim N(\\mu, \\sigma^2)$ 일때 $E[\\epsilon^2] = \\sigma^2$이고, 각각 $\\epsilon_i$들이 independent임))\n",
    "\n",
    "$$\\begin{align}\n",
    "E \\left[ (y^{noisy} - t)^2\\right] &= E \\left[ \\left(y + \\sum_i^m w_i \\epsilon_i - t \\right)^2\\right] \\\\\n",
    "&= E \\left[ \\left( (y-t) + \\sum_i^m w_i \\epsilon_i \\right)^2\\right] \\\\\n",
    "&= (y-t)^2 + E \\left[ 2(y-t) \\sum_i w_i \\epsilon_i \\right] + E \\left[ \\left( \\sum_i w_i \\epsilon_i \\right)^2 \\right]\\\\\n",
    "&= (y-t)^2 + E \\left[ \\sum_i w_i^2 \\epsilon_i^2 \\right] \\\\\n",
    "&= (y-t)^2 + \\sum_i w_i^2 \\sigma_i^2 \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 식을 보면 결국 normal error term에 squared error penelty를 더한 형태이므로 앞서 봤던 L2 penalty와 동일하다는 것을 확인할 수 있다. ($\\sigma^2 = \\frac{\\lambda}{2}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Noisy weights in more complex nets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 noise를 input에 넣는 방법을 사용했었는데, noise를 input이 아니라 weight자체에 주는 방법도 생각해볼 수 있다. 이렇게 하면 앞서의 L2 weight penalty와 정확히 같지는 않지만 recurrent net과 같이 보다 많은 hidden layer를 포함하고 non-linear unit을 사용하는 경우 매우 효과적일 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Using noise in the activities as a regularizer</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "noise를 input도 weight도 아닌, unit activitiy에 주는 방법도 생각해볼 수 있다. 기존에 input이 unit의 activation function에 들어가 정해진 출력값을 내놓는 것과 달리 activation function이 어떤 확률 값을 계산하고 그 확률 분포에서 output을 sampling해서 내놓는 방법을 사용한다. 예를들어 logistic unit을 사용하는 경우 이 unit의 계산된 값이 결국 0과 1사이의 값이고 이를 1을 출력할 확률로 생각하는 것이다. 이 binary distribution에서 1 혹은 0을 뽑아 unit의 출력값으로 내놓는 것이다. 대신 back propagation을 할 때에는 1이나 0을 unit output으로 사용하는 것이 아니라 앞서 계산 했던 확률 값을 output으로 보고 error derivative를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_noisy_activation.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9d, Introduction to the full Bayesian approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The Bayesian framework</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "철수와 영희가 창이 없는 방 안에서 밖에 비가 왔을지 오지 않았을지에 대해 생각하고 있다.        \n",
    "\n",
    "철수는 자연의 섭리에 의해 밖에 비가 왔거나 오지 않았거나 하는 것이 정해져 있고, 문을 열고 나갔을 때 비가 왔다는 것을 뒷받침 하는 증거 혹은 그렇지 않은 증거들을 관측하게될 것이라고 생각한다. 만약 비가 왔다면 비가 왔다는 사실을 뒷받침하는 증거들을 더 많이 관측하게 될 것이다.    \n",
    "\n",
    "반면 영희는 생각이 좀 다르다. 비가 오거나 오지 않았다는 것은 정해진 사실이 아니라 기존의 정보와 현재 획득한 증거에 따라 비가 왔을 가능성이 클수도 있고 그렇지 않을수도 있다는 것이다. 또한 추가적인 정보를 획득함에 따라 비가 왔을 가능성은 달라진다는 것이다. \n",
    "\n",
    "철수와 영희가 문을 열고 방 밖으로 나갔는데, 문 앞 길기 조금 졎어 있는 것을 발견한다. 이에 대해 철수는 비가 분명히 왔을 것이고 비가 왔을 때 흔히 발생할 수 있는 증거중 하나가 발견되었다고 말한다. 반면 영희는 비가 왔을지 안 왔을지는 모르는 사실이고 어제 비가 왔었다는 사실과 방금 본 길이 졎어 있다는 사실을 통해 오늘도 비가 왔을 가능성이 조금 더 커졌다고 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서의 예에서 철수는 Frequentist에 반면 영희는 Bayesian에 가깝다고 할 수 있다. 즉 모수(비가 왔을 확률)은 정해져 있고 그에 따른 증거들의 확률 분포를 생각하는 것이 Frequentist적 생각이라면, 모수는 정해져 있지 않고 사전 지식과 관측한 증거에 따라 모수의 분포가 달라진다는 접근이 Bayesian적 접근이라 할 수 있다. 즉 Frequentist적 접근 방법에서는 정해진 모수에 따른 증거들의 확률 분포를 생각한다면 Bayesian적 접근 방법에서는 증거에 따른 모수의 확률 분포를 생각한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian 접근법에서는 어떤 사전 지식에 대한 확률을 prior probability라 하고, 사전 정보가 사실일 때 관측된 정보가 사실일 확률을 likelihood라고 한다. 이 두 확률을 결합하여 관측된 정보가 주어졌을 때 사전 지식이 사실일 확률, 즉 posterior probability를 구하게 된다. 이 posterior probability는 이후 단계의 prior probability가 되고 새로운 데이터를 획득하면 새로운 posterior probability를 구하는 과정을 반복하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Bayes Theorem</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p(W|D) = \\frac{p(D|W) ~ p(W)}{p(D)} \\\\\n",
    "p(D) = \\int_W p(W)p(D|W)$$\n",
    "\n",
    "- $p(w)$: prior probability of weight vector $W$\n",
    "- $p(D|W)$: probability of observed data given $W$\n",
    "- $p(W|D)$: posterior probability of weight vector $W$ given training data $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A coin tossing example</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동전 던지기 예를 통해 prior probability distribution, likelihood function, posterior probability distribution의 관계에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "biased or unfair coin, 즉 앞면이 나올 확률은 $p$이고 뒷면이 나올 확률은 $1-p$로서, 동전의 앞 뒤가 같은 확률로 나오지 않을 수 있는 동전을 생각해 보자. 앞면이 $h$번, 뒷면이 $t$번 나왔다면 동전의 앞면이 나올 확률은 얼마일까? 예를들어 이 동전을 100번 던저 53번 앞면이 나왔다면 $p$는 얼마일까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Frequentist**적 접근 방법에 의하면,       \n",
    "앞면이 나올 확률 $p$에 대한 최량 추정량(best estimator)는 $r = \\frac{h}{h + t}$이다.     \n",
    "따라서 이 질문에 대한 Frequentist 혹은 Likelihoodist적 답변은 $p=0.53$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면 **Bayesian**적 접근 방법에 의하면,    \n",
    "우선 $p$에 대한 사전 정보가 없다고 하자. 이 경우 사전분포는 uniform distribution을 사용하여 $g(p) = 1$이다.\n",
    "또한 likelihood function은 아래와 같다.\n",
    "$$f(H=h|r, N = h + t) = {N \\choose h} r^h (1-r)^t$$\n",
    "Bayes Theorem에 대입하면 아래와 같은 posterior distribution을 구할 수 있다.\n",
    "$$\n",
    "\\begin{align}\n",
    "f(r|H=h, T=t) &= \\frac{{N \\choose r} r^h (1-r)^t}{\\int_0^1 {N \\choose h} p^h (1-p)^t ~ dp} \\\\\n",
    "&= \\frac{r^h (1-r)^t}{\\int_0^1 p^h (1-p)t ~ dp} \\\\\n",
    "&= \\frac{1}{\\mathbf{B}(h+1, t+1)} r^h (1-r)^t \\\\\n",
    "&= \\frac{(h+t+1)!}{h! t!} r^h (1-r)^t\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 앞면이 53번이 나오는 경우, p에 대한 확률 분포는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f(p ~ | ~ H=53, T=47) = \\frac{(h + t + 1)!}{h! t!} p^{53} (1-p)^{47}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그림으로 그려보면 아래와 같은데.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAFkCAYAAADBklkAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQf4/ld2Mt76/uPwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x296ad736b00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting binomial distribution with success probability p with h times of success.\n",
    "def get_p_binomial(p, h, t):\n",
    "    return factorial(h + t + 1) / (factorial(h) * factorial(t)) * np.power(p, h) * np.power(1 - p, t)\n",
    "\n",
    "def get_deri_binomial(p, h, t):\n",
    "    return factorial(h + t + 1) / (factorial(h) * factorial(t)) * (h/p - t/(1-p)) * (np.power(p, h) * np.power(1-p, t))\n",
    "# plot\n",
    "import numpy as np\n",
    "from math import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0.3, 0.8, 100)\n",
    "y = [get_p_binomial(p, 53, 47) for p in x]\n",
    "#d = [get_deri_binomial(p, 53, 47) for p in x]\n",
    "plt.plot(x, y);\n",
    "#plt.plot(x, d);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.5보다 조금 큰 어딘가? 에서 가장 확률값이 높은 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f(p ~ | ~ H=53, T=47)$가 최대가 되는 $p$값을 찾아보면\n",
    "$$\\begin{align}\\frac{d f(p ~ | ~ H=53, T=47)}{dp} &= \\frac{(h + t + 1)!}{h! t!} \\left(\\frac{53}{p} - \\frac{47}{1-p} \\right) p^{53} (1-p)^{47} \\\\\n",
    "&= 0 ~ ~ if p=0.53\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 참고: https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Some problems with picking the parameters that are most likely to generate the data</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 앞서 Frequentist적 접근 방법은 trial을 무한번 반복할 수 있다는 가정이 내포되어 있다. 즉 trial 수가 지나치게 낮게 제한된다면 정확한 확률을 구할 수 없다. 예를들어 동전을 한번 던저 앞면이 나왔다고 해서 $p=1$이라고 할수는 없다는 것이다. 따라서 주어진 데이터를 이용해 어떤 하나의 값을 정답으로 사용하는 것 보다는 정답에 대한 불확실성을 포함한 표현을 사용하는 것이 더 나을 수 있다는 것이다. Bayesian 접근법에서는 불확실성을 포함하는 표현으로 모수($p$)에 대한 posterior distribution을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Using a distribution over parameter values</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 코드에서 h와 t를 증가시켜보면 사후 분포가 점차 볼록한 곡선으로 바뀜을 관찰할 수 있는데... 각각 $t+1$ 번째 trial의 likelihood function에 $t$번째 trial까지의 posterior distribution을 $t+1$번째 trial의 prior distribution으로 사용하여 둘을 곱한 형태가 $t+1$번째 trial의 posterior distribution으로 나오고 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAFkCAYAAAC0KZhSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npBEMB5IkaYT/D6AdwtAHhd5hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a8eecb240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:99, t:101\n"
     ]
    }
   ],
   "source": [
    "# Ploting binomial distribution with success probability p with h times of success.\n",
    "import numpy as np\n",
    "from math import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import comb\n",
    "\n",
    "def get_p_binomial(p, h, t):\n",
    "    return factorial(h + t + 1) / (factorial(h) * factorial(t)) * np.power(p, h) * np.power(1 - p, t)\n",
    "\n",
    "def get_p_likelihood(p, h, t):\n",
    "    return comb(h+t, h) * (np.power(p, h) * np.power(1-p, t))\n",
    "\n",
    "h = 99\n",
    "t = 101\n",
    "x = np.linspace(0, 1, 100)\n",
    "y = [get_p_binomial(p, h, t) for p in x]\n",
    "#d = [get_deri_binomial(p, 53, 47) for p in x]\n",
    "plt.plot(x, y);\n",
    "#plt.plot(x, d);\n",
    "plt.show()\n",
    "print('h:{}, t:{}'.format(h, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9e, The Bayesian interpretation of weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight penalty에 대한 Bayesian 관점에서 살펴보자. 사실 pure Bayesian 접근법을 사용한다면 모든 parameter에 대한 posterior distribution을 구해야 하겠으나, 단순히 prior distribution(belief)과 given data에 최적으로 맞는 한쌍의 parameter를 구할수도 있을 것이다. 이렇게 전체 분포가 아니라 가장 높은 Posterior probability를 갖는 한쌍의 parameter를 찾는 방법을 **Maximum A Posteriori** estimation이라 한다.(줄여서 MAP라 함)      \n",
    "model capacity를 control하기 위해 weight decay를 사용하는데, 이 과정을 Bayesian 접근법, 특히 MAP를 통해 살펴보면 실제 어떤 일들이 일어나는지 이해하기 쉬워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Supervised Maximum Likelihood Learning</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*squared error(redidual)의 합을 최소로 하는 weight vector를 구하는 것은 결국 log probability density를 최대로 하는 weight vector를 구하는 것과 같다?*      \n",
    "이게 무슨 의미인지 살펴보자.   \n",
    "(이 논의에서는 network의 output이 $y_c$일때, correct answer $t$는 $y_c$에 noise $\\epsilon \\sim N(0, \\sigma^2)$를 더한 값이라 가정한다.)\n",
    "\n",
    "아래 그림과 같이 network가 $y$라고 예측했을 때, 정답은 $y$에서 조금 혹은 많이 떨어진 어떤 값 $t$라는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_normal.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 $y_c$가 주어졌을 때 $t_c$의 확률분포는 아래와 같이 평균이 $y_c$이고 분산이 $\\sigma^2$인 정규 분포가 된다.\n",
    "\n",
    "$$p(t_c | y_c) = \\frac{1}{\\sqrt{2 \\pi}\\sigma} e^{- \\frac{(t_c - y_c)^2}{2 \\sigma^2}}$$\n",
    "\n",
    "여기에 $-log$를 취하면 아래와 같은데, log 함수는 단조증가(monotonically increasing)하므로 위 식을 최대화 하는 $W$를 구하는 것과 아래 식을 최소화 하는 $W$를 구하는 것은 결국 같다.\n",
    "\n",
    "$$\\begin{align}\n",
    "-log~p(t_c | y_c) &= k + \\frac{(t_c - y_c)^2}{2 \\sigma^2} \\\\\n",
    "k &= -log \\left( \\frac{1}{\\sqrt{2 \\pi}\\sigma}\\right)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 위 식을 보면 결국 $\\frac{(t_c - y_c)^2}{2 \\sigma^2}$를 최소화 하는 것인데 이는 squared error이다. \n",
    "즉 **squared error(redidual)의 합을 최소로 하는 weight vector를 구하는 것은 결국 log probability density를 최대로 하는 weight vector를 구하는 것과 같다**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why we maximize sums of log probabilities</u>, $p(D|W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight vector $W$가 주어졌을 때, 어떤 데이터가 나올 확률을 구해보자. $c$번째 sample이 나올 확률은 p(t_c | W)이고, 각 sample이 독립일 때 전체 sample data가 나올 확률은 아래와 같다. \n",
    "$$p(D|W) = \\prod_c p(t_c | W) = \\prod_c p(t_c | f(input_c, W))$$\n",
    "\n",
    "그런데 $c$개의 확률을 곱하게 되므로 연산 속도와 소수점 이하의 값들이 사라지는 문제 때문에 아래와 같이 log를 취한 값을 최대화 하는 것이 더 효과적이다.($\\because$ log 함수는 monotonic)\n",
    "\n",
    "$$log ~ p(D|W) = \\sum_c log ~ p(t_c | W)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>MAP: Maximum a Posteriori</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 model을 학습하는 과정은 weight vector $W$를 구하는 과정인데, Bayesian 접근법으로 data $D$가 주어졌을 때 $W$의 확률 분포를 구한다면 아래와 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_map.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The log probability of a weight under its prior</u>, $p(W)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 sum of squared weight을 최소화 하는 것은       \n",
    "$W$의 prior distribution이 $N(0, \\sigma^2)$일때          \n",
    "$-log~p(W)$를 최소화 하는 것과 같다.\n",
    "\n",
    "$$\\begin{align} p(w) &= \\frac{1}{\\sqrt{2 \\pi}\\sigma} e^{- \\frac{w^2}{2 \\sigma_W^2}} \\\\\n",
    "-log ~ p(w) &= \\frac{w^2}{2 \\sigma^2_W} + k\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The Bayesian interpretation of weight decay</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 앞서 구한 블록들을 조합해 보면 아래와 같은데..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_bayesian_weight_decay.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 term인 $-log ~ p(D ~ | ~ W)$을 최소화 하는 것은 결국 cost function $E$를 최소화 하는 것이고,     \n",
    "두번째 term인 $-log ~ p(W)$를 최소화 하는 것은 결국 L2 weight penalty(sum of squared weight)를 최소화 하는 것과 같다.\n",
    "\n",
    "위 식은 Lecture 9b 에서 등장했던 아래 식과 유사한데..\n",
    "$$C = E + \\frac{\\lambda}{2} \\sum_i w_i^2$$\n",
    "\n",
    "결국 $\\frac{\\lambda}{2}$이 $\\sigma_D^2 / \\sigma_W^2$와 같은 의미를 갖는다는 것이다. (이는 data 분산과 weight의 분산의 비 이다.) \n",
    "\n",
    "이런 아이디어를 이용한 방법이 다음에 등장한 <u>MacKay's quick and dirty method</u>이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 9f, MacKay's quick and dirty method of setting weights costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1990년대에 영국의 물리학자이자 수학자인 David Mackay(22 April 1967 – 14 April 2016)가 고안한 방법으로 weight penalty가 $\\sigma_D^2$(tightness of the prior distribution over weights)의 역수에 비례한다는 사실을 이용하여 경험적으로(empirically) weight penalty와 distribution of noise를 찾을 수 있다는 것이다. (즉 validation set 없이 weight penalty를 결정할 수 있게 해 준다.)     \n",
    "이 방법을 통해 validation set없이도 network의 weight group 마다 다른 weight penalty를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Estimating the variance of the output noise</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 아래 내용을 배웠었는데, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\".\\_images\\09_bayesian_weight_decay.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-log~p(D~|~W) \\propto \\frac{1}{2 \\sigma_D^2} \\sum_C (y_c - t_c^2)$ 라는 점에서 아이디어를 얻어,      \n",
    "residual error, ($y_c - t_c$)의 분산을 output variance, $\\sigma_D^2$로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Estimating the variance of the Gaussian prior on the weights</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-~log~p(W)$를 근사하기 위해서는 $\\sigma_W^2$를 정해야하는데,    \n",
    "MacKay의 방법에서는 처음에는 대략 적당한 variance of prior를 사용하고,     \n",
    "학습을 진행한 후 나온 weight들의 분산을 바로 variance of prior로 사용한다.    \n",
    "이 방법의 좋은 점은 weight들을 그룹지어서 각 그룹마다 다른 variance of prior를 사용할 수 있다는 것이다.(결국 각 그룹마다 다른 weight penalty를 사용하는 것과 같음)     \n",
    "말도 안되는 아이디어 같지만 예측 성능이 좋다고 한다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>MacKay's quick and dirty method of choosing the ratio of the noise variance to the weight prior variance</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 방법을 정리해보면..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 noise variance와 weight prior variance로 그냥 적당한 값을 정해 시작한다.\n",
    "\n",
    "1. 앞서 정한 $\\sigma_D$와 $\\sigma_W$의 ratio를 이용하여 weight penalty를 정한다.\n",
    "2. 학습이 조금 진행된 후 noise variance($\\sigma_D$)를 variance of the residual error로 대체\n",
    "3. 학습된 weight(grouped)들의 variance로 $\\sigma_W$를 대체\n",
    "4. 학습을 좀더 진행하고 다시 1로 돌아간다.(반복)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
