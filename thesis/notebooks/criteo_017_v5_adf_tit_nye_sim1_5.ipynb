{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "            \n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?: sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 10000000        #train_start, train_size\n",
    "                         , 10000001, 10000000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 2148.9990730285645 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 2756.5304708480835 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'fp': 2125802, 'tot': 10000000, 'accuracy': 0.7124528, 'precision': 0.46005714377152446, 'fn': 749670, 'f1_score': 0.55748639359363938, 'tp': 1811285, 'tn': 5313243, 'recall': 0.7072693585010279}, 0.5599016879010087)\n"
     ]
    }
   ],
   "source": [
    "sim1_sgd = get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test\n",
    "print(sim1_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'fp': 2123647, 'tot': 10000000, 'accuracy': 0.71301800000000004, 'precision': 0.46078829909083036, 'fn': 746173, 'f1_score': 0.55844738516757886, 'tp': 1814782, 'tn': 5315398, 'recall': 0.70863486472819714}, 0.5585999682067023)\n"
     ]
    }
   ],
   "source": [
    "sim1_adf = get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test\n",
    "print(sim1_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.78384728490954902, 0.78487680726923015)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRApQYRESkgP8HQO2LEeK3f1cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x79237b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')\n",
    "    \n",
    "sim1_auc = (roc_auc_sgd, roc_auc_adf)\n",
    "print(sim1_auc)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
