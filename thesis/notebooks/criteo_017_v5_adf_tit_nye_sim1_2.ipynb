{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "\n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?: sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 10000        #train_start, train_size\n",
    "                         , 10001, 10000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 2.310324192047119 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 3.1087799072265625 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'recall': 0.57378472222222221, 'tot': 10000, 'f1_score': 0.47571068729758903, 'tn': 5764, 'fp': 1932, 'precision': 0.40626920712968656, 'fn': 982, 'accuracy': 0.70860000000000001, 'tp': 1322}, 0.5672998573037459)\n"
     ]
    }
   ],
   "source": [
    "sim1_sgd = get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test\n",
    "print(sim1_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'recall': 0.55208333333333337, 'tot': 10000, 'f1_score': 0.47864534336782688, 'tn': 5957, 'fp': 1739, 'precision': 0.42245101295250748, 'fn': 1032, 'accuracy': 0.72289999999999999, 'tp': 1272}, 0.5526848301193127)\n"
     ]
    }
   ],
   "source": [
    "sim1_adf = get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test\n",
    "print(sim1_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.72954926079926075, 0.73052509014423084)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npM31KWgWRgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8564080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')\n",
    "    \n",
    "sim1_auc = (roc_auc_sgd, roc_auc_adf)\n",
    "print(sim1_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
