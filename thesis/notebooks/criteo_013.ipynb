{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "v012 : 테스트 데이터 생성 & 로지스틱 회귀\n",
    "\n",
    "v013 : applied tinrtgu's idea to this test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I'v made test data and result of logistic regression of this dataset. I'll use this data to check result of further development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class Node: \n",
    "    def __init__(self): \n",
    "        self.data = None # Variable to store 'list'\n",
    "        self.length = None # Length of the list\n",
    "        self.next = None # Next node\n",
    "        self.prev = None # Previous Node\n",
    "        self.current_index = None # Index of current value of my list.\n",
    "\n",
    "    def __str__(self): \n",
    "        return str(self.data)\n",
    "    \n",
    "    def get_cur_value(self):\n",
    "        return self.data[self.current_index] # Returns current value of my list.\n",
    "\n",
    "    def increse_index(self):\n",
    "        overflow_flag = False # flag to show if current_index is indicating last value of my list.\n",
    "\n",
    "        if((self.current_index + 1) == self.length): # Check if current_index is indicating the last value of my node.\n",
    "            self.current_index = 0 # Resetting the current_index\n",
    "            overflow_flag = True\n",
    "            if(self.prev is not None):\n",
    "                self.prev.increse_index() # Propagating the overflow to previous node.\n",
    "        else:\n",
    "            self.current_index += 1\n",
    "        \n",
    "        return overflow_flag\n",
    "            \n",
    "    \n",
    "class Linked_list:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.head_node = None\n",
    "        self.tail_node = None\n",
    "        self.num_node = 0\n",
    "    \n",
    "    def add_first(self, data):\n",
    "        #create a new node\n",
    "        new_node = Node()\n",
    "        new_node.data = data\n",
    "        new_node.length = len(data)\n",
    "        new_node.current_index = 0\n",
    "        \n",
    "        if(self.head_node):\n",
    "            new_node.next = self.head_node\n",
    "            self.head_node.prev = new_node\n",
    "        else:\n",
    "            self.tail_node = new_node\n",
    "            \n",
    "        self.head_node = new_node\n",
    "        Linked_list.num_node += 1\n",
    "    \n",
    "    def add_last(self, data):\n",
    "        #create a new node\n",
    "        new_node = Node()\n",
    "        new_node.data = data\n",
    "        new_node.length = len(data)\n",
    "        new_node.current_index = 0\n",
    "        \n",
    "        if(self.head_node):\n",
    "            new_node.prev = self.tail_node\n",
    "            self.tail_node.next = new_node\n",
    "        else:\n",
    "            self.head_node = new_node\n",
    "            \n",
    "        self.tail_node = new_node\n",
    "        self.num_node += 1\n",
    "        \n",
    "    def list_print(self):\n",
    "        node = self.head_node\n",
    "        while node:\n",
    "            print(node.data)\n",
    "            node = node.next\n",
    "\n",
    "    def get_current_record(self):\n",
    "        node = self.head_node\n",
    "        return_list = []\n",
    "        while node:\n",
    "            return_list = return_list + [node.get_cur_value()]\n",
    "            node = node.next\n",
    "        return return_list\n",
    "    \n",
    "    def get_number_of_total_combination(self):\n",
    "        total = 1\n",
    "        node = self.head_node\n",
    "        while(node):\n",
    "            total *= node.length\n",
    "            node = node.next\n",
    "        return total\n",
    "    \n",
    "    def get_df_one(self, times=1):\n",
    "        stri = [str(i) for i in list(range(1, self.num_node))]\n",
    "        col_names = [\"y\"] + [\"x\" + s for s in stri]\n",
    "\n",
    "        df = pd.DataFrame(columns = col_names)\n",
    "        tot = self.get_number_of_total_combination() * times\n",
    "\n",
    "        for i in range(tot):\n",
    "            record = self.get_current_record()\n",
    "            df = df.append(pd.Series(record, index = col_names), ignore_index=True)\n",
    "            self.tail_node.increse_index()\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1 = Linked_list()\n",
    "l1.add_last([1, 0])\n",
    "l1.add_last(['a1', 'a2', 'a3'])\n",
    "l1.add_last(['b1', 'b2', 'b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2 = Linked_list()\n",
    "l2.add_last([0])\n",
    "l2.add_last(['a1', 'a2'])\n",
    "l2.add_last(['b1', 'b2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l3 = Linked_list()\n",
    "l3.add_last([1])\n",
    "l3.add_last(['a2', 'a3'])\n",
    "l3.add_last(['b3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = l1.get_df_one(1)\n",
    "df2 = l2.get_df_one(10)\n",
    "df3 = l3.get_df_one(20)\n",
    "\n",
    "df_train = df1.append(df2).append(df3)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "df_train.to_csv('./mycsv.csv')\n",
    "\n",
    "\n",
    "dummy_x1 = pd.get_dummies(df_train['x1'], prefix='x1')\n",
    "dummy_x2 = pd.get_dummies(df_train['x2'], prefix='x2')\n",
    "\n",
    "data_train = df_train[['y']].join(dummy_x1.ix[:,'x1_a2':]).join(dummy_x2.ix[:,'x2_b2':])\n",
    "data_train['intercept'] = 1.0\n",
    "data_train = data_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1_ = l1.get_df_one(1)\n",
    "df2_ = l2.get_df_one(2)\n",
    "df3_ = l3.get_df_one(5)\n",
    "\n",
    "df_test = df1_.append(df2_).append(df3_)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "dummy_x1_ = pd.get_dummies(df_test['x1'], prefix='x1')\n",
    "dummy_x2_ = pd.get_dummies(df_test['x2'], prefix='x2')\n",
    "\n",
    "data_test = df_test[['y']].join(dummy_x1_.ix[:,'x1_a2':]).join(dummy_x2_.ix[:,'x2_b2':])\n",
    "data_test['intercept'] = 1.0\n",
    "data_test = data_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.280984\n",
      "         Iterations 7\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                   98\n",
      "Model:                          Logit   Df Residuals:                       93\n",
      "Method:                           MLE   Df Model:                            4\n",
      "Date:                Tue, 15 Dec 2015   Pseudo R-squ.:                  0.5946\n",
      "Time:                        06:29:31   Log-Likelihood:                -27.536\n",
      "converged:                       True   LL-Null:                       -67.928\n",
      "                                        LLR p-value:                 1.188e-16\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "x1_a2          0.8659      0.927      0.934      0.350        -0.951     2.683\n",
      "x1_a3          2.3049      1.145      2.013      0.044         0.061     4.549\n",
      "x2_b2        1.51e-16      0.900   1.68e-16      1.000        -1.764     1.764\n",
      "x2_b3          4.1810      0.890      4.696      0.000         2.436     5.926\n",
      "intercept     -2.7841      0.915     -3.043      0.002        -4.577    -0.991\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "logit = sm.Logit(data_train['y'], data_train.ix[:,'x1_a2':])\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4386847041540758"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = result.predict(data_train.ix[:,'x1_a2':])\n",
    "actual = data_train['y']\n",
    "\n",
    "import numpy as np\n",
    "SSE = sum((np.array(predicted) - np.array(actual))**2)\n",
    "SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9801424285949789"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = result.predict(data_test.ix[:,'x1_a2':])\n",
    "actual = data_test['y']\n",
    "\n",
    "import numpy as np\n",
    "SSE = sum((np.array(predicted) - np.array(actual))**2)\n",
    "SSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.533914895676304"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = result.predict(data_test.ix[:,'x1_a2':])\n",
    "actual = data_test['y']\n",
    "\n",
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)\n",
    "\n",
    "loss = 0\n",
    "for i in range(len(actual)):\n",
    "    loss += logloss(predicted[i], actual[i])\n",
    "loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_dic(df_train, row_num):\n",
    "    keys = list(df_train.columns.values)\n",
    "    values = list(df_train.ix[row_num])\n",
    "    x_dic = {}\n",
    "    for i in range(len(keys)):\n",
    "        x_dic[keys[i]] = values[i]\n",
    "    return x_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "\n",
    "D = 2 ** 6   # number of weights use for learning\n",
    "alpha = .75    # learning rate for sgd optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x(csv_row, D):\n",
    "    x = [0]  # 0 is the index of the bias term\n",
    "    for key, value in csv_row.items():\n",
    "        index = int(value + key[1:], 16) % D  # weakest hash ever ;)\n",
    "        x.append(index)\n",
    "    return x  # x contains indices of features that have a value of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y):\n",
    "    for i in x:\n",
    "        # alpha / (sqrt(n) + 1) is the adaptive learning rate heuristic\n",
    "        # (p - y) * x[i] is the current gradient\n",
    "        # note that in our case, if i in x then x[i] = 1\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.71840180366248"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize our model\n",
    "w = [0.] * D  # weights\n",
    "n = [0.] * D  # number of times we've encountered a feature\n",
    "\n",
    "# start training a logistic regression model using on pass sgd\n",
    "loss = 0.\n",
    "\n",
    "\n",
    "for i in range(len(df_train)):\n",
    "    row = get_x_dic(df_train, i)\n",
    "    \n",
    "    y = 1. if row['y'] == 1 else 0.\n",
    "    del row['y']\n",
    "    \n",
    "    x = get_x(row, D)\n",
    "    \n",
    "    p = get_p(x, w)\n",
    "    \n",
    "    loss += logloss(p, y)\n",
    "    \n",
    "    w, n = update_w(w, n, x, p, y)\n",
    "\n",
    "w\n",
    "\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x1': 'a3', 'x2': 'b3', 'y': 0.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.917320400138082"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = get_x_dic(df_train, 17)\n",
    "print(row)\n",
    "del row['y']\n",
    "get_p(get_x(row, D), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.546426169225775"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = 0.\n",
    "for i in range(len(df_test)):\n",
    "    row = get_x_dic(df_test, i)\n",
    "    \n",
    "    y = 1. if row['y'] == 1 else 0.\n",
    "    del row['y']\n",
    "    \n",
    "    x = get_x(row, D)\n",
    "    p = get_p(x, w)\n",
    "    \n",
    "    loss += logloss(p, y)\n",
    "    \n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
