{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "\n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        \n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?: sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 100000        #train_start, train_size\n",
    "                         , 100001, 100000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 22.601940870285034 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 30.980741024017334 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26023"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(arr_sgd_y) / len(arr_sgd_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'f1_score': 0.5469408130791551, 'precision': 0.46035872790777066, 'fn': 8493, 'fp': 20549, 'tp': 17530, 'tn': 53428, 'tot': 100000, 'recall': 0.67363486146870077, 'accuracy': 0.70957999999999999}, 0.5642465684711354)\n"
     ]
    }
   ],
   "source": [
    "sim1_sgd = get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test\n",
    "print(sim1_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'f1_score': 0.54393064459903906, 'precision': 0.44909400340374411, 'fn': 8079, 'fp': 22012, 'tp': 17944, 'tn': 51965, 'tot': 100000, 'recall': 0.68954386504246246, 'accuracy': 0.69908999999999999}, 0.5746658922608376)\n"
     ]
    }
   ],
   "source": [
    "sim1_adf = get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test\n",
    "print(sim1_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.76951788790369902, 0.76802905987799763)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsWCRVUYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5d348d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')\n",
    "    \n",
    "sim1_auc = (roc_auc_sgd, roc_auc_adf)\n",
    "print(sim1_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
