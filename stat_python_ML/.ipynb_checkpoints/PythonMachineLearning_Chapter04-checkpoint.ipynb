{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. Building Good Training Sets - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Dealing with missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값(missing value)은 일부 관측개체의 일부 변수에서 관측값이 얻어지지 않아 'NA'(not available)로 남은 것인데 어느 정도 규모의 자료에서는 불가피하다. 결측값을 포기(무시)하고 관측자료만을 분석하게 되면 많은 경우 통계적 편향(bias)이 생긴다. - [허명회, 2014, 응용데이터분석, 5장 中]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.1.1 결측값 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값에 대처하는 방법으로 가장 간단한 방법은 해당 컬럼 혹은 행을 분석에서 제외하는 것이다. 예를들어 표본조사 데이터에서 주소에 대한 컬럼에 누락값이 지나치게 많다면 해당 컬럼을 제외하고 분석을 진행하게 된다. 혹은 특정 표본에서 누락된 변수값이 많다면 이 행을 제외하는 선택을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측값(NaN)이 포함된 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   NaN  8.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data w/missing value\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "0.0,11.0,12.0,'''\n",
    "# If you are using Python 2.7, you need\n",
    "# to convert the string to unicode:\n",
    "# csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 컬럼에 null 값이 몇개인지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    0\n",
       "B    0\n",
       "C    1\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NA 가 포함된 행을 제거, (1번, 2번 행이 제거됨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1번째 열(C)을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B\n",
       "0  1.0   2.0\n",
       "1  5.0   6.0\n",
       "2  0.0  11.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모든 값이 NaN인 행만 제거(이 데이터에는 모든 값이 NaN인 행은 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   NaN  8.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 4개 이상 NaN이 아닌 값이 포함되지 않은 행을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D\n",
       "0  1.0  2.0  3.0  4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(thresh=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> C열에 NaN이 포함된 열은 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4.1.2. 결측값 대체(imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값이 포함된 행이나 열을 제거하는 방법은 간편하기는 하지만 그런 행이나 열이 많아지면 데이터의 편향을 가져오게 된다. 측 남자와 여자 각각 50명식 표본조사를 했고 어떤 문제로 인해 남자들이 특정 설문에 대거 응답하지 않아 해당하는 행들을 모두 분석데이터에서 제거한다면, 그 분석 데이터는 모집단의 특성을 잘 반영하지 못하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측값을 제거하는 것이 적절하지 않은 상황이라면 결측값을 어떤 다른 값으로 대체하는 방법(Missing value imputation)을 선택할 수 있다. 어떤 값으로 결측값을 대체 해야한다면, (알수는 없는) 실제 값과 가장 가까운 값으로 대체할 수 있다면 좋을 것이다. 간단한 아이디어로는 데이터 컬럼의 평균값/중간값/최빈값 등으로 대체할 수도 있고, 값이 있는 컬럼을 기반으로 유사한 특성을 갖는 다른 행들이 갖는 값과 유사한 값으로 대체할 수도 있을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 결측값을 각 열의 평균으로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A     B     C    D\n",
       "0  1.0   2.0   3.0  4.0\n",
       "1  5.0   6.0   NaN  8.0\n",
       "2  0.0  11.0  12.0  NaN"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample data w/missing value\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "csv_data = '''A,B,C,D\n",
    "1.0,2.0,3.0,4.0\n",
    "5.0,6.0,,8.0\n",
    "0.0,11.0,12.0,'''\n",
    "# If you are using Python 2.7, you need\n",
    "# to convert the string to unicode:\n",
    "# csv_data = unicode(csv_data)\n",
    "df = pd.read_csv(StringIO(csv_data))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1. ,   2. ,   3. ,   4. ],\n",
       "       [  5. ,   6. ,   7.5,   8. ],\n",
       "       [  0. ,  11. ,  12. ,   6. ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "# strategy: mean, median, most_frequent\n",
    "# axis: 0 for column, 1 for row\n",
    "imr = imr.fit(df)\n",
    "imputed_data = imr.transform(df.values)\n",
    "imputed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Handling categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ 데이터 값은 그 특성에 따라 아래 4가지로 나눌 수 있다.\n",
    "1. 명목 척도(Nominal scale): 순서 없는 범주형 / 범주간 비교 불가, 예) 남자/여자\n",
    "2. 순서 척도(Ordinal scale): 순서 있는 범주형 / 범주간 비교 가능, 예) 긍정, 보통, 부정\n",
    "3. 간격 척도(Interval scale): 연속형의 상대적인 수치 / 의미있는 원점이 없음, 예) 섭씨온도\n",
    "4. 비율 척도(Ratio scale): 의미있는 원점이 있는 연속형의 상대적 수치, 예) \n",
    "\n",
    "1번과 2번은 정성적, 비계량형(Nonmetric) 값으로서 범주형 이라 하고    \n",
    "3번과 4번은 정량적, 계량형(Metric)값으로 연속형 이라 한다.\n",
    "\n",
    "■ 그런데 데이터 값이 명목형 일 경우 특별한 고려/처리가 필요하다. 명목형 변수를 그 자체로 순서나 비교 혹은 사칙 연산이 의미를 갖지 못하고 한 변수로 범주에 속함을 표현한다면 의도 하지 않은 정보를 분석 모형에 주게 된다. 예를들어 성별을 나타내는 열이 있고 남자를 1 여자를 2로 표시 했을 때, 하나의 열을 그대로 분석 모형에 사용할 경우 여자가 남자의 2배라거나 크다는 식의 정보를 의도치 않게 부여하게 된다.         \n",
    "\n",
    "또한 분석을 위한 데이터셋은 각 열이 대상의 특성을 나타내는 변수이고, 분석 모형은 각 변수의 영향에 따른 결과값을 알아보기 위한 것 이므로, 데이터셋의 각 변수는 대상에 대한 하나의 속성을 나타내야한다.    \n",
    "\n",
    "따라서 범주형 변수의 경우 indicator 혹은 dummy 변수를 사용하여 각 범주에 속하는지를 표현하는 변수를 나누게 된다. 예를들어 어떤 데이터의 성별을 나타내는 (1:남/2:여)열이 있다면 이를 '남자 이냐'라는 변수와 '여자 이냐'라는 2개의 변수로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 범주형 변수를 포함하는 예시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>M</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>L</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>XL</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color size  price classlabel\n",
       "0  green    M   10.1     class1\n",
       "1    red    L   13.5     class2\n",
       "2   blue   XL   15.3     class1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "        ['green', 'M', 10.1, 'class1'],\n",
    "        ['red', 'L', 13.5, 'class2'],\n",
    "        ['blue', 'XL', 15.3, 'class1']])\n",
    "df.columns = ['color', 'size', 'price', 'classlabel']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 범주를 다른 숫자로 치환(mapping) - dictionary 직접 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class1\n",
       "1    red     2   13.5     class2\n",
       "2   blue     3   15.3     class1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_mapping = {'XL': 3, 'L': 2, 'M': 1}\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'M', 2: 'L', 3: 'XL'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{v: k for k, v in size_mapping.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 범주를 다른 숫자로 치환(classlabel) - enumerate을 이용한 dictionary 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class1': 0, 'class2': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df['classlabel']))}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price  classlabel\n",
       "0  green     1   10.1           0\n",
       "1    red     2   13.5           1\n",
       "2   blue     3   15.3           0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['classlabel'] = df['classlabel'].map(class_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 치환을 역으로.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>price</th>\n",
       "      <th>classlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>2</td>\n",
       "      <td>13.5</td>\n",
       "      <td>class2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>3</td>\n",
       "      <td>15.3</td>\n",
       "      <td>class1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  size  price classlabel\n",
       "0  green     1   10.1     class1\n",
       "1    red     2   13.5     class2\n",
       "2   blue     3   15.3     class1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv_class_mapping = {v: k for k, v in class_mapping.items()}\n",
    "df['classlabel'] = df['classlabel'].map(inv_class_mapping)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> scikit-learn LabelEncode class를 이용한 치환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "y = class_le.fit_transform(df['classlabel'].values)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class1', 'class2', 'class1'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_le.inverse_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "순서형(Ordinal) 값의 경우 위와 같은 치환이 의미를 갖을 수 있으나,      \n",
    "명목형(Norminal) 값의 경우 위와 같은 치환을 할 경우 원래 데이터에 없는 순서와 크기라는 원래 없던 정보를 부여하는 꼴이 되므로 분석에 큰 재앙을 가져온다. \n",
    "\n",
    "이런 경우 사용하는 방법이 one-hot encoding(가변수 변환)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['green', 1, 10.1],\n",
       "       ['red', 2, 13.5],\n",
       "       ['blue', 3, 15.3]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X = df[['color', 'size', 'price']].values; X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 10.1],\n",
       "       [2, 2, 13.5],\n",
       "       [0, 3, 15.3]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_le = LabelEncoder()\n",
    "X[:, 0] = color_le.fit_transform(X[:, 0])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0. ,   1. ,   0. ,   1. ,  10.1],\n",
       "       [  0. ,   0. ,   1. ,   2. ,  13.5],\n",
       "       [  1. ,   0. ,   0. ,   3. ,  15.3]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categorical_features=[0])\n",
    "ohe.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Partitioning a dataset in training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사용할 데이터가 있다면        \n",
    "이중 일부는 모형을 학습시키는데 사용하고,      \n",
    "다른 일부는 모형의 weight이 아닌 모형 변수들을 결정하는데 사용하고,       \n",
    "나머지는 모형의 성능을 평가하는데 사용한다. \n",
    "\n",
    "이들 데이터를 차례대로 Training set, Validation set, Test set이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ 데이터를 효과적으로 이렇게 3개(혹은 Training set과 Test set만으로 2개)로 나누는 방법에 대해서 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번에는 연습용 데이터로 3종류의 와인의 13가지 특성에 대한 데이터를 사용해 보자.     \n",
    "(http://archive.ics.uci.edu/ml/ 에 들어가면 다양한 연습용 데이터를 얻을 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Wine 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels [1 2 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data', header=None)\n",
    "df_wine.columns = ['Class label', 'Alcohol'\n",
    "                   , 'Malic acid', 'Ash'\n",
    "                   , 'Alcalinity of ash', 'Magnesium'\n",
    "                   , 'Total phenols', 'Flavanoids'\n",
    "                   , 'Nonflavanoid phenols', 'Proanthocyanins'\n",
    "                   , 'Color intensity', 'Hue'\n",
    "                   , 'OD280/OD315 of diluted wines', 'Proline']\n",
    "print('Class labels', np.unique(df_wine['Class label']))\n",
    "\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> scikit-learn을 이용한 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모형을 잘 학습시키기 위해서는 가능한 많은 데이터가 Training set으로 사용된다면 좋을 것이다. 단지 평가만을 위해 많은 데이터를 사용한다면 낭비일 수 있다. 일반적으로 Training:Test set을 6:4, 7:3, 8:2의 비율로 나누는 것이 일반적이며, 만약 사용 가능한 데이터가 아주 많다면 극단적으로 training set에 많은 데이터를 사용하여 9:1 혹은 99:1로 데이터를 나눌 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4. Bringing features onto the same scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋의 변수간 단위(scale)이 지나치게 다르다면 모형 예측의 정확도가 낮아지고 최적화 수렴 속도가 느려지게 된다. 따라서 변수간의 단위를 맞춰주는 작업을 하는데 이를 **feature scaling**이라 한다.    \n",
    "\n",
    "feature scaling에는 normalization(혹은 Rescaling, Min-Max scaling)과 standardization이 있다.\n",
    "\n",
    "■ 우선 normalization은 변수의 값을 0과 1사이로 옮기는데 그 방법은 아래와 같다.\n",
    "$$x_{norm}^{(i)} = \\frac{ x^{(i)} - x_{min} }{ x_{max} - x_{min} }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> MinMaxScaler를 이용하면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.71,  12.22,  13.27,  13.16,  13.86,  12.85,  13.84,  13.3 ,\n",
       "        13.05,  12.51,  12.29,  12.77,  12.96,  13.67,  13.16,  12.37,\n",
       "        12.47,  11.81,  13.24,  14.1 ,  11.61,  12.99,  12.77,  13.48,\n",
       "        11.46,  12.07,  11.82,  13.45,  12.2 ,  13.05,  13.17,  12.08,\n",
       "        12.17,  12.42,  11.87,  12.21,  13.94,  14.1 ,  12.67,  14.75,\n",
       "        12.25,  12.85,  13.73,  14.06,  13.63,  12.33,  13.82,  12.08,\n",
       "        13.03,  14.37,  13.17,  12.72,  14.39,  13.34,  11.66,  11.84,\n",
       "        12.86,  13.75,  12.53,  13.11,  14.38,  14.23,  12.  ,  13.23,\n",
       "        14.38,  14.12,  12.  ,  12.34,  13.48,  13.29,  13.41,  13.71,\n",
       "        12.37,  13.2 ,  11.45,  13.62,  13.88,  12.42,  12.81,  12.58,\n",
       "        13.83,  13.07,  12.7 ,  13.77,  12.84,  12.37,  13.51,  13.87,\n",
       "        12.08,  13.58,  13.08,  11.79,  12.45,  13.68,  13.52,  13.5 ,\n",
       "        12.87,  14.02,  12.29,  12.08,  12.7 ,  11.03,  13.32,  14.13,\n",
       "        13.49,  11.84,  13.05,  12.72,  12.82,  13.4 ,  14.22,  13.72,\n",
       "        12.93,  11.64,  12.29,  11.65,  13.28,  12.93,  13.86,  11.82,\n",
       "        12.37,  12.42,  13.9 ,  14.16])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72043011,  0.31989247,  0.60215054,  0.57258065,  0.76075269,\n",
       "        0.48924731,  0.75537634,  0.61021505,  0.54301075,  0.39784946,\n",
       "        0.33870968,  0.46774194,  0.5188172 ,  0.70967742,  0.57258065,\n",
       "        0.36021505,  0.38709677,  0.20967742,  0.59408602,  0.82526882,\n",
       "        0.15591398,  0.52688172,  0.46774194,  0.65860215,  0.1155914 ,\n",
       "        0.27956989,  0.21236559,  0.65053763,  0.31451613,  0.54301075,\n",
       "        0.57526882,  0.28225806,  0.30645161,  0.37365591,  0.22580645,\n",
       "        0.3172043 ,  0.78225806,  0.82526882,  0.44086022,  1.        ,\n",
       "        0.32795699,  0.48924731,  0.72580645,  0.81451613,  0.69892473,\n",
       "        0.34946237,  0.75      ,  0.28225806,  0.53763441,  0.89784946,\n",
       "        0.57526882,  0.45430108,  0.90322581,  0.62096774,  0.16935484,\n",
       "        0.21774194,  0.49193548,  0.7311828 ,  0.40322581,  0.55913978,\n",
       "        0.90053763,  0.86021505,  0.26075269,  0.59139785,  0.90053763,\n",
       "        0.83064516,  0.26075269,  0.35215054,  0.65860215,  0.60752688,\n",
       "        0.63978495,  0.72043011,  0.36021505,  0.58333333,  0.11290323,\n",
       "        0.69623656,  0.76612903,  0.37365591,  0.47849462,  0.41666667,\n",
       "        0.75268817,  0.5483871 ,  0.44892473,  0.73655914,  0.48655914,\n",
       "        0.36021505,  0.66666667,  0.76344086,  0.28225806,  0.68548387,\n",
       "        0.55107527,  0.20430108,  0.38172043,  0.71236559,  0.66935484,\n",
       "        0.66397849,  0.49462366,  0.80376344,  0.33870968,  0.28225806,\n",
       "        0.44892473,  0.        ,  0.6155914 ,  0.83333333,  0.66129032,\n",
       "        0.21774194,  0.54301075,  0.45430108,  0.4811828 ,  0.63709677,\n",
       "        0.85752688,  0.72311828,  0.51075269,  0.16397849,  0.33870968,\n",
       "        0.16666667,  0.60483871,  0.51075269,  0.76075269,  0.21236559,\n",
       "        0.36021505,  0.37365591,  0.77150538,  0.84139785])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ 다음으로 standardization은 변수값을 평균이 0이고 분산이 1인 정규 분포($\\mathcal{N}(0, 1)$)로 변환해준다.\n",
    "$$x_{std}^{(i)} = \\frac{ x^{(i)} - \\mu_x }{ \\sigma_x }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> StandardScaler를 이용하면...     \n",
    "(test set을 변환할 때에도 training set의 평균($\\mu_x$)과 분산($\\sigma_x$)을 사용함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.71,  12.22,  13.27,  13.16,  13.86,  12.85,  13.84,  13.3 ,\n",
       "        13.05,  12.51,  12.29,  12.77,  12.96,  13.67,  13.16,  12.37,\n",
       "        12.47,  11.81,  13.24,  14.1 ,  11.61,  12.99,  12.77,  13.48,\n",
       "        11.46,  12.07,  11.82,  13.45,  12.2 ,  13.05,  13.17,  12.08,\n",
       "        12.17,  12.42,  11.87,  12.21,  13.94,  14.1 ,  12.67,  14.75,\n",
       "        12.25,  12.85,  13.73,  14.06,  13.63,  12.33,  13.82,  12.08,\n",
       "        13.03,  14.37,  13.17,  12.72,  14.39,  13.34,  11.66,  11.84,\n",
       "        12.86,  13.75,  12.53,  13.11,  14.38,  14.23,  12.  ,  13.23,\n",
       "        14.38,  14.12,  12.  ,  12.34,  13.48,  13.29,  13.41,  13.71,\n",
       "        12.37,  13.2 ,  11.45,  13.62,  13.88,  12.42,  12.81,  12.58,\n",
       "        13.83,  13.07,  12.7 ,  13.77,  12.84,  12.37,  13.51,  13.87,\n",
       "        12.08,  13.58,  13.08,  11.79,  12.45,  13.68,  13.52,  13.5 ,\n",
       "        12.87,  14.02,  12.29,  12.08,  12.7 ,  11.03,  13.32,  14.13,\n",
       "        13.49,  11.84,  13.05,  12.72,  12.82,  13.4 ,  14.22,  13.72,\n",
       "        12.93,  11.64,  12.29,  11.65,  13.28,  12.93,  13.86,  11.82,\n",
       "        12.37,  12.42,  13.9 ,  14.16])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.94841977, -0.24190464, -0.76815332,  0.72288462,  0.08386836,\n",
       "       -1.7830615 ,  1.34937115, -0.78068305, -0.91851009, -1.13151551,\n",
       "        0.47229001,  1.123836  ,  1.52478738, -0.76815332,  0.74794408,\n",
       "       -1.23175335,  0.97347923,  1.51225764, -0.4298506 ,  1.06118734,\n",
       "        0.15904674,  0.08386836,  0.32193324, -0.59273709, -0.81827224,\n",
       "       -0.58020736, -0.69297494, -1.03127766, -1.53246689,  0.99853869,\n",
       "        0.5098792 ,  1.54984684, -1.18163443,  1.53731711,  2.3141604 ,\n",
       "        0.08386836,  0.88577112, -0.36720194, -1.70788312,  0.52240893,\n",
       "        0.64770623,  0.93589004, -0.86839117, -0.47996952, -1.97100746,\n",
       "        0.82312246, -0.47996952, -1.28187228, -0.91851009,  1.65008468,\n",
       "       -0.12913706,  0.6351765 ,  0.72288462,  1.7002036 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수값을 특정 범위(0~1)로 옮겨야 한다면 normalization이 유용하다. 하지만 특이치가 포함되어 있을 경우 normalization의 결과는 한쪽으로 치우치게 되어 많은 정보를 잃게 된다. 반면 standardization은 값이 특정 범위로 국한되지는 않지만 값의 분포를 고려한 결과를 준다는 장점이 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/hcP4l.png\"/>\n",
    "[http://stackoverflow.com/questions/32108179/linear-regression-normalization-vs-standardization]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [How to prevent OVER-FITTING]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set에만 잘 맞는 상태인 overfitting은 주로 아래와 같은 방법으로 해결할 수 있다.\n",
    "\n",
    "- 더 많은 데이터를 Training data로 사용(데이터를 더 수집)\n",
    "- Weight의 크기를 제한(Regularization)\n",
    "- 의미가 덜한 변수를 분석에서 제외(Feature selection)\n",
    "- 차원 축소(Dimensionality reduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5에서 Weight의 크기를 제한하는 방법(Regularization)에 대해 그리고 4.6에서 의미가 덜한 변수를 분석에서 제외하는 방법(Feature selection)에 대해 알아볼 것이다. 이후 5장에서 더 많은 데이터가 필요한지 확인 하는 방법과 차원 축소에 대해 다루게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5. Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적인 (least squares) 회귀 문제에서는 아래와 같이 실제값($y_i$)와 예측값($\\hat{y}_i$)의 차이들을 최소화 하는 것이 그 접근 방법이다.\n",
    "$$\\mathrm{min}_w C\\sum_i^n \\left[ (y_i - \\hat{y}_i)^2 \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 weight의 크기를 어느정도로 제한하기 위해 위의 최적화 식에 weight의 크기를 표현하는 어떤 항($f_r(w)$)을 추가할 수 있고, 이것의 효과로 오차를 최소화 하는 것과 weight의 크기를 제한하는 것의 절충점으로 weight이 작아지게 된다.\n",
    "\n",
    "$$\\mathrm{min}_w\\{ C\\sum_i^n \\left[ (y_i - \\hat{y}_i)^2 \\right] + f_r(w) \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight의 크기를 제한하기 위한 다양한 형태의 $f_r(w)$를 사용하는 방법이 있는데    \n",
    "대표적인 방법인 **L2 regularization**과 **L1 regularization**에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ L2 regularization은 각 weight 제곱의 합을 penalty($f_r(w)$)로 사용하며 이를 Ridge penalty라고도 한다.\n",
    "$$f_r(w) = ||w||_2^2 = \\sum_{j=1}^m w_j^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "■ L1 regularization은 각 weight 절대값의 합을 penalty$f_r(w)$로 사용하며 이를 Lasso penalty라고도 한다.\n",
    "$$f_r(w) = ||w||_1 = \\sum_{j=1}^m |w_j|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 penalty와 L1 penalty는 각기 다른 특성을 갖는데, L1 penalty는 아래 좌측의 그림의 하늘색 마름모이고 L2 penalty는 아래 우측 그림의 하늘색 원과 같다. \n",
    "\n",
    "L1 penalty의 경우 cost function과의 접점이 꼭지점에서 만들어질 가능성이 크고, 이것은 어떤 weight은 0이 될 가능성이 커지는 것을 의미한다. 즉 L1 penalty의 이런 특성은 feature selection을 해 주는 효과를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/04_regu2.PNG\"/>\n",
    "<div align='right'>[p71, Elements of Statitical Learning]</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다실 다양한 형태의 weight penalty를 사용할 수 있는데 그 차수($q$)에 따라 다른 특성을 갖게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/04_regu3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L1 penalty를 포함한 cost function은 아래와 같이 '적합도를 높이려는 항'(첫번째)과 'weight을 줄이려는 항'(두번째)로 구성된다. 상수 C는 그 값이 커질 수록 모형 적합이 덜 진행되는데, 이 값을 조절하면서 weight이 어떻게 변하는지를 관찰해볼 수 있다. (이런 궤적을 regularization path라 함)\n",
    "\n",
    "$$\\mathrm{min}_w\\{ C  \\dot ~~ \\mathrm{(error)} + \\mathrm{(weight ~ penalty)} \\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.981481481481\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogisticRegression(penalty='l1')\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', C=0.1)\n",
    "lr.fit(X_train_std, y_train)\n",
    "print('Test accuracy:', lr.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38384675, -0.15806564, -0.70045741])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2803456 ,  0.        ,  0.        , -0.02797473,  0.        ,\n",
       "         0.        ,  0.710205  ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  1.23577765],\n",
       "       [-0.64405192, -0.06878583, -0.05722272,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        , -0.9267572 ,\n",
       "         0.06014647,  0.        , -0.37102714],\n",
       "       [ 0.        ,  0.06149138,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.63572778,  0.        ,  0.        ,  0.4979461 ,\n",
       "        -0.35834698, -0.57163692,  0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "colors = ['blue', 'green', 'red', 'cyan',\n",
    "          'magenta', 'yellow', 'black',\n",
    "          'pink', 'lightgreen', 'lightblue',\n",
    "          'gray', 'indigo', 'orange']\n",
    "weights, params = [], []\n",
    "\n",
    "for c in np.arange(-4, 6):\n",
    "    lr = LogisticRegression(penalty='l1', C=10**float(c), random_state=0)\n",
    "    lr.fit(X_train_std, y_train)    \n",
    "    weights.append(lr.coef_[1])\n",
    "    params.append(10**float(c))\n",
    "    \n",
    "weights = np.array(weights)\n",
    "for column, color in zip(range(weights.shape[1]), colors):\n",
    "    plt.plot(params, weights[:, column],\n",
    "             label=df_wine.columns[column+1],\n",
    "             color=color)\n",
    "plt.axhline(0, color='black', linestyle='--', linewidth=3)\n",
    "plt.xlim([10**(-5), 10**5])\n",
    "plt.ylabel('weight coefficient')\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.legend(loc='upper left')\n",
    "ax.legend(loc='upper center',\n",
    "          bbox_to_anchor=(1.38, 1.03),\n",
    "          ncol=1, fancybox=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림과 같이 $C$값이 커질수록(우측으로 갈 수록) 모형 적합을 더 하려는 효과가 커지기 때문에 각 weight의 절대값이 커지는 것을 관찰할 수 있다. 또한 우측으로 갈 수록 weight penalty의 효과는 작아진다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 weight의 크기를 제한하는 방법(regularization)을 이용해 overfitting을 최소화 하는 방법에 대해 알아봤고, 이번에는 중요하지 않은 변수는 제거(혹은 중요한 변수만을 선택)하는 방법(feature selection)에 대해서 알아본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 구성하는 변수가 10개라면 이 10개의 변수가 모두 중요한 요인이 아닐 수도 있다. 즉 중요한 몇개의 변수만으로 결과를 충분히 설명할 수 있다면, 모형을 만들고 학습시키고 사용하는데 있어 몇개의 변수만을 사용하여 비용과 속도 등의 이득을 볼 수 있을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 문제는 어떤 변수가 중요한지 혹은 중요하지 않은지를 알아내는 것인데, 가장 단순한 방법은 전체 변수를 사용했을 때와 변수를 하나식 제거한 후 모형의 성능을 비교하는 것이다. 여러 변수들 중 제거했을 때 모형의 성능이 크게 떨어지지 않는 변수를 먼저 제거하는 것이 좋을 것이다. 이런 접근법을 **Sequential Backward Selection(SBS)**라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SBS 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features,\n",
    "                 scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "    def fit(self, X, y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X\n",
    "                                                            , y\n",
    "                                                            , test_size=self.test_size\n",
    "                                                            , random_state=self.random_state)\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train,\n",
    "        X_test, y_test, self.indices_)\n",
    "        \n",
    "        self.scores_ = [score]\n",
    "        \n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "            \n",
    "            for p in combinations(self.indices_, r=dim-1):\n",
    "                score = self._calc_score(X_train, y_train, X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "            \n",
    "            self.scores_.append(scores[best])\n",
    "            \n",
    "        self.k_score_ = self.scores_[-1]\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self\n",
    "                    , X_train\n",
    "                    , y_train\n",
    "                    , X_test\n",
    "                    , y_test\n",
    "                    , indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> KNN 모형에 SBS를 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SBS at 0x240a11e1a90>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 변수의 수에 따른 모형 정확도 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2409e199908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.1])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 가장 좋은 성능을 내는 가장 적은 변수의 수는 5개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'Malic acid', 'Alcalinity of ash', 'Hue', 'Proline'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "k5 = list(sbs.subsets_[8])\n",
    "print(df_wine.columns[1:][k5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 전체 변수를 사용 했을 때와, 선택된 5개 변수만을 사용했을 때의 정확도 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.983870967742\n",
      "Test accuracy: 0.944444444444\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.959677419355\n",
      "Test accuracy: 0.962962962963\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_std[:, k5], y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std[:, k5], y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std[:, k5], y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Random Forests를 이용한 변수 중요도 판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1) Alcohol                        0.182483\n",
      " 2) Malic acid                     0.158610\n",
      " 3) Ash                            0.150948\n",
      " 4) Alcalinity of ash              0.131987\n",
      " 5) Magnesium                      0.106589\n",
      " 6) Total phenols                  0.078243\n",
      " 7) Flavanoids                     0.060718\n",
      " 8) Nonflavanoid phenols           0.032033\n",
      " 9) Proanthocyanins                0.025400\n",
      "10) Color intensity                0.022351\n",
      "11) Hue                            0.022078\n",
      "12) OD280/OD315 of diluted wines   0.014645\n",
      "13) Proline                        0.013916\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "feat_labels = df_wine.columns[1:]\n",
    "forest = RandomForestClassifier(n_estimators=10000\n",
    "                                , random_state=0\n",
    "                                , n_jobs=-1)\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEZCAYAAADCJLEQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xe4nFW5///3JxTpIuWAlESkCopIEwEl6FGagoKAUazI\nwYb4Q4/YAfVY4OhPRBEQRAEPTUBQiiASikgJhE4oIhAQQRCQqpTP94+1JplMJntPkmc9z+yZ+3Vd\n+8qeZ8q99k4y96x2L9kmhBBC6Dfjmm5ACCGE0E0kqBBCCH0pElQIIYS+FAkqhBBCX4oEFUIIoS9F\nggohhNCXIkGFEELoS5GgQl+RdLekpyX9U9IT+c8V5/M1t5I0vao29hjzWElfrzPmnEg6QNJxTbcj\nhLm1YNMNCKGDgR1sX1Thayq/7rw9WVrA9gsVtqc2khZoug0hzKvoQYV+pK4Xpc0k/VHSo5KmStqq\n7b4PSbol97julPRf+fpiwDnASu09ss4eTmcvS9JfJH1e0vXAk5LGSXq5pF9JekjSnyXt09MPI02Q\n9GJu472SHpG0t6SNJV0v6R+SDmt7/AclXSbpMEmP5Z/rzW33v1zSmfl1bpf00bb7DpB0qqTjJT0G\nfAz4ErB7/vmnjvT7av9dSNpP0oOS7pf0obb7F5H0vdzbfVTSJZJe0uPf0Z9zzD9LmtTL7y8Mr+hB\nhTFB0krAb4H32f6dpLcAp0la2/YjwIPA9rbvlvRG4DxJV9m+TtJ2wPG2x7e9Xrcwnb2s9wDbAY/k\n+34DnAHsDqwK/F7SNNsX9PhjbAqsAbwpv9a5wJuBlwBTJZ1i+9L82NcDpwDLArsAp0t6he3HgJOB\n64EVgXWBCyTdaXtyfu6OwLttvz8njuWA1W1/oK0tc/x95ftXBJYEVgLeBvxK0hm2Hwe+B7wK2Cy/\nzuuBF0f6OwKeAQ4FNrJ9p6QVgGV6/L2FIRU9qNCPfp17Ff+QdHq+tgdwtu3fAdi+EJgCbJ9vn2v7\n7vz9pcD5wBvnsx2H2v6r7X8BmwDL2f4f2y/kWEeTklgvDHzd9r9t/x54CjjR9iO2/wpcCryu7fEP\n2v5hjnUKcBuwg6RVgDcA+9t+zvb1uR3tyedPtn8DkNs+e2NG/339G/hGjn8u8CSwtlJm/zDwadt/\nc3KF7ecY5e8IeAF4jaRFbD9o+9Yef3dhSEWCCv1oJ9vL5K+d87UJwG5tietRYAvg5QCStpP0pzzs\n9Sip57PcfLbjvrbvJwArd8T/IvAfc/F6D7V9/wyp99F+e4m22/d3PPceUm9mJeAftp/uuG/lttuj\nLgjp4ff1iO0X224/ndu3HKnHd1eXl53j31Fu7+7Ax4EHJP0m96xCmKMY4gv9qNv423TgONt7z/Zg\naWHgV6RP8GfaflHSGW2v022BxFPAYm23X97lMe3Pmw7cZbuuN9WVO26PB84E/gosI2lx20+13dee\n0Dp/3llu9/D7GsnDwLPA6sCNHffN8e8IIA+FXpCHHf8H+ClpuDOErqIHFcaKE4B3SHpbXrCwSJ7M\nXwlYOH89nN9styPNm7Q8CCwraam2a9cB20t6mdIy9n1HiX8V8EReOLGIpAUkrSdp4x7b38ubf7v/\nkLSPpAUl7QqsQxo+uw+4HPi2pJdIWh/YEzh+hNd6EHiFZk68jfb7miOn83mOBb6fF2uMywsjFmKE\nvyNJ/yFpR6VFK8+RhgzH5MrIUJ9IUKHfdF0Ont+YdyKtSPs7aVjrc8A4208CnwZOlfQP0rzQmW3P\nvQ04EbgrDz2tSHpDvwG4GzgPOGmkduThrrcDGwB/IQ3X/RRYit6M2KvpcvtKYE1Sj+UbwC55gQTA\nJGA1Um/qNOCroyzLP5WUIB+RNCX/vvZlDr+vHtr/OVLv6WrSApLvkP4e5vh3lL/2I/X0Hib1nD4+\nSsww5NTLgYWStgV+QPpHdozt73bc/15g/3zzCeATtm/o5bkhhFlJ+iCwp+0Y/gpDbdQelKRxwI+A\nbYD1gEmS1ul42F3Am2y/FvgmcNRcPDeEEEKYTS9DfJsCd9i+Jy8lPYnUjZ8hLzN9PN+8gpkTvKM+\nN4QQQuimlwS1MrMuW72P2VcYtfsoaQPivDw3hKFn+xcxvBdCxcvMJW1N2sS3ZZWvG0IIYfj0kqDu\nJ+2zaFmF2TcRkpe7HgVsa/vRuXlufv48F/MMIYQwdtnuug2jlyG+q4E1lApeLkxaknpW+wMkjSct\nd32/7T/PzXM7GlnL1wEHHDCQseJnG5uxBvlni9/j2IxXZ6yRjNqDsv2CpE+RanW1lorfKmnvdLeP\nAr5KKvx4eN4M+JztTef03NFihhBCCD3NQdk+D1i749qRbd/vBezV63NDCCGE0QxlJYmJEycOZKy6\n48XPNjbjDWqsuuPFz1ZeT5Uk6iDJ/dKWEEII9ZCE52ORRAghhFC7SFAhhBD60sAkqPETJiCp8q/x\nEyY0/aOFEMJQGpg5KEmcNu2vFbYo2WWdlUZdqx9CCGHexBxUCCGEMScSVAghhL4UCSqEEEJfigQV\nQgihL0WCCiGE0JciQYUQQuhLkaBCCCH0pUhQIYQQ+lJPCUrStpKmSbpd0v5d7l9b0uWSnpW0X8d9\nd0u6XtJUSVdV1fAQQgiDbdQEJWkc8CNgG2A9YJKkdToe9giwD3BIl5d4EZho+3W2N53P9vaFKKsU\nQgjl9XJg4abAHbbvAZB0ErATMK31ANsPAw9LenuX54sBG0qcfu+9xcoqhRBCSHpJHCsD09tu35ev\n9crABZKultT11N0QQgihU09Hvs+nLWw/IGl5UqK61fZlNcQNIYQwhvWSoO4HxrfdXiVf64ntB/Kf\nf5d0BmnIsGuCOvDAA2d8P3HixL45drhp4ydMYPq991b+uquOH8+999xT+euGEMKcTJ48mcmTJ/f0\n2FGP25C0AHAb8BbgAeAqYJLtW7s89gDgSdvfy7cXA8bZflLS4sD5wEG2z+/y3DFz3EbdR3vEUSIh\nhEE10nEbo/agbL8g6VOk5DIOOMb2rZL2Tnf7KEkrAFOAJYEXJe0LrAssD5whyTnWL7slpxBCCKFT\nT3NQts8D1u64dmTb9w8Cq3Z56pPABvPTwBBCCMNpoJZ/hxBCGByRoEIIIfSlSFAhhBD6UiSoEEII\nfSkSVJhF1BkMIfSLOipJhDEk6gyGEPpF9KBCCCH0pUhQIYQQ+lIkqBBCCH0pElQIIYS+FAkqhBBC\nX4oEFUIIoS9FggohhNCXIkGFEELoSz0lKEnbSpom6XZJ+3e5f21Jl0t6VtJ+c/PcEEIIoZtRE5Sk\nccCPgG2A9YBJktbpeNgjwD7AIfPw3BBCCGE2vfSgNgXusH2P7eeAk4Cd2h9g+2Hb1wDPz+1zw3CL\n2n8hhDnppRbfysD0ttv3kRJPL+bnuWEIRO2/EMKcxCKJEEIIfamXHtT9wPi226vka72Yq+ceeOCB\nM76fOHEiEydO7DFMCCGEsWDy5MlMnjy5p8f2kqCuBtaQNAF4AHgPMGmEx2ten9ueoEIIIQyezs7H\nQQcdNMfHjpqgbL8g6VPA+aQhwWNs3ypp73S3j5K0AjAFWBJ4UdK+wLq2n+z23Hn/0UIIIQyLng4s\ntH0esHbHtSPbvn8QWLXX54YQQgijiUUSIYQQ+lIkqBBCCH0pElQIIYS+FAkqhBBCX4oEFUIIoS9F\nggohhNCXIkGFoRGFaUMYW3raBxXCIIjCtCGMLdGDCiGE0JciQYUQQuhLkaBCCCH0pUhQIYQQ+lIk\nqBBCCH0pElQIIYS+FAkqhEJK7LuKPVdhmPS0D0rStsAPmHno4He7POaHwHbAU8CHbU/N1+8GHgde\nBJ6zvWk1TQ+hv5XYdxV7rsIwGTVBSRoH/Ah4C/BX4GpJZ9qe1vaY7YDVba8p6fXAT4DN8t0vAhNt\nP1p560MIIQysXob4NgXusH2P7eeAk4CdOh6zE3AcgO0rgZfmY+AB1GOcEEIIYYZeEsfKwPS22/fl\nayM95v62xxi4QNLVkvaa14aGEEIYLnXU4tvC9gOSliclqlttX9btgQceeOCM7ydOnMjEiRNraF4I\nIYS6TJ48mcmTJ/f02F4S1P3A+Lbbq+RrnY9ZtdtjbD+Q//y7pDNIQ4ajJqgQQgiDp7PzcdBBB83x\nsb0M8V0NrCFpgqSFgfcAZ3U85izgAwCSNgMes/2gpMUkLZGvLw68Dbip9x8lhBDCsBq1B2X7BUmf\nAs5n5jLzWyXtne72UbbPkbS9pDvJy8zz01cAzpDkHOuXts8v86OEEEIYJD3NQdk+D1i749qRHbc/\n1eV5fwE2mJ8GhhBCGE6x/DuEEEJfigQVQgihL0WCCiGE0JciQYUQQuhLkaBCGAAlKqdH9fTQtDoq\nSYQQCitROR2ienpoVvSgQggh9KVIUCGEuRLDiaEuMcQXQpgrdQ8njp8wgen33lt5vFXHj+fee+5p\nLFYYXSSoEEJfqzMhxlxef4khvhBCCH0pElQIIYS+FAkqhBAaUueCk7G4uCXmoEIIoSExvzaynnpQ\nkraVNE3S7ZL2n8NjfijpDknXSdpgbp4bQgghdBo1QUkaB/wI2AZYD5gkaZ2Ox2wHrG57TWBv4Ihe\nn9uEm668fCBj1R0vfraxGW9QY9UdL3628nrpQW0K3GH7HtvPAScBO3U8ZifgOADbVwIvlbRCj8+t\n3c1X1ffLrzNW3fHiZxub8QY1Vt3x4mcrr5cEtTIwve32fflaL4/p5bkhhBDCbEqt4lOh1w0hhDAk\nZHvkB0ibAQfa3jbf/gJg299te8wRwEW2T863pwFbAauN9ty21xi5ISGEEAaS7a6dml6WmV8NrCFp\nAvAA8B5gUsdjzgI+CZycE9pjth+U9HAPzx2xgSGEEIbTqAnK9guSPgWcTxoSPMb2rZL2Tnf7KNvn\nSNpe0p3AU8CHR3pusZ8mhBDCwBh1iC+EEEJoQpQ6CiGMWZKWbboNoZxIUBWRtMxIX023L4xM0s6S\nlszff0HSKe0VUWqIP07SUoVe+2BJS0laSNKFkv4uaY8SsRpwhaRT8xTDQM1jS9q17d/kVySdLmnD\npttVp4Ee4pN0GDDHH9D2pyuM9ZccS8B44NH8/dLAvbZXqypWR9zlgb2AV9A2p2j7IwVibQEcCEzI\nsZRC+ZVVx6qbpBtsry9pc+A7wPeAL9rerGDM/wM+BrxAWoy0FHCo7UMqjnOd7Q0kvQt4O7AfcInt\n11YZpy3ersB5tp+Q9BVgQ+Cbtq8tEEvAfwIfATYBTgF+bvv2qmO1xdwSWNP2sfn/3xK2/1IgTuvf\n5JbAN4FDgK/Zfn3VsXK8FYBvASvZ3k7SusAbbB9TIl4vBr0HNQW4ZoSvytheLb9R/x54h+3lbC9L\nekM4v8pYHc4EXprjnt32VcIxwPeBLUlvBhvnP4uR9HZJUyX9Q9I/JT0h6Z8FQr2Q/3w7cKTtM4GX\nFIjTbl3b/wTeCZxL2pbx/gJxWh9cdgBOtf14gRjtvpqT05ak5HEM8JMSgZxcYHsS6YPaB4GrJF0s\n6Q1Vx5N0ALA/8MV8aSHghKrjZK1/kzsAR9k+G1i4UCyAnwO/A1rVX28HPlMw3qgGupq57V+035a0\nRL7+ZMGwm9neq60N50o6uGC8xWzXVYT3cdvn1hSr5QfAzsCNLtvdf0DSj4FtgY0lLUz5D3ALSVqI\nlKB+ZPu5QvsBf5v3Jj4DfDx/6n+2QJyW2d5YJX2zRKA8B7UHKbE/COxD2vayAXAqKelX6V3A64Br\nAWz/tTUMV8D9ko4E3gp8V9JLKPtvcjnbp0j6IoDt5yW9MNqTShr0HhQAkl4taSpwM3CLpGskrVco\n3F/zePEr8teXgepr3M/0W0nbF3x9JG2Yx74vknSIpDe0rtUwJj4duKlwcgLYDbgY2MH2o8BywBcK\nxzwSuBtYHLgk7xesvHdo+wvA5sDGuSbmU5Stidl6Y90dOKfwG+ufSEOj77S9g+3TbT9vewq5aHXF\n/p3/LRpA0uIFYrTsRurRbGP7MWAZ4L8LxnsqJ/zWz7YZULq3PaKBnoNqkXQ58GXbF+XbE4Fv2d68\nQKxlgAOAN+VLlwAH2f5HxXGeYOac1+LAv4DnmDkvVNmEu6SLRrjbtt9cVawusTcBvkFKHv9qC/r9\nil5/xN9THoKrjaQFbT9f0WvtPNL9tk+vIk6XuIuReqI32r5D0suB19iufKhb0m62T+m4tqvtU6uO\nlV/7c8CapF7Nt0lzX/9n+7BC8WqZ78qxNgQOA14N3AQsD7zb9g0l4vXUpiFJUNd3Tgh3uxb6j6Tz\ngSeBG4EXW9dtH1TR609nZqLvZNvjq4jTEXO/ke6vMPkeO3KY6hfStMVeAFiBWRfu3FsgzrW2Nxzt\nWsUx3wq8jfRv5ne2LygU5wDSPO/atteStBJpDnGLEvFyzAWBtUk/2225x92YgZ6DanOXpK8Cx+fb\newB3VRlA0g9sf0bSb+iyctD2jlXGa4u7BXCd7afy0uENgR8UejPYFzgWeAL4aY71hRKfjNusZPvV\npV7c9qqlXnsErTmLtUmLTM7Kt98BXFVVENsfruq15oakfUijCA8y80OFgfUrjLEdsD2wsqQftt21\nFFBJD3ROckIqkpQ61Dnf1bIpM1cEbygJ28cVjjlHw5KgPgIcBLSGNC7N16rUSn7/W/HrjuYnwGsl\nvRb4LHB0bstWBWJ9xPahkrYBliVNTB9P2VWK50h6W+EkCECey2sNzU62fV6JOK3en6RLgA1tP5Fv\nH0iBFZiSXsqsw84XA18vuJpvX9Kn/kcKvT6ked0pwI7MuiL3CeD/KxW0bWgd0oq6hYCnqhxSb/Nv\n224tnCk834Wk44HVgeuYudDF5LP+mjAUCSpPele252kOMVr/SaYAz9h+EWYMdZRcrvx8/ke8E2kl\n2DGS9iwUqzUMtj1wnO2b8z6Ukj4OfE5SsTk2AEn/A2wB/F++9HlJW9r+SpVxOqwA/Lvt9r/ztar9\njDSnsFu+/X5ST3jEOar5MJ3Ck+u2rweul/TLqubseow7oweT/+3vBJTaK3dKXmyytKS9SB+qf1oo\nFqThxHVrWJDUs2GZg1oL+Byzb2atfHJf0hXAf7aWsuel7eeXWJCRX/9i4DzSP943Ag+RhvwqG05p\ni3Us6cDJ1YDXAguQehobVR2rbpJuAF5n+4V8e0Hg2hK/x7aYXyYljTPypXcCJ9v+dsVxrrO9wWjX\nKox3DGn48mwKLGzJMU6xvZukG5l1SL31AabY31uXtky1/bpCr13LfFeOdSrwadsPlIoxt4aiB0Xa\nD3EEafir9Lr+Rdr3Wdl+Mq9qKmV34L3Ah23/TdKbSKv6StiTtL/kLttP5yWpRec58s8zG9uXFAi3\nFKkCCMycJyrG9v9IOpf0wQLS3+HUAqGeyb3By2DGvOUzBeK03Ju/FqbcxtJ9859vL/T6XXWsjBxH\n6nUU21NW43wXpK0Vt0i6ilk/WBSZP+/FsCSo520X2cnexVOSNnQu6yJpIwq+GeSkdBHwXkknAH8h\nbW4tEetFpZJOa0lapESMLtr3fSxCmsS9Bqi693swcK2kC0mfVicCX604BpCWttv+Z96ScHf+at23\nTNVbEkjllI7Lc1EC/gF8qOIYM1S1wnKUGK1P+Q+Th9TzSMk6pKocpbyj7fvnSX93RfaU5WT4XeA/\nSH9vRYa32xxY6HXn2UAP8WlmkdZPk4a+zmDWTwZVvxG09u2cRJrEFbAisHvbHFVVcdYiHf44ifSf\n9GTgc7YnVBmnI+ZHSZ9cVyFNpG4G/KnkPqgubViVtEpxlwKvvTLQqnN2pe37q46R4/zW9ts1a/3G\nFrtQbcPWnq9Se7uaWMkq6RpSD/RlwB9JNQ3/bft9Vceqm9L5eu/wEJ+hN+gJqtsbQEvJN4KFSGPw\nUGgvgaQXSasR97R9Z752V6mfKb/+jaRl0Vc4FR9dh7ThudRke7c2CLjZ9roFXntFUqHf9nnKy6uO\nUzelSg67MPsc7NcrjrOR7WskdV1BavviKuPlmNfa3jAvbV/U9sEl5tdUY+Hptph/LLnnqS3OZba3\n7FihCOV7bKMa6CE+F6og3oO1gXVJQ1Kl9hLsDLyHVH7oPFKvrfSKumdtPysJSS+xPU3S2qM/bd51\nvDGMI82BlaiK/S3S/rhbmXXvTukyUjsy69L23xYIcyZpVd01tI0gVK01SlAiEY1ASkVh30eaI4W0\neKdqU9q+P4i0bL+0KZJOBn7NrCM/lVYAsb1l/rP4vOvcGugeVEvu0XyctjcCUsXqEj2bA0jzF+sC\n5wDbAZfZfnfVsXK8xUlj4JNI8zLHAWeU2Dck6QzSoojP5FiPAgvZLvYmLumDbTefB+62/ccCcW4D\nXmu7ZBHVzpjfIfVIf5kvTQKutv2liuPcVHKzc5d4tR3LkhfRfA74o+3vSnol8JkSPZq2mMVW7XXE\n6VYJxK64AohGOa+uxFRIr4YlQR1N2lDXqm7+fuAF2x8tEOtG0hLsqbZfq3TGygm231p1rC6xXwbs\nSprzekvhWFuRjvk4z/a/R3t8v8u90F1sP1VjzBuADTr2zE2teom0pKOAw2zfWOXrjhBvGmmz7DW0\nrZp12Y27tVHhUkp1a2oqpBcDPcTXZhPPWnfvD5KuLxSrtaLo+Twp/RBQSzkdpw3JR+Wv0rGKDuM0\nsM/lCdIqvt8z63DKiHXzKrA0aVUdpIRfwpbAh/Ib0b8ov1eotmNZ6tzjWBdJn89zaV3nvaruHTY4\nFTKqYUlQL0ha3fafAfIwQKn9UFMkLU3a8X0NqdDpnwrFGmR173M5L3/V6dvA1LxNQKQh6BJHfGxX\n4DVHcpGkQ0ilxdqTfeVzh9S0x7FjAcFimnloZomFBK1Ve1NGfFQBNc2J9t6eIRniewuptMtdpH9Q\nE0ibIkc6RqKKuK8AlnKD5eqrkBdEFJtcHyX24nTZ51Jo/nBhYHxrVWQdlI6iaJ1KfJXtvxWKU+ex\nDd3+X7lEr0bSNR6ASibdtH+orileLXOic9WmYUhQMGOpbfvS70becMeitqW8x9sucST5SLFr2eci\naQfScfYL215N0gbAAbbfVWWcLnFXZuZiAqD6Khlq4NiGuigV2K1lj2PdlMqYrUL6N38pcEnJecS6\n5kTnxlAM8Un6JPDLVk9G0ssk7Wn78IabNlYsLOm9wObqcghe1cteO8iprNKewOGtfS4F4nydtEn3\nIgDb10lao0CcGSR9l1Sq6mZmXdpedRmn2o9tyAl/PdJWC3LcSvddZa1Vnu0VRww0NrFfFdtb5V79\nJqSVwWdLWsL2iKvu5lMdc6I9G4oEBexl+8etG7YfVaoOHAmqNx8j7TNZmllLvUB6MyiaoGra5/Kc\n7cc0a3H20sML7yT1akr35us+tuEIYDFga9Lc0Lup8Jyrdv08wT+/8rDsG/PX0sBvST2pUuqaE+3Z\nsCSoBSTJeTwzd12LFLGUtBmp0kHrjJ+lgFfZvrJEvDo4FRm9TNIU28fUHP4zwBdJe7tuzgtcSswd\n3ippN2CcpNVI5bGuKBCn3V2k7Q+lE1TdxzZsbnt9STfYPkjS9yhUH0+pEPN+pLnD/5K0JinpNzq5\nX5HJpIVW3wbOKbmdQ+mT2WWk8mWtOdH9S82J9moo5qDyiqIJwJH50t7AdNufLRBrKukQulYyHAdM\nGYR9E3m44WPMevDdESUWLHSJvZjtpwu+/uLA12g72gA4qHDM00h75i5k1vmTEmVz6jy24Urbr1c6\nemZn4BHSh7bKh0xzpYVrgA/YfnVOWJe70FEidcqrgbcg/X/bhDQM/CfbpYoY32j7NSVee14NSw9q\nf1JS+ni+fQFp6KGEGT01mFEBfFB+z4eTPvG3hkbfTzrRt/INzy15eO8YYAlgvNLJwXvb/kSVcfIG\n3f3zV13OYuZx70W53mMbfpvfXA8hzXuZcj221W3vLmkSQJ6vLF3yqxZ5yPku0j7KVYDNSf//SrlW\n0ia2ry4YY64MRQ+qTpJOJ3XNW8d7fALY2vY7G2tURSRd37Hhueu1imNeSZrDOKtVXkYFSvfkBRH7\nMfuGz7dVGacJqv/YhvbYLyGdkVbkhF1JlwNvIZU62lDS6sCJtjctEa9OOTlNI807XUrahlBymG8a\nsCbpCJGnKL+he1SD8sm+qy5VCNq50Bvrx4AfAl/JsS8E/qtAnCbUueF5BtvTOz4Ul4j5K1JP7YRC\nrz+bPF/ybWYWFgagQGmZg6nx2Ia8NeBnwP/l6iYl59gOJG2wXlXSL0lDYkUP0azRGq0l3zXZpsZY\nPRnoBEX3KgQidZm/WCKg7YdIVcYH0X+TqgTMsuG5cMzpkjYHrFT0d19m7rSv0ou2DyvwuiM5llQV\n+/8nrXj7MKlie9UerCs5ZbuTfparJU0h/Zznu8Bwje3zc0LcjPRvcl/bD1cdpwl1JSelw0c/BqwB\n3AgcY/v5OmKPZmiG+CS9jnQ0+q6kU2dPs/2jCl+/1vpZTal7w7Ok5YBDgf8kvQGdT3oTqqTwaF5l\nCam46QPMvuGzyOF+OfY1tjdqn5yusjJC2561rUgHZxY9tqFL/HGkD4k/IfVKjwUOrXITraQL3VEY\nudu1MGd5oclzpGHE7YB7bO878rPqMdA9KHU/dVa2ty4QrrH6WXXKCam20k3503DJ01FvZtZKzu0r\npEw6wLCUf+U38TskfQq4n7QYpCrte9aeJq3iaym6f03S+qRe1PbAaaTyOVsCfyCd6TW/r78Iaa/V\nckpV/Ft/f0sBK8/v6w+Zdds+IB1DoT1r82Kge1Bq4NTZUC2lunF7MfvihUrPxGmCpE1IH2yWBr5B\nenM9xHbp/VdF5SG3x0hzeqe197Ilne4KTmCWtC9pj9xKpMTeSlD/BH5a5ehI3SSNWEHf9vcrjjfL\n8SGdt5s06AnqnaT5oC1IE6knAUeX2H0u6TeMfCT0jlXHHAZ5ldalzH620GkVx3kJaSvClqS/x0tJ\nb3TFhjAlbegyFb4747ySNEy6Geln+xPpUL9SxWJfafuuEq/dJdY+DcwdFqVUOxHSUPomzNyK8A7S\nSr49Ko73AmnVHqREvyipx934ke8DnaBaVMOps0oH+M2R6z0Gu4i8hP4YUjXxuiZwr6tj06Wkk0jz\nMyfkS+8S6sZYAAAU/klEQVQFFrVdbMFLLimzImkF4cm2byoU5wrgx8CJ+dJ7gH1sv75QvG8BB9t+\nLN9+GfBZ218pFG9zZu9hH1ciVp0kXQLs0FaVZkngbNtvGvmZg2MoElQ71Xjq7KCR9J+keYXNSOfw\nHGv7tsIxv0mqDHBO4Ti32F53tGsF4q4I7EZa+bYUKVF9s+IYN3TuZSm5f01djkQvNWwk6XhgdeA6\nZvawPQiLkiTdBqzf6sXnXv4Nttce+ZmDY+gSVGk17m1pjKSXknqjXwamk6oEnFCi5JHSQXGLk3o3\nz1Fo2EHSicD3W7voJW0E7OeKj/UYIf5rgM+TPjhVWidSqWr6o6QhbpOS4ctIlR4qP5pC6diGTdre\nWBcllftar8o4+bVvJU3yD9wbmaQvkz68nJEvvRM4xfa3mmtVvSJBVUzSZczc2/IO8t4W219rtGEV\nkbQssAepzNFfmbk66zW2JzbYtPki6SbgVaQtCACrkRYwPEdKiCU+/b+KlCx2IdWrO5m0qOChiuOM\nNNfkqj88Sdqf9G//2Hzpw6RKIAdXGSfHOhX4tO0Hqn7tfiBpQ1I1c0jnQU1tsj11iwRVsdJ7W5ok\n6QzSxO3xwM/b3xSUKp1vXCBmt8TwOGmvRmWbCXOJnDlygZNNJf2J1Ks51fZfq379JknalrR3DeAC\n278rFOci0rL1q5h1j9dALEpSjSch96OB3gfVkNJ7W5r00865IOXj4Eskp+xwYEPSDneA1wA3AS+V\n9PGqFrqUSEA9xHxD3TFrNJVU2NT5+1IOLPjajVLbScik3uhCpEU8Y/4k5F5FD6piXfa2vJS0omlM\n722B7hPdpfdM5JWDX7V9c769Lun0288Dp9exwq+UQZ2vVDpX6xBS0WSRhqj+2/avmmzXWKN0cvTr\ngGs9s1DybAteBln0oCrmmaXqn2RAilbmlWYrA4vmklHtu/YXKxx+rVZyArB9i6R1bN+lsX+qQl21\n+Or2ZdIiiYdgxmbr35OW01dC0mW2t8yLaNo/ZTe+d6dCtZ6E3I8iQVVE0ojn+ozxMfFtgA+RzqRp\n38X+BPClwrFvlvQT0lwNpEUFt+Qlt8UPSixsUdsXSpLte4ADcxWGShbUzGH+boaCm4THdSz0eISK\nE6/tLfOfS1b5un2m20nIpc6x60sxxFcRSX8nLbk+EbiSmb0MYGA26u5SdQWHHmIuSjpTa8t86Y+k\nealngcVsPzmfr/8o3SuAtD6JLzM/rz9K7MtJP9evSDXq7ge+U9U+l7yAANLw4cbA9aSfa33Ssu8i\nc2BKJ1ivz8yNwbuT9u/UeRjkQFCNJyH3o0hQFZG0APBW0v6g9YGzSQen3TziE8cASXvYPkHSZ+le\nqb3S2mB1yn9vc2S72NlQdc1X5nm8A2zfmG+/GjjQ9rurjNMRcxdmTuZfavuMkR4fZifpu51Jvdu1\nQRYJqoA8/DSJNFF8kMdw4UoASXvbPrKtRtgsbB9UMHatCwkkLdMRZ8wv/5Z0c+cm2W7XQn+Zw6Kk\noVokEQmqQjkx7UBKTq8gFXn8me37m2zXWFbXxmdJO+QYq5DmTFYGbre9TpVxcqxaCwvnKhlPMbPO\n4PtI+2kmVRmnLV4tR8zn3u/vXeb4nMZI+jhpWPuVQPv2hyVJR9tXWiy2n0WCqoik44BXA+cAJ7lQ\n4c8mqYGjL+ra+JyX9L6VdPLr6/LY/26296oyTo5Va2FhpbOTPg60ioxeAvzE9rNVxmmLdyc1HTEv\n6UJgZ9uPl45Vl1xK7GWkkYMvtN31RNVlqfpdJKiKKJ091SpZP5DLXlXT0RddYhZbSNAWZ4rtjSVd\nD2yQl/cWKagqabzte6t+3X4h6Y+2a9lMKulM0l6hC5j5/28gTrCW1PWwzEH+t9MplplXxPYg7F8Z\nzWINTNDuS9pr9WnSQoI3Ax8sEOdxSUsAlwHHSXoIeKZAHEhHr28IIOk027uUCCLpFNu7SbqR7otb\nKp3L0Mwj5qcoHSNexxHzp1PwZOCGnc3M054XIdWHvA0YmrnD6EGFnqmmoy+aoHTWztOk/TofIK2o\nO87pyPmqY804jkJdjqaoMM7LbT8gaUK3+/PeqyrjHTvC3S41FCxpYWCtfPM2F6iq3w/yvrZP2P5o\n022pSySo0DPVdPRFjlXrxmdJ37L9pdGuVRRrxuqs0qWi2mKuQDqdFdKprJVWTO+ItYXtP452raJY\nE4FfAHeT/j2uCnzQ9iVVx+oH7XOxwyASVOhLdW98nsOS3lJzUK0jttuP14Zyq91qrY1XZ83GXHnj\nvc4HZ0pai7T/cBBOD9iv7eY40rDwsra3aahJtYs5qDCqXPtu2pxK5xQqmbMiMzc+v5dCG58l7Q18\nDFhLUvvPsSRpMUjlbI+4ObiA4rXx8uu+AdgcWL7jzXUpoNTPvJDbTnW2fbukhQrFqlt7GafnSf8H\naq3k0rRIUKEXnyUtL/9el/tMWrhQqVzB4TzgvLaNz5MlVb3x+RTgQrov6S02DFaz4rXxsoVJR8ss\nyKxvrv8ESlWtmCLpaGbd4zWlUKxaldwAP1bEEF/oW3VvfJa0HjNPL710EMpUQf218SRNqHoBxgix\nXgJ8kpm1Gi8FDnc+bn4sqnsjdz+LBBVG1bZ8uKsSy4fr3vgs6ZOkN7pf50s7AT+2fXjJuHWpszZe\nngf6HLNv6K68pz2I6t7I3c8iQYVRNbF8uO6Nz5JuADZ3ro6e90RdPkx1z6qSNzsfwewbuiub05vT\n3q62WPH3NgBiDiqMynbtBy82sPFZwL/bbreW0Y95ddXGa/O87Z8Ueu2Wtxd+/cbUvcG6n0UPKsyV\nXFR1PWat+P315lo0fyQtaPt5SZ8nzXW1Vkm9i7Rq8H+ba1016qyNl+MdCDwEnMGslSSK1JGrc49X\nHereYN3PIkGFnkk6glR2aGvSyZ7vJr0h7Nlow+ZDx6bZTWmbbLd9dXMtq06dtfFyvL90uWwXOCKl\n7j1eoV6RoELPWmfRtP25BHCu7TeO+uQ+VbLUUL+QdChpX1kdtfFqlee73tq5x6vEBuu65IotI82v\njfnC072KOagwN1rFU5+WtBJpP83LG2xPFTo3lc7CY/i04DZLkapVvK3tmilYZFXp1N7OQyaPKxCq\nrj1etbG9JICkbwAPAMeTeofvY+z/f5srkaDC3PitpKVJQyrXkt7kjm62SfNtAdLm0oFYENFN3Ytc\nlE5enkhKUOcA25GrxBcId56k3zHrHq9zC8Rpwo4dPcGf5B5jpYd19rMY4gvzJG+QXMRj/KC4uoq1\nNikfWLgnsy9uKVVd/EbgtcBU26/NixhOsP3WQvF2Zta5w2J7vOqUz0L7MXAS6cPgJOCTtjdvtGE1\nGtNd4VAvSZ/MPSjyTv1xkj7RcLPm18D2nNocT5qD2ga4mHSs/RMF4z1j+0XgeUlLkVb0rVplAElr\nSNoC0lya7f1s7wf8XdLqVcZq0HuB3YAH89eu+drQiAQV5sZeth9r3bD9KKlG31j2lqYbUIM1bH8V\neMr2L0jlo15fMN6U/EHmp6TNutcCf6o4xg9INf46PZ7vG/Ns3217J9vL2V7e9jtt3910u+oUc1Bh\nbiwgSc7jwpIWIBUIHbNK7c3pM60D/B7Lixf+Rtq0W4TtVq/6CEnnAUvZvqHiMCvYvrFL7BslvaLi\nWKEhkaDC3DgPOFnSkfn23vla6G9HSXoZ8FVSwd0l8vfFSNoReFO+eTFQdYJaeoT7Fq04VmhILJII\nPZM0jpSUWsNiFwBH56MxQp+StECdf0eSvkOq7PDLfGkScLUrPJ1Y0onAH2z/tOP6R0n7onavKlbd\nJO1r+9BSpxCPJZGgQhhwku4l935Jb+pF/9Pnwrsb5IUSraHgqVXWkMsrA88g1U9sFaHdmDTk/C7b\nf6sqVt0kXWd7g2FYYTqaGOILo4rK0WPeOqTiqp8EfpbPGzrJ9mUFYy4NtOb3Xlr1i9t+ENhc0tak\nY1kAzrb9h6pjNeBWSXcAK+Vk39Iq8js0/9+iBxVGNaeilS3DVLxyrMtzUYcC7yt19LykScB3gItI\nb6pvAr5g++QS8QaRpBWB3wGzHU44TP/fIkGFeSZpS2CS7U823ZYwsnwI3u7AtqQj0U+2fdrIz5qn\nOCLts3qeWSuMj9khtyZJWhhYK9+8zfZzIz1+0ESCCnNF0utImwV3Bf4CnG77sGZbFUYi6W5gKnAK\ncJbtp0Z+xnzHu9H2a0rGGAb5Q8VxwN2knuiqwAdtX9Jku+oUc1BhVPkI70n562HSZLtsb91ow0Kv\n1rfdbVNrKddK2mRQjitp0PeBt9m+DWb8PzwR2KjRVtUoelBhVPn49UuBPW3fma/dVeJ8n1C9Bmrx\nTQPWJH3yf4ohnNyvQutYm9GuDbLoQYVe7Ay8B7goVwY4ieGoYTcojgemkWrxfZ10bEPJ03W3Kfja\nw2SKpKOBE/Lt95HmD4dG9KBCzyQtDuxEGup7M2l8/Azb5zfasDCi1qGMbQdNLkSq+r1ZxXEWAT4G\nrAHcCBxj+/kqYwyTfGLAJ2mr1A4cngs1D4VIUGGe5OXKuwK72x6GgqtjlqSrbG8q6RLgE6RafFdV\nPUQr6WRS3b9LSWdA3WN73ypjhOESCSqEAZfL/5wGrA8cS6rF9zXbR1QcZ8bqPUkLkpLgUFdCCPMn\nElQIoRKdpXmiVE+YX5GgQhhQkvYb6X7b36843gukVXuQFtEsCjzNzFV8S1UZLwy+WMUXwuBass5g\npUonDRtJ67fOz8oLWvYHNgVuAr5p++km21en6EGFMKAkfdf2/pJ2tX1q0+0JvWkfGpX0PWBZ0tzh\nO4FlbX+gyfbVKRJUCAMqV6FfH7gm5oLGjta2gPz9dcAmtp/LdQ6vj426IYRBcB7wKLCEpPZSRzEn\n1N9eKuldwDhg0VaBWNuWNFQ9iuhBhTDgJJ1pe6em2xF6I+nYjktfsP1gPoLjl8O07zASVAghhL40\nrukGhBDKkrSzpDskPS7pn5Ke6BjyC2OEpLc23YY6RQ8qhAEn6U7gHbZLFogNNZB0r+3xTbejLrFI\nIoTB92Akp7FD0llzuou05HxoRIIKYfBNyYVcfw3MqIRt+/TmmhRG8EZgD+DJjusibdgdGpGgQhh8\nS5FKDr2t7ZqBSFD96QrgadsXd94h6bYG2tOYmIMKIYTQl2IVXwgDTtIqks6Q9FD+Ok3SKk23K4TR\nRIIKYfAdC5wFrJS/fpOvhT4kaR1J50o6W9Lqkn4u6TFJV0l6VdPtq1MkqBAG3/K2j7X9fP76ObB8\n040Kc3QUcDhwAvAHUsmqlwHfAH7UYLtqFwkqhMH3iKQ9JC2Qv/YAHmm6UWGOlrT9G9snAs/ZPsnJ\nb0iJamhEggph8H0E2A34G/AA8G7gw422KIyk/VytzkMlF66zIU2LZeYhDDjb9wA7Nt2O0LMfS1rC\n9pO2D29dlLQG8PsG21W7WGYewoCS9LUR7rbtb9TWmBDmQQzxhTC4nuryBbAn6Rjx0KckbS3pdEk3\n569fSZrYdLvqFj2oEIaApCWBfUnJ6RTge7YfarZVoRtJO5BW630duJZU4mhD4CvAp2yf02DzahUJ\nKoQBJmkZYD/gfcAvgENtP9psq8JIJE0G9rV9fcf19YHDbG/VSMMaEIskQhhQkg4Bdibtq3mN7c7i\no6E/rdiZnABs3yBphSYa1JToQYUwoCS9SKpe/jypOOyMu0iLJJZqpGFhRJKusb3R3N43iKIHFcKA\nsh2LoMam1edwJpSAV9bdmCZFDyqEEPqIpBHnmLodwzGoIkGFEEIfkrQIsEa+eaftZ5tsTxNiCCCE\nEPqIpAUlHQzcR1p5eRwwXdLBkhZqtnX1igQVQgj95RBgGWA12xvZ3hBYHVga+N9GW1azGOILIYQ+\nIukOYC13vDlLWgCYZnvNZlpWv+hBhRBCf3FncsoXX2DW7QIDLxJUCCH0l1skfaDzYj7Ha1oD7WlM\nDPGFEEIfkbQKcBrwDHBNvrwxsCjwLtv3N9W2ukWCCiGEPiTpzcB6+eYtti9ssj1NiAQVQgh9RNI1\nwGXAucDkYdz/1BIJKoQQ+oikBYEtgW2BrYFHgN8B59q+vcm21S0SVAgh9DFJK5GS1bak/VBX2v5E\ns62qRySoEEIYIySNA95g+49Nt6UOkaBCCKGP5CG+PYF3ASvly/cDZwLH2H6uqbbVLRJUCCH0EUkn\nAo+R6vDdly+vAnwQWMb27k21rW6RoEIIoY9Iut32WnN73yCKShIhhNBf/iFp1zzfBKS5J0m7A482\n2K7aRYIKIYT+8h7g3cCDkm7PxWMfBHbO9w2NGOILIYQ+JWlZANuPNN2WJkQPKoQQ+oykN0laOyem\ndSR9TtIOTberbtGDCiGEPiLpB8CmwIKkChJvIZU92gqYavu/G2xerSJBhRBCH5F0M/BqUvXy+4GV\nbT+dj3ufavvVjTawRjHEF0II/aV1YOGLrdv5zxcZsvfsBZtuQAghhFmcLelSYBHgaOAUSVeQhvgu\nabRlNYshvhBC6DOS3kDqSV0haXVS2aN7gV/ZfnHkZw+OSFAhhBD60lCNZ4YQQr+TtKqkkyRdKulL\neXFE675fN9m2ukWCCiGE/vIzYDKwD/By4OLWhl1gQlONakIskgghhP6yvO0j8vf7SNoDuETSjsxc\n0TcUIkGFEEJ/WUjSIrafBbB9gqS/kTbtLt5s0+oVQ3whhNBfjgZe337B9u+BXYGbGmlRQ2IVXwgh\nhL4UPagQQugzkraWdLqkm/PXryRNbLpddYsEFUIIfSRXLf8Z8BvgvcD7gHOAn0navsm21S2G+EII\noY9Imgzsa/v6juvrA4fZ3qqRhjUgelAhhNBfVuxMTgC2bwBWaKA9jYkEFUII/eWpebxv4MQ+qBBC\n6C+rSzqry3UBr6y7MU2KOagQQugjkkacY7J9cV1taVokqBBC6EOSFgHWyDfvbFWWGCYxBxVCCH1E\n0oKSDgbuA34BHAdMl3Rwe2XzYRAJKoQQ+sshwDLAarY3sr0hsDqwNPC/jbasZjHEF0IIfUTSHcBa\n7nhzlrQAMM32ms20rH7RgwohhP7izuSUL77AkB23EQkqhBD6yy2SPtB5MZ8LNa2B9jQmhvhCCKGP\nSFoZOB14BrgmX94YWBR4l+37m2pb3SJBhRBCH5L0ZmC9fPMW2xc22Z4mRIIKIYTQl2IOKoQQQl+K\nBBVCCKEvRYIKIYTQlyJBhRBC6EuRoEIIIfSl/wdCOXrhNboS1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x240a11b9908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Feature Importances')\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], color='lightblue', align='center')\n",
    "plt.xticks(range(X_train.shape[1]), feat_labels, rotation=90)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
