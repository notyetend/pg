{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera의 Neural Networks for Machine Learning 강의를 정리한 내용임.   \n",
    "2017.01.16. by Dongwan Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week15. Modeling hierarchical structure with neural nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15a, From Principal Components Analysis to Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신호처리에서 매우 많이 이용되는 PCA에 대해 알아보겠다. PCA의 아이디어는 high-dimensional data를 훨씬 작은 dimension의 data로 표현해보겠다는 것이다. 특히 데이터가 high himensional space에서 linear manifold 근처에 분포할 때 이런 방법이 유용하다. 만약 어떤 데이터에 대한 이런 manifold를 찾을 수 있다면 manifold에 데이터를 투사(projection, 그림자를 내리는 것)해서 이것으로 데이터를 표현하겠다는 것이다.\n",
    "\n",
    "이런 projection과정에서 정보를 조금 잃기는 하지만 데이터가 manifold에 orthogonal하므로 manifold 방향으로 data의 variation이 작고 정보의 유실량이 많지는 않다. 앞으로 다루겠지만, 일반적인 주성분 방법(Principle components method)를 이용해 이런 projection을 할 수도 있고 혹은 linear 한 hidden / output unit을 포함하는 hidden layer가 하나인 neural net을 이용해서도 이것을 할 수 있는데 Neural net을 이용할 경우 여러가지 장점이 있다.(input space에서 curved manifold를 다룰 수 있게 해 줌)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Principal Components Analysis</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N 차원의 데이터가 주어졌을 때, 이 데이터에서 variance가 큰 순으로 M개의 orthogonal direction을 찾는다.(variance가 작은 N-M개의 direction은 무시한다.)\n",
    "\n",
    "이렇게 찾은 M개의 direction은 낮은 차원의 subspace를 만들게되고, N차원의 데이터를 M차원의 M개의 principal direction(주성분 방향)으로 투사(projection)하여, 투사된 데이터를 새로운 (축약된) 데이터로 사용한다. 따라서 이 과정에서 N-M개의 차원 방향으로의 정보는 잃게 된다. 하지만 그 양이 많지는 않다.(많지 않도록 M을 선택하므로...)\n",
    "\n",
    "N-M개의 방향에 대해서는 정보를 잃게 되는데, 이때의 error를 원래의 data point와 projected data point(mean value) 사이의 거리의 제곱으로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A picture of PCA with N=2 and M=1</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_pca1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Using backpropagation to implement PCA inefficiently</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural net을 이용해 PCA를 만들어볼 수 있는데, 아래와 같다. Input vector는 N개의 unit을 갖고 hidden layer는 M개의 hidden unit을 갖는다. output layer에서는 원본 데이터에 대한 reconstruction을 출력하게 된다.(projected data) 이때 원본 데이터와 출력 데이터 사이의 squared error를 최소화 하도록 (M이 정해져 있을 때) weight을 조절하는 것이 목표가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_pca_with_nn.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 hidden layer와 output layer에 linear unit을 사용할 경우 이 NN은 데이터에 대한 squared reconstruction error를 최소화 하는 linear function을 학습하게 된다. PCA와 비교해보면 M개의 hidden unit이 만들어내는 space는 PCA의 M개 주성분이 만들어내는 space와 동일하지만, weight vector들은 서로 orthogonal 하지 않고, 각 방향은 (PCA와 달리) 동일한 variance를 갖는다.\n",
    "\n",
    "이런 NN에 Stochastic gradient descent로 optimize할 경우 데이터가 작을 경우 PCA보다 효과적이지 않지만 데이터가 아주 커질 경우 PCA보다 효과적일 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Using backpropagation to generalize PCA</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN을 PCA에 사용해서 얻는 이점이 무엇일까?     \n",
    "code(보통 linear unit을 사용) 앞 뒤에 non-linear layer들(보통은 logistic unit들을 사용)을 사용할 경우 non-linear manifold 주변에 분포하는 데이터를 효과적으로 나타낼 수 있다. 아래와 같이 NN을 구성하고 input vector와 output vector 사이의 squared error를 최소화 하도록 NN을 학습시킨다. \n",
    "\n",
    "흥미롭게도 이방법은 unsupervised learning(PCA)를 하기 위해 supervised learning(input vector라는 true output이 주어진)을 사용하는 방법이라고 할 수 있다.\n",
    "\n",
    "input vector에서 code까지의 부분은 encoder라고 할 수 있는데, non-linear mapping을 이용해 input vector를 code로 바꾸는 역할을 한다. code에서 output vector까지의 부분은 code를 이용해 input vector에 대한 reconstruction을 만들어내는 역할을 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_pca_with_nn3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15b, Deep Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Autoencoder를 학습시키는 방법에 대해서 알아볼텐데, 1980년대 중반에도 이런 아이디어가 등장 했지만 당시에는 PCA보다 더 나은 성능을 낼 만큼 이런 network를 학습시킬 수 없었다. \n",
    "\n",
    "그런데 Hinton group에서 deep network에 layer by layer로 pre-training 기법을 고안해 낸 후, Russ Salakhutdinov(러스 셀러쿠디노브)와 Hinton가 pre-tranining을 deep autoencoder에도 적용해 보았고 PCA보다 좋은 성능을 얻을 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Deep Autoencoders</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep autoencoder는 효과적인 비선형 차원 축소 방법으로서 효과적인 weight 초기화 방법(pre-training, Echo-State nets 등)과 backpropagation을 이용해 학습시킬 수 있고 그 학습 속도와 encoding 성능이 좋다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_deep_autoencoder1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The first really successful deep autoencoders</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST hand-written dights 데이터를 이용해 deep autoencoder를 만들어 보았는데, 초창기 성능이 좋았던 모형은 아래와 같다.    \n",
    "우선 784 pixel짜리 image를 입력으로하여 3개의 hidden layer(각각 1000, 500, 250 units)를 거쳐 code layer의 30개의 real valued activity로 변환한다. 그리고 다시 3개의 hidden layer를 통해 784 pixel의 reconstructed image를 만들어낸다. 이때 encoding layer 사이의 weight들($W_1, W_2, W_3, W_4)$)을 초기화 하기 위해 4개 층의 RBM을 사용 했고, 이들의 transpose를 decoding layer 사이의 weight에 사용했다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_deep_autoencoder_mnist1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A comparison of methods for compressing dight images to 30 real numbers</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림의 첫번째 줄은 원본 이미지 이고, 두번째 줄은 앞서 소개한 deep autoencoder를 사용한 reconstruction이고, 세번째 줄은 PCA를 사용한 결과이다. deep autoencoder를 사용한 결과가 PCA를 사용한 결과보다 원본 이미지와 유사함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_deep_autoencoder_mnist2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15c, Deep autoencoders for document retrieval and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep autoencoder를 document retrieval(등장 단어의 수를 토대로 문서간의 유사성을 판단)에 사용하는 문제에 대해 알아보자. Deep autoencoder를 사용하기 이전부터 문서에서 추출한 word count vector에 PCA를 적용하여 document retrieval을 하는 LSA(latent semantic analysis)라는 방법이 있다. \n",
    "\n",
    "Deep autoencoder가 PCA보다 좋은 성능을 보였기 때문에 document retrieval에서도 좋은 성능을 보이지 않을까 하는 궁금증에서 Russ Salakhutdinov(러스 셀러쿠디노브)와 Hinton이 Deep autoencoder를 document retrieval에 적용해 보게 된다. 그 결과 10개의 code를 사용하는 Deep autoencoder가 50개의 component를 사용하는 LSA보다 더 나은 성능을 보이는 것을 확인 할 수 있었다. 또한 단 2개의 component를 사용하여 document를 시각화 할 수 있는데, 이 경우에도 Deep autoencoder를 사용하는 경우 더 좋은 시각화 결과를 만들어내는 것을 알 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>How to find documents that are similar to a query document</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특정 document와 유사항 문서를 찾는 문제를 어떻게 풀 수 있을까?\n",
    "\n",
    "우선 각 document를 'bag of words'(vector of word counts ignoring order)로 바꾼다. 이 과정에서 the, over과 같은 stop words들은 무시하고 문서의 topic을 결정하는데 의미를 갖는 단어들만 포함 시킨다.\n",
    "\n",
    "예를들어 아래와 같은 word vector를 만들 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_word_vector1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 모든 document에 대한 word vector를 만들고, 특정 document(query document)와 다른 모든 document를 비교한다. 그런데 document에 들어있는 단어의 수가 많을 것이므로 큰 vector간의 많은 비교 연산이 필요하고 이 연산은 느릴 수 밖에 없다. 그래서 word vector를 (가능한 큰 정보 유실 없이) 조금 더 낮은 dimension의 vector로 바꿔 표현할 수 없을지 생각해 보게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>How to compress the count vector</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "high dimensional vector를 lower dimensional vector로 바꾸기 위해 deep autoencoder를 사용할 수 있고 아래와 같이 중간에 10개의 code를 갖는 deep autoencoder를 생각해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_deep_autoencoder2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림과 같이 길이가 2000인 word vector를 입력으로 받아 길이가 10인 실수 vector로 변환하고 다시 이를 이용해 길이가 2000인 word vector를 reconstruct하도록 network를 구성한다. 이런 network를 학습시킨 후, 각 document의 10개의 숫자만을 이용해 document간의 유사성을 비교하게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The non-linearity used for reconstructing bags of words</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image pixel과 달리 word count의 scale이 문서마다 제각각이므로, 각 문서의 전체 단어 수 N으로 word vector를 나눠준다. 이렇게 하면 word count vector가 probability vector로 바뀌게 된다. 즉 어떤 document를 단어를 하나 뽑았을 때 그 단어가 나올 확률을 의미하는 vector로 바뀌게 된다. \n",
    "\n",
    "그리고 network의 output layer에 길이가 2000인 softmax를 배치하면 기대하는 입력값에 대응하는 word proabaility vector를 얻게 된다. \n",
    "\n",
    "또한 첫번째 RBM을 training할 때 [visible to hidden weights]들을 [hidden to visible weights]보다 N배 크게 하는 trick을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Performance of the autoencoder at document retrieval</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로이터의 business document 400,000건을 이용해 길이가 2000인 word vector 400,000개를 만들 수 있고 이들을 autoencoder의 입력으로 하여, 길이가 10인 실수 vector 400,000개를 만든다. 이제 특정 document를 하나 고르고 이것과 다른 document vector간의 cosine값을 구한다. 이 cosine 값으로 단어들을 분류해볼 수 있다. 이 결과를 실제 수작업으로 분류한 결과와 비교해 볼 수 있고 그 정확도를 확인해볼 수 있다. (또한 LSA와 비교)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Retrieval performance on 400,000 Reuters business news stories</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSA-50D, LSA-10D와 비교해보면 Autoencoder-10D의 accuracy가 더 높음을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_deep_autoencoder3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>First compress all documents to 2 numbers using PCA on log(1+count). The use different colors for different categories</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림은 LSA(w/ 2 component)를 이용해 2차원으로 축소한 후 시각화 한 결과인데, 같은 종류의 문서들이 많이 섞여 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_2d_LSA.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>First compress all documents to 2 numbers using deep auto. The use different colors for different document categories</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep aucotoencoder를 사용하여 시각화한 결과를 보면, LDA에 비해 그 구분이 명확함을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/15_2d_autoencoder.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15d, Semantic hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Finding binary codes for documents</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Using a deep autoencoder as a hash-function for finding approsimate matches</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Another view of semantic hashing</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15e, Learning binary codes for image retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Binary codes for image retrieval</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A two-stage method</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Krizevsky's deep autoencoder</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Reconstructions of 32x32 color images from 256-bit codes</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>How to make image retrieval more sensitive to objects and less sensitive to pixels</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 15f, Shallow autoencoders for pre-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neep neural net을 pre-training하는 또 다른 방법에 대해 알아보자. 앞서 RBM에 CD(Contrastive Divergence)를 적용해 pre-training하는 방법에 대해 알아봤었는데, 이 방법이 소개된 후 사람들이 pre-training하는 다른 많은 방법들을 발견해 낸다. 특히 weight들을 잘 초기화 하면 pre-training 자체가 필요 없게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>RBM's as autoencoders</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Denoising autoencoders</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Contractive autoencoders</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Conclusions about pre-training</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
