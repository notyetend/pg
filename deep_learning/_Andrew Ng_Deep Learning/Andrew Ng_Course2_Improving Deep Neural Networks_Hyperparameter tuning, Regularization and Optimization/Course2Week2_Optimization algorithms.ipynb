{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coursera  | Andrew Ng's Deep Learning Class | Course2. Improving Deep Neural Networks_Hyperparameter tuning, Regularization and Optimization | Week2. Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1]. Optimization algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-1]. Mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번주에는 최적화 알고리즘(optimization algorithm)들에 대해 알아볼 것이다. 전에도 언급했듯 머신러닝을 적용하는 것은 대단히 경험적이고 반복적인 과정이다. 즉 잘 동작하는 모형을 만들기 위해서는 다양한 조건들을 바꿔보고 그때마다 모형을 훈련 시키는 과정이 필요하다. 따라서 모형을 빠르게 훈련시키는 것이 중요하며 빅데이터를 다뤄야 한다면 그 중요성은 두말할 나위 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 처리를 벡터화 하면 for-loop와 같은 명시적 반복문을 없앨 수 있고, 연산 속도가 빨라진다. 여기서 빨라진다는 것은 $\\frac{dw}{dL}(=\\text{dw})$를 계산하고 $w$를 한번 수정(one little step of gradient descent)하는 속도가 빨라진다는 것이다. 그런데 데이터 건수가 매우 많아지게 되면 벡터화를 하더라도 $w$를 한번 수정하기까지 시간이 많이 걸릴수밖에 없다. 예를들어 데이터 건수가 5백만건이라면 $w$를 한번 수정하기 위해 5백만건 데이터에 대한 $\\text{dw}$를 계산해야 한다. 또한 좋은 $w$값에 수렴할 때 까지 이런 처리를 반복해야 하므로 최적화가 끝날때까지 많은 시간이 소요된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 문제에 대한 해결책으로 $w$를 한번 수정하기 위해 전체 데이터에 대한 $\\text{dw}$를 계산하는 것이 아니라 일부 데이터에 대한 $\\text{dw}$를 계산한 후 $w$를 수정하고, 다음 일부 데이터에 대한 $\\text{dw}$를 계산한 후 $w$를 수정하는 것을 반복하는 접근을 생각해볼 수 있다. 이때 일부 데이터(baby training set)를 mini-batch라 한다. 예를들어 전체 5백만건 데이터가 있다고 할 때 mini-batch 크기가 1000이면 전체 데이터는 총 5000개의 mini-batch로 나뉘게 된다. 이 경우 1번째부터 1000번째 샘플에 대한 $\\text{dw}$를 계산하여 $w$를 수정하고, 1001번째 샘플부터 2000번째 샘플에 대한 $\\text{dw}$를 계산하고 $w$를 수정하는 과정을 5000번 하게 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터 세트에서 $X$에 대한 $1, 2, i, \\cdots$번째 mini-batch를 표현하기 위해 $X^{\\{1\\}}, X^{\\{2\\}}, \\cdots, X^{\\{5000\\}}$와 같이 중괄호(curly brace)를 사용한 표기법을 사용할 것이고, 마찬가지로 $Y$에 대한 mini-batch를 $Y^{\\{1\\}}, Y^{\\{2\\}}, \\cdots, Y^{\\{5000\\}}$와 같이 표기할 것이다. 그래서 $t$번째 mini-batch는 $X^{\\{t\\}}$와 $Y^{\\{t\\}}$ 의 쌍으로 구성된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 강의에서부터 등장했던 표기법들을 정리해보면       \n",
    "$x^{i}$는 i번째 샘플을,      \n",
    "$z^{[l]}$은 l번째 레이어의 z값을     \n",
    "$X^{\\{t\\}}$는 t번째 mini-batch의 X를 의미한다.\n",
    "\n",
    "또한 $t$번째 mini-batch, $X^{\\{t\\}}$의 shape은 ($n_x$, 1000)이고 $Y^{\\{t\\}}$의 shape은 (1, 1000) 이다.\n",
    "\n",
    "이렇게 데이터를 나누고 gradient descent로 최적화 하는 것을 **mini-batch gradient descent**라 한다.(반면 mini-batch가 아니라 전체 데이터를 한번에 처리하는 것을 **batch gradient descent**라 한다.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L01_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mini-batch gradient descent를 어떻게 구현하는지 알아보자. \n",
    "\n",
    "전체 데이터가 5백만건이고 mini-batch 크기가 1000이라면 총 5000개의 mini-batch가 있다. 우선 첫번째 mini-batch(1번째부터 1000번째 샘플)를 이용하여 (각 레이어를 따라 출력레이어까지) 순전파($A^{[1]}, \\cdots, A^{[L]}$)를 계산한다. 다음으로 cost값 $J$를 구한다. 이제 출력레이어에서부터 입력레이어까지 역전파를 계산하여 결국 $\\text{dw}$를 구하고 $w$를 업데이트 한다. 이때 순전파와 역전파 계산은 벡터화할 수 있고, 이런 과정을 5000개의 mini-batch에 대하여 진행한다. 즉 5백만건 데이터를 한번 처리하게 되면 $w$를 5000번 수정하는 것이 된다. 이렇게 전체 데이터를 한번 처리하는 것을 epoch 1번(single path through training set)이라 하며, 최적의 w에 수렴하기까지 여러번의 epoch(미국식 발음은 에펙, 영국식 발음은 이파크)를 반복하게 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L01_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-2]. Understanding mini-batch gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일반적으로 batch gradient descent를 이용하면 매 epoch마다 cost가 감소한다. 만약 cost가 증가한다면 learning rate이 너무 크다거나 어떤 다른 문제를 의심해 봐야 한다. \n",
    "\n",
    "반면 mini-batch gradient descent의 경우 매 mini-batch를 처리할 때마다 cost가 증가할수도 있고 감소할 수도 있다 다만 전체적으로는 감소하는 경향을 갖는다. 이런 특징은 전체 데이터에 대한 여러 mini-batch 마다 전체 데이터의 특성을 잘 반영하는 데이터가 뽑힌 경우도 있지만 그렇지 않은 경우도 있기 때문에 발생한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L02_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mini-batch방식을 사용하려면 mini-batch의 크기를 어느정도로 할지를 결정해야 한다. \n",
    "만약 mini-batch 크기가 $m$이라면 이건 batch gradient descent와 같고,\n",
    "mini-batch 크기가 $1$이라면 이건 stochastic gradient descent가 된다. mini-batch의 크기에 따른 $w$좌표의 궤적을 살펴보면 이들 각각의 특징을 알 수 있다. \n",
    "\n",
    "<u>(아래 슬라이드의 보라색 궤적)</u> 우선 batch gradient descent의 경우 각 step의 크기가 크고 global minimum으로 거의 직행하는 특징이 있다. 이는 각 step의 방향에 노이즈가 매우 작다고 할 수 있다. 또한 각 step을 계산하기 위해 전체 데이터를 처리해야하므로 각 step이 상대적으로 오래 걸린다.\n",
    "\n",
    "<u>(아래 슬라이드의 파란색 궤적)</u> 반면 stochastic gradient descent의 경우 각 step의 크기가 매우 작고 그 뱡항이 매우 자주 바뀌고 꼭 minimum으로 향하지 않을 수도 있다. 이는 각 step의 방향에 노이즈가 매우크다고 할 수 있다. 또한 각 step을 계산하는 것은 오래 걸리지 않으나 전체 데이터를 벡터화 하지 않고 한건 한건 계산하는 것이므로 계산 효율이 좋지 않다. 그래서 전체적으로는 처리 속도가 매우 느리다.\n",
    "\n",
    "<u>(아래 슬라이드의 녹색 궤적)</u> 이렇게 mini-batch 크기를 1이나 m과 같이 극단적인 값이 아니라 그 중간의 적절한 값을 사용한다면 각 mini-batch에 대한 계산을 벡터화 할 수 있고, 전체 데이터를 다 처리하지 않고도 썩 괜찮은 방향으로 gradient step을 밟아 갈 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L02_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 적절한 mini-batch size는 어느정도 일까? 대략적인 가이드라인으로는 만약 데이터 크기가 작다면(대략 2000건 이하?) 그냥 batch gradient descent를 사용하는 것이 좋다. 반면 데이터 크기가 이보다 크다면 mini-batch gradient descent를 사용하는 것이 좋고 mini-batch size는 64, 128, 256, 512 등 2의 차수를 사용하는 것을 추천한다. \n",
    "그리고 mini-batch size를 정할 때 한번에 처리하는 mini-batch data $X^{\\{t\\}}$와 $Y^{\\{t\\}}$가 CPU/GPU 메모리에 들어올 정고가 되어야 한다. 이보다 크다면 메모리 부족 으로 인해 처리 속도가 급격히 저하되는 문제를 겪게 될 것이다. \n",
    "\n",
    "이렇게 mini-batch size또한 하나의 hyper parameter라 할 수 있고, 다양한 값을 실험해보고 적절한 값을 선택해야 하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L02_03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-3]. Exponentially weighted averages, 지수가중평균"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient descent보다 나은 최적화 알고리즘이 여럿 있는데, 이들을 이해하기 위해 우선 '지수가중 평균'(exponentially weighted average)에 대해 알 필요가 있다. (통계학에서는 지수 가중 이동 평균exponentially weighted 'moving' average라 부른다.)\n",
    "\n",
    "아래와 같이 반년간 런던의 매일 특정 시간대의 기온이 있다고 하자. 그래프에서 알 수 있는 것 처럼 봄에는 온도가 낮았다가 여름으로 가면서 온도가 올라가고 여름이 지나면서 온도가 다시 내려가는 경향이 있다. \n",
    "\n",
    "1일자 기온부터 시작하여 지수가중평균을 구해보자. 구하는 방식은 t번째 날짜의 지수가중평균을 구한다면 t-1번째 날짜까지의 지수가중평균 $v_{t-1}$에 가중치 $\\beta$를 곱하고, t번째 날짜의 기온 $\\theta_t$에 $1-\\beta$의 가중치를 곱하고 두 값을 더한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L03_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$t$ 시점의 기수 가중 평균은 아래와 같으며\n",
    "$v_t = \\beta v_{t-1} + (1-\\beta) \\theta_t$\n",
    "\n",
    "이렇게 구한 지수가중평균 $v_t$는 근사적으로 $\\frac{1}{1-\\beta}$일 동안의 값들에 대한  평균을 구한 것과 같다. 예를들어 $\\beta=0.9$라면 대략 10일간의 기온의 평균을 구한 것과 같고, 만약 $\\beta=0.98$이라면 대략 50일간의 기온의 평균을 구하는 것과 같다. \n",
    "이들 지수가중평균을 그려보면 $\\beta$값이 1에 가까워질수록 실제 값보다 오른쪽으로 이동되어 있는 것을 알 수 있다. 이는 $\\beta$값이 커질수록 과거 데이터에 대한 가중치가 커지므로 최근 데이터가 반영되기까지 시간이 걸리는 것이다. 반면 $\\beta$값이 작아지면 매일의 데이터에 가까워지지만 최근 데이터를 많이 반영하므로 최근 데이터의 노이즈가 많이 반영된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L03_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-4]. Understanding exponentially weighted averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지수 가중 평균에 대해 좀더 알아보도록 하자. \n",
    "$t$시점의 지수가중평균은 \n",
    "$v_t = \\beta v_{t-1} + (1-\\beta) \\theta_t$\n",
    "인데, 런던의 기온 데이터는 아래 슬라이드의 파란 점과 같은데, $\\beta$가 0.98이면 지수 가중 평균은 노란 선과 같고, $\\beta$가 0.9이면 빨간 선과 같고, $\\beta$가 0.5이면 녹색 선과 같다. 즉 $\\beta$가 작아질수록 실제 데이터와 가깝고 노이즈를 그대로 반영하게 되고, $\\beta$가 커질수록 노이즈가 줄어들면서 실제 데이터와의 딜레이가 발생하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L03b_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 $\\beta$가 0.9일 때 100번째 시점의 지수 가중 평균을 구해보자.\n",
    "$\\begin{align} v_{100} &= 0.1 \\theta_{100} + 0.9 v_{99} \\\\\n",
    "&= 0.1 \\theta_{100} + 0.1 \\cdot 0.9 \\cdot \\theta_{99} + 0.1 \\cdot 0.9^2 \\cdot \\theta_{98} + 0.1 \\cdot 0.9^3 \\theta_{97} + \\cdots\n",
    "\\end{align}$\n",
    "\n",
    "위 식을 보면 $t$시점으로부터 멀리 있는 $\\theta_{?}$일수록 더 높은 차수의 $\\beta=0.9$를 곱하고 있다. (즉 $0.1$, $0.1 \\cdot 0.9$, $0.1 \\cdot 0.9^2$, $0.1 \\cdot 0.9^3$, ... )\n",
    "\n",
    "참고로 이 계소값들은 모두 더하면 1이 된다.($\\sum_{i=1}^{\\inf}0.1 \\cdot 0.9^{i-1} = \\frac{0.1}{1-0.9}= 1$)\n",
    "\n",
    "\n",
    "또한 $(1- \\epsilon)^{1/ \\epsilon} = \\frac{1}{\\epsilon}$이고 이 값은 대략 0.35이다. $\\beta$가 0.9인 경우 이 계산은 $0.9^{19} \\approx 0.35$가 되며 10일정도전 데이터에 대한 가중치는 $t$시점 데이터에 비해 1/3 수준이라는 것이다. 이런 이유로 $\\beta$가 0.9이면 대략 과거 10일간의 데이터를 평균낸 것이라고 예기한다.\n",
    "만약 $\\beta$가 0.98일 경우 위 계산은 $0.98^{1/0.02}$로서 대략 1/0.02=50일간의 평균이 되는 것이다. (대략 그렇게 생각하면 된다는 것이지 정확히 50일간의 평균은 아니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L03b_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 구현에 있어서는 $v_0$, $v_1$, $v_2$, ...를 별도의 변수로 잡지 않고 아래와 같이 한 변수를 이용해 for-loop로 구현할 수 있다.\n",
    "$$\\begin{align}\n",
    "&\\text{Repeat} \\{ \\\\\n",
    "&\\qquad \\text{Get next} ~~ \\theta_t \\\\\n",
    "&\\qquad   v := \\beta v + (1-\\beta) \\theta_t \\\\\n",
    "\\}\n",
    "\\end{align}$$\n",
    "이렇게 구현하면 모든 시점의 $v_t$를 메모리에 저장할 필요가 없는 장점이 있다.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L03b_03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-5]. Bias correction in exponentially weighted average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 슬라이드에서 $\\beta$가 0.98일때 지수 가중 평균은 보라색 선과 같은데, 초기 값이 실제 값과 큰 차이가 있음을 알 수 있다. 이 차이는 지수 가중 평균의 초기값이 0이라서 발생하는 것인데, 이런 부정확함을 보정해주는 'Bias correction'이라는 방법이 있다. \n",
    "\n",
    "예를들어 $\\beta$가 0.98일 때, \n",
    "$v_0 = 0$이고\n",
    "$v_1 = 0.98 \\cdot v_0 + 0.02 \\cdot \\theta_1 = 0.02 \\cdot \\theta_1$이다. 만약 첫 데이터 $\\theta_1$가 100이라면 $v_1$은 겨우 2이다. 또한  $v_2 = 0.0196 \\cdot \\theta_1 + 0.02 \\cdot \\theta_2$로서 ($\\theta_1$과 $\\theta_2$가 모두 양수일 때) $\\theta_2$보다 매우 작다. \n",
    "이런 차이를 보정하기 위해 $v_t$대신 $\\frac{v_t}{1-\\beta^t}$를 사용하는 방법을 사용할 수 있다. 즉 t가 작을 때에는 $v_t$에 1보다 큰 어떤 값($\\frac{1}{1-\\beta^t}$)이 곱해지고, t가 증가하면서 보정 값이 1로 수렴하는 효과가 나타난다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L04_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-6]. Gradient descent with momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모멘텀(momentum) 알고리즘 혹은 gradient descent with momemtum이라 부르는 최적화 알고리즘이 있다. 이는 거의 항상 보통의 gradient descent보다 빠른 최적화 성능을 보인다. \n",
    "이 알고리즘을 한마디로 표현하자면 gradient($\\frac{dL}{dw}(=\\text{dw})$)의 지수 가중 평균(exponentially weighted average)을 구하고, $\\text{dw}$대신 이 값을 weight 업데이트에 사용하는 것이다.\n",
    "\n",
    "예를들어 weight이 단 두개이고 cost-contour가 아래 그림과 같이 중심에 global minimum이 있고 위 아래로 찌그러진 형태 다고 하자. 이때 일반적인 gradient descent로 최적화를 하면 아래 파란색 궤적과 같이 contour의 양 사이드에서는 지그제그 형태로 최적화가 진행된다. 사실 이런 형태는 곧장 global minimum으로 가는것에 비하면 매우 비 효율적이며 learning rate이 클 경우 cost가 증가하는 일도 발생하게 된다.  사실 contour가 이런 형태인 경우 세로축 방향으로는 조금만 움직이고 가로축 방향으로는 많이 움직이는 것이 바람직할 한데, 보통의 gradient descent로는 이걸 표현하는 것이 쉽지 않다. \n",
    "\n",
    "momentum방법은 이 문제를 어떻게 접근하는지 살펴보자.\n",
    "\n",
    "우선 batch혹은 mini-batch에 대해 dw와 db를 구한다.\n",
    "(보통의 gradient descent에서는 아래와 같이 w와 b를 업데이트 했을 것이다.)\n",
    "$$w := w - \\alpha \\text{dw} \\\\\n",
    "b := b - \\alpha \\text{db}$$\n",
    "\n",
    "그리고 이전 batch(epoch)들 혹은 이전 mini-batch들에서 구했던 값들을 이용해 dw와 db의 지수 가중 평균을 구한다. \n",
    "$$\n",
    "v_{dw} := \\beta v_{\\text{dw}} + (1-\\beta) \\text{dw} \\\\\n",
    "v_{db} := \\beta v_{\\text{db}} + (1-\\beta) \\text{db}\n",
    "$$\n",
    "이렇게 구한 지수 가중 평균값을 이용해 w와 b를 업데이트 한다.\n",
    "$w := w - \\alpha v_{\\text{dw}}$, \n",
    "$b := b - \\alpha v_{\\text{db}}$\n",
    "\n",
    "이것이 어떤 효과를 갖을지 생각해보자. 어떤 w방향에 대해 각 gradient step마다 dw의 부호가 바뀐다면, 일반적인 gradient descent에서는 그 궤적이 지그-제그 형태가 될 것이다. 이런 경우 이들 dw들의 평균을 구하면 양수와 음수가 상쇄되어 $v_{dw}$는 0에 가까운 값이 된다. 따라서 지그-제그 흔들림이 줄어드는 효과를 갖게 된다.\n",
    "\n",
    "모멘텀 방법을 물리학 관점에서 생각해보면 \n",
    "$\\text{dw}$와 $\\text{db}$는 가속도(acceleation), $v_{dw}$와 $v_{db}$는 속도(velocity), $\\beta$는 (1보다 작은 값이므로) 속도를 제한하는 역할을 하게 된다.\n",
    "\n",
    "gradient descent에서는 각 gradient step이 독립적이었다면 모멘텀 방법에서는 각 gradient step의 $\\text{dw}$와 $\\text{db}$가 가중 평균으로 이후 값에 영향을 주게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L05_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 구현은 아래와 같은데, 결정해야 하는 hyper parameter는 learning rate $\\alpha$와 평균 가중치 $\\beta$이다. 일반적으로 $\\beta$값으로 0.9를 많이 사용한다. 또한 가중평균을 구할 때 bias correction을 사용할 수도 있다. \n",
    "그리고 종종 $(1-\\beta)$항을 생략하는 구현도 있는데, 이 경우 $v_{dw}$가 $(1-\\beta)$만큼 커지는 효과가 있기 때문에 결과적으로 learning rate alpha가 커지는 효과를 갖는다. 이때문에 $\\alpha$를 이에 맞게 다시 튜닝해야하는 상황이 된다. 이런 이유 때문에 $(1-\\beta)$를 생략하지 않는 버전이 좀 더 직관적이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L05_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-7]. RMSProp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 모멘텀 방법을 이용해 gradient descent의 수렴 속도를 빠르게 할 수 있다는 내용을 다뤘다. 비슷한 의도를 갖는 알고리즘으로 RMSProp이라는 것이 있다. 아래 슬라이드와 같은 cost contour($x$, $y$ 축이 두개의 파라미터이고 $z$축이 cost일 때 $z$축에 수직으로 자른 단면)가 있고 가로축이 $w$, 세로축이 $b$라고 할 때 일반적인 gradient descent로는 아래 파란색 선과 같이 지그제그 형태의 최적화 궤적이 만들어진다.\n",
    "\n",
    "이때 우리가 원하는 것은 $b$방향으로는 보다 조금만 움직이고, $w$방향으로는 보다 많이 움직이는 형태의 최적화 궤적이 만들어지는 것이다. 모멘텀 방법에서는 $w$를 업데이트 할 때 $\\text{dw}$ 대신  $\\text{dw}$의 지수 가중 평균을 이용했었는데, RMSProp에서는 지수 가중 평균을 조금 다른 형태로 이용한다.\n",
    "\n",
    "RMSprop에서는...    \n",
    "$t$번째 반복에서 $\\text{dw}$와 $\\text{db}$를 구하고, 아래와 같이 각각 $\\text{dw}^2$와 $\\text{db}^2$의 지수가중평균 $S_{\\text{dw}}$, $S_{\\text{db}}$를 구한다.\n",
    "$$ S_{\\text{dw}} := \\beta S_{\\text{dw}} + (1-\\beta) \\text{dw}^2 \\\\\n",
    "S_{db} := \\beta S_{db} + (1-\\beta) db^2\n",
    "$$\n",
    "그리고 아래와 같이 $w$와 $b$를 업데이트 한다.\n",
    "$$w := w - \\alpha \\frac{\\text{dw}}{\\sqrt{S_{\\text{dw}}}}\\\\\n",
    "b := b - \\alpha \\frac{\\text{db}}{\\sqrt{s_{\\text{db}}}}$$\n",
    "\n",
    "이 예에서는 $\\text{dw}^2$보다 $\\text{db}^2$가 매우 큰 상황이므로, $S_{\\text{dw}} \\ll S_{db}$ 이고, $w$에 대한 업데이트는 보다 커지고, $b$에 대한 업데이트는 보다 작아지게 된다. \n",
    "\n",
    "구현시 고려될 수 있는 부분으로 $\\sqrt{S_{dw}}$나 $\\sqrt{S_{db}}$가 지나치게 작아져서 step이 너무 커지는 경우를 방지하기 위해 분모에 어떤 작은 숫자 $\\epsilon$을 더해 주기도 한다. (보통 $10^{-8}$정도의 값을 사용한다.)\n",
    "\n",
    "결국 RMSProp을 이용하면 아래 슬라이드의 녹색 선과 같은 최적화 궤적이 만들어진다. \n",
    "\n",
    "이렇게 RMSProp과 모멘텀 방법과 대해 알아봤는데, 다음 강의에서는 이 두 방법을 결합한 방법인 Adam 최적화를 다루게 될 것이다. 모멘텀과 RMSProp 모두  Hyperparameter $\\beta$가 사용되므로, 모멘텀에서의 그것을 $\\beta_1$로, RMSProp에서의 그것을 $\\beta_2$로 표기할 것이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L06_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-8]. Adam optimization algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 역사에 있어서 많은 최적화 알고리즘이 제안되었었는데, 사실 많은 알고리즘들이 실험실이 아닌 일반적인 다양한 상황에는 효과적이지 않다는 것이 밝혀졌다. 이 때문에 모멘텀 방법(gradient descent with momentum) 보다 더 나은 새로운 최적화 알고리즘이 개발될 수 있을지에 대해 회의적인 입장이 많았다. 하지만 결국 RMSProp과 Adam 최적화라는 더 나은 알고리즘이 등장하게 된다. 이들은 다양한 구조의 딥러닝 구조에 효과적이라는 것이 증명 되었다.\n",
    "\n",
    "Adam 최적화는 사실 모멘텀 방법과 RMSprop를 혼합한 것이다. 알고리즘은 아래 슬라이드와 같은데 $V_{\\text{dw}} = \\beta_1 V_{\\text{dw}} + ( 1 - \\beta_1 ) \\text{dw}$는 모멘텀 방법에서 지수 가중 평균을 구하는 것과 같고, $S_{\\text{dw}} = \\beta_2 S_{\\text{dw}} + (1 - \\beta_2) \\text{dw}^2$는 RMSProp에서 지수가중평균을 구하는 것과 같다. (모멘텀 방법에서의 가중치는 $\\beta_1$으로 RMSprop에서의 가중치는 $\\beta_2$로 표기함)    \n",
    "\n",
    "이렇게 구한 지수 가중평균에 bias correction항인 $\\epsilon$을 추가해서 $V_{\\text{dw}}^{\\text{corrected}}$, $V_{\\text{db}}^{\\text{corrected}}$, $S_{\\text{dw}}^{\\text{corrected}}$, $S_{\\text{db}}^{\\text{corrected}}$를 구하고, 이들을 결합하여 아래와 같이 $W$와 $b$를 업데이트 한다.\n",
    "$$\n",
    "W := W - \\alpha \\frac{V_{\\text{dw}}^{\\text{corrected}}}{\\sqrt{S_{\\text{dw}}^{\\text{corrected}}} + \\epsilon} \\\\\n",
    "b := b - \\alpha \\frac{V_{\\text{db}}^{\\text{corrected}}}{\\sqrt{S_{\\text{db}}^{\\text{corrected}}} + \\epsilon} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L07_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "보다시피 Adam 최적화에 사용되는 hyperparameter가 몇가지 있다. 우선 learning rate $\\alpha$는 여러 값들을 테스트 해보고 적절한 값을 골라야 한다.\n",
    "\n",
    "$\\beta_1$값은 일반적으로 0.9를 사용하며 모멘텀항에 영향을 준다. $\\beta_2$값으로는 0.999를 사용하는 것을 추천한다.(adam 최적화를 소개한 최초 논문에 의함). 반면 $\\epsilon$값은 사실 크게 중요하지 않은데, 원 논문에서는 $10^{-8}$을 사용한다.(사실 이 값은 적절히 작은 값을 사용하면 되며 튜닝까지 하지는 않는다.)\n",
    "\n",
    "참고로 Adam이란 단어는 은 Adaptive Momentum Estimation의 글자들을 따서 작명했다고 한다. 사실 알고리즘에서 $V_{\\text{dw}}$는 $\\text{dw}$의 1차 모멘트이고, $S_{\\text{dw}}$는 2차 모멘트라 할 수 있다. ($\\text{dw}$를 표준화 한 것이라 생각할 수 있겠다.)\n",
    "\n",
    "참고로 Adam 방법은 아래 슬라이드의 Adam Coates란 분과 전혀 관련이 없다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L07_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-9]. Learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 알고리즘의 수렴 속도를 높이는 방법 중 하나로 learning rate $\\alpha$를 점차 줄이는 방법(learning rate decay)를 사용할 수 있다.\n",
    "\n",
    "mini-batch gradient descent를 이용해 최적화를 한다고 할 때 (b, w)의 괘적은 아래와 같이 지그-제그로 움직이면서 점차 minimum에 다가가는 형태일 것이다. 그런데 epoch마다 동일한 $\\alpha$값을 사용하면 (step이 크기 때문에) minimum에 가까이 가더라도 minimum을 지나처 근처에서 계획 배회한다는 문제가 있다. 이런 문제를 극복하기 위해 epoch마다 혹은  mini-batch마다 learning rate을 줄이는 방법을 사용한다. (여기서 epoch는 데이터 세트 전체를 한번 읽는 것이다. 또한 한번의 epoch는 여러개의 mini-batch 로 구성되어 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L08_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate을 줄이는 여러가지 방식이 있는다.\n",
    "첫번째 아이디어로 아래와 같이 epoch에 반비례하도록 learning rate을 줄이는 방법이 있다.\n",
    "\n",
    "- $\\alpha = \\frac{1}{1 + \\text{decay rate} \\times \\text{epoch num}}$\n",
    "이 경우 learning rate 의 초기값 $\\alpha_0$와 epoch마다 얼마나 빠르게 learning을 줄일지를 결정하는 decay rate을 결정해야만 한다. (decay rate의 값이 1에 가까울수록 epoch가 계속될 수록 더 빠르게 learning rate이 감소할 것이다.) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L08_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다른 아이디어로 아래와 같은 exponential decay라 불리는 방법도 있고\n",
    "\n",
    "- $\\alpha = \\text{decay rate}^{\\text{epoch num}} \\times \\alpha_0$\n",
    "\n",
    "\n",
    "아래와 같이 epoch 횟수나 지나온 mini-batch 수에 따라 $\\alpha$를 조정하기도 한다.\n",
    "\n",
    "- $\\alpha = \\frac{k}{\\sqrt{\\text{epoch num}}} \\times \\alpha_0$ ($k$는 어떤 상수이다.)\n",
    "\n",
    "- $\\alpha = \\frac{k}{\\sqrt{\\text{mini-batch num}}}\\times \\alpha_0$\n",
    "\n",
    "혹은 mini-batch num $t$에 따라 계단형으로 $t$가 어느정도 증가할 때마다 learning rate을 줄이는 방법도 있다. 또한 학습이 오래 걸리는 모형의 경우 모형의 수렴 상태를 관찰하면서 learning rate을 직접 바꾸는 경우도 있다.\n",
    "\n",
    "이처럼 learning rate decay를 위해서도 결정해야 하는 hyperparameter들이 많다. 이런 hyperparameter들 또한 여러 가지 값들을 테스트 해 보면서 좋은 값을 고를 수 있는데, 사실 다른 hyperparameter들에 비해 그 중요성이 높지는 않다. 우선 적당한 상수 값으로 learning rate을 잡고 다른 hyperparameter들을 우선 튜닝하는 것을 추천한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L08_03.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-10]. The problem of local optima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기 딥러닝 분야에서는 최적화 알고리즘이 (global optima가 아니라) local optima에 도달하게 되는 것이 큰 문제로 여겨졌었다. 그런데 딥러닝 연구가 점점 진전되면서 local optima가 중요한 문제가 아니라는 것이 밝혀진다.\n",
    "\n",
    "아래 슬라이드에서 좌측의 예를 보면 (b와 w있다고 가정하는) 2차원상에서 중심에 global optima가 있고 주변에 다수의 local optima가 존재하는 경우를 생각해볼 수 있다. 그런데 (w가 다수인) 다차원 공간에서 어떤 w값이 0인 지점은 local optima가 아니라 아래 슬라이드의 우측과 같은 saddle point인 상황이 대다수라는 것이다. (말 안장 능선의 가장 아래 지점에서는 3개 치원 중 2개는 gradient값이 0이다.)\n",
    "\n",
    "예를들어 w가 20000차원이라면 아래 좌측과 같은 optima가 존재하려면 20000개의 w가 모두 0인 저점이 존재한다는 것인데, 그런 경우는 매우 드물 것이다. 대부분의 경우 아래 우측 슬라이드와 같이 일부 w들만 0인 상황이 더 많을 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L09_01.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 슬라이드와 같은 능선이 존재하면 (일반적인) 최적화 알고리즘은 (빨간 선을 따라) 고원(plateau)의 능선 상단부터 능선의 최저점까지 내려온 후에야 능선을 벗어나 아래로 내려오게 된다. 즉 곧바로 능선을 벗어날 수 있었다면 더 빨리 최적화 되었을 것이다.\n",
    "\n",
    "결론적으로 딥러닝과 같이 다차원 파라미터에 대한 최적화에 있어서는 local optima에 빠지는 경우 드물이다. 이보다는 고원(plateau)을 따라 최적화가 진행되는 경우가 많으며 이는 최적화 속도를 느리게하는 영향이 있다. 다행히도 (일반적인 gradient descent가 아니라) 앞서 다뤘던 Momentum, RMSProp, Adam를 사용하면 이런 문제가 개선된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/C2W2L09_02.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
