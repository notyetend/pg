{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coursera | Andrew Ng's Deep Learning Class | Course3. | Week2. ML Strategy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1]. Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-1]. Carrying out error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인간이 잘하는 문제를 머신러닝 알고리즘으로 해결하려하는데 그 성능이 충분히 나오지 않는다면 어떻게 문제를 해결 해야할까? 모형을 개선하기 위한 다양한 접근 방법이 있겠지만 가장 현명한 방법으로 error analysis를 해보는 것이다. error analysis는 알고리즘이 잘 분류하지 못한 케이스들 중 일부를 선택하여 직접 하나 하나 살펴보면서 문제의 원인을 찾는 방법을 말하는데, 이를 통해 어떤 에러 케이스에 집중하는 것이 보다 효과적인지를 보다 빠르게 알아낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Look at dev examples to evaluate ideas)         \n",
    "예를들어 고양이 그림을 분류하는 알고리즘을 개발중인데, 이 알고리즘의 다양한 오분류 사례 중 개 그림을 고양이라고 오분류하는 경우가 발견되었다고 하자. 이때 누군가 '개 그림을 오분류하는 것을 해결하는데 집중해보자'라고 말한다면, 이 말을 따라도 되는 것일까? 혹은 다른 문제에 집중해야하는 것일까? \n",
    "어떤 모형 개선 시도든 시간과 노력이 소모되며 실패할 가능성 또한 존재하기 때문에 어느 부분에 집중할지 신중한 선택이 필요하다. 이런 신중한 선택을 돕는 방법이 바로 error analysis이다. error analysis를 위해 대략 100건 이내의 오분류 데이터를 준비하고,  개 이미지가 몇건인지 확인한다. \n",
    " 예를들어 100건중 5건만이 개 이미지였다고 하자. 이는 개 이미지 오분류를 해결하는데 집중하여 완벽히 해결했다하더라도 겨우 5%의 오분류를 제거할 수 있다는 것을 의미한다. 개선 전 모형 에러가 10%였다면 개 이미지 오분류를 해결한다 하더라도 에러율은 9.5%로 떨어지는데 그친다는 것이다. (이처럼 최적의 경우를 가정해보는 것을 'ceiling on performance'라 한다.)\n",
    " 그런데 만약 100건중 50건이 개 이미지였다면, 개 오분류 문제를 해결한다면 50%의 에러를 줄일 수 있다는 의미한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Evaluate multiple ideas in parallel)    \n",
    "다양한 오분류 케이스들 중 어느것에 집중할 것인지 선택하기 위해 아래 슬라이드와 같이 표를 만들고 각 오분류 샘플이 어느 케이스에 속하는지 혹은 어떤 특이사항이 있는지를 체크해볼 수 있다. 이 결과를 통해 어떤 경우에 에러가 많이 발생하는지 알 수 있고, 어떤 에러를 먼저 해결하는 것이 좋은지 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-2]. Cleaning up incorrectly labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습의 데이터는 입력 데이터 X와 타겟 레이블 y로 구성된다. 그런데 만약 작업이 어느정도 진행된 이후에 타겟 y가 잘못 레이블링 되어 있다면 어떻게 해야할까? 이 레이블들을 옳게 수정해야할까?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Incorrected labeled examples)        \n",
    "아래 슬라이드의 6번째 그림은 개 그림을 1로 잘못 레이블링 되어 있다. 모형 학습을 이미 진행한 경우 이런 레이블을 수정하고 다시 학습시켜야할까?\n",
    "\n",
    "딥러닝 모형은 랜덤 노이즈에 상당히 강건한 특성이 있기 때문에 만약 훈련데이터에 이런 데이터다 섞여 있는데, 그 비율이 많지 않고 랜덤 노이즈와 유사한 형태라면 레이블을 수정하는 것이 모형의 성능에 큰 영향이 없을 수 있다. \n",
    "\n",
    "반면 딥러닝 모형은 어떤 경향성이 있는 노이즈(systematic error)에는 강건하지 못하다. 예를들어 훈련데이터에 하얀 개를 고양이로 잘못 분류한 데이터가 많이 섞여 있다면 그런 경향까지도 모형이 학습하게 되는 문제가 생긴다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Error analysis)    \n",
    "훈련 데이터 혹은 개발데이터에 잘못 레이블링된 샘플이 섞여 있다면 어떻게 해야할까?\n",
    "\n",
    "이런 경우 error analysis를 할 때 잘못 레이블링됨(Incorrectly labeled)라는 컬럼을 하나 추가해서 오분류 샘플 중 잘못된 레이블로 인한 에러가 얼마나 되는지를 확인해보는 것이 좋다. 확인 결과 다른 오분류 원인에 비해 그 영향이 크다면 잘못된 레이블을 바로잡는 것이 좋을 것이다. 반면 오분류 원인이 비용대비 효과가 더 나은 원인이 존재한다면 그것을 먼저 해결해보는 것이 좋다.\n",
    "\n",
    "예를들어 100건의 오분류 샘플을 대상으로 error analysis를 진행했을 때, 잘못 레이블링된 샘플로 인한 에러가 6건이 있다고 해 보자. 이때 모형의 전체 오분류율이 10%라면 잘못 레이블린된 샘플로 인한 오분류율은 0.6%이고, 다른 원인으로 인한 오분류율은 9.4%이다. 이런 경우 다른 원인들을 먼저 해결해보는 것이 나은 접근이라 할 수 있다.\n",
    "\n",
    "다른 예로 전체 오분류율이 2%이고, 100건의 어뷴류 샘플중 30건이 잘못 레이블링된 샘플로 인한 에러라면 0.6%의 오분류가 이로 인한 것이고 나머지 1.4%가 다른 원인으로 인한 것이다. 이런 경우에는 레이블링을 바로 잡는 것이 좋은 접근법이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Correcting incorrect dev/test set examples)    \n",
    "데이터를 수정하는 작업을 해야한다면 개발데이터와 테스트 데이터 모두에 적용하는 것이 좋다.(두 데이터가 동일한 분포를 갖도록 하기 위함)\n",
    "\n",
    "상확이 허락된다면 오분류 샘플 뿐만 아니라 정분류 샘플에서의 데이터 문제 또한 살펴보는 것이 좋다. 레이블링이 잘못 되어 있는데 운이 좋아 정분류 했을 수도 있기 때문이다. 다만 정분류 샘플은 상대적으로 양이 많을 것이므로 모두를 살펴보는 것이 불가능할수도 있다.\n",
    "\n",
    "딥러닝 모형은 노이즈에 강건한 특성이 있기 때문에 훈련데이터의 문제를 바로잡는 것은 비용대비 효과가 좋지 않을 수 있다.\n",
    "\n",
    "결론적으로 단순히 데이터를 더 넣거나 이런 저런 방법을 시도해보다가 좋은 결과를 얻을수도 있지만, (많은 머신러닝 엔지니어들이 싫어하는 방법인데..) 사람의 눈으로 직접 에러를 하나하나 분석해보고 원인을 찾고 방향을 잡는 것이 효과적일 때가 많다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1-3]. Build your first system quickly, then iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝을 이용해 어떤 새로운 어플리케이션을 개발중이라면 우선 간단한 시스템을 빠르게 만들고 이를 반복적으로 개선해가는 것이 좋다.\n",
    "\n",
    "예를들어 음성인식 시스템을 정교하게 만들기 위해서는 배경에 깔린 잡음, 엑센트가 강한 음성, 마이크 멀리에서 들려오는 음성 인식, 아이들의 음성 인식 등 풀어야 하는 많은 꼭지들이 있다. 이들 꼭지들 각각은 그마다의 노하우를 필요로 하며 이들중 어느것부터 집중할 것인지를 결정하는 것 또한 쉽지 않다.\n",
    "\n",
    "이미 기존의 연구 결과가 축적되어 있지 않은 분야의 새로운 어플리케이션을 만들어야 하는 상황이라면 우선 개발/테스트 데이터와 성능 측정 지표부터 만들고, 빠르게 간단한 초기 시스템을 만들고, Bias/Variance분석, error analysis 를 통해 우선시해야할 문제를 결정한 후 모형을 개선해가는 것이 좋다. 예를들어 error analysis결과 스피커에서 먼 음성으로 인한 에러가 많다고 밝혀지면 그 부분을 먼저 해결하는 것이다.\n",
    "\n",
    "즉 초기 모형/어플리케이션을 만들 때부터 너무 깊게 문제를 고민하지 말라는 것이다. 오히려 덜떨어지고 간단한 모형부터 만들고 이를 개선하는 것이 좋다. 물론 안면 인식과 같이 기존 연구 결과가 축적되어 있는 분야의 문제를 풀어야한다면 초반부터 기존의 연구 노하우를 시스템에 녹여내는 것이 좋다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2]. Mismatched training and dev/test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-1]. Training and testing on different distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "딥러닝 모형에 사용할 데이터를 수집하다보면 개발 데이터와 테스트 데이터의 분포가 다른 경우가 발생하기도 한다. \n",
    "예를들어 모바일 환경에서 사진을 수집하여 분류하는 어플리케이션을 만들어야 하고 모바일 특성상 해상도가 낮은 사진이 대부분이다. 그런데 여건상 모바일 환경과 같은 데이터는 10k장만을 수집했고, 웹 크롤링을 통해 200k장의 다른 해상도의 이미지를 수집했다고 하자. 즉 수집한 많은 데이터의 분포가 실제 사용환경과 다른 상황이다. 이때 200k 장의 이미지를 잘 활용할 수 있는 방법이 있을까?\n",
    "\n",
    "첫번째 방법으로 전체 200k장의 이미지를 랜덤하게 섞고 205k는 훈련에, 5k는 개발에, 나머지 5k는 테스트에 사용할 수 있다. 이렇게 하면 훈련, 개발, 테스트 데이터의 분포가 같아지는 효과가 있다. 하지만 모형 성능 평가의 기준이라 할 수 있는 개발데이터 2500장 이미지중 대부분이 모바일 환경과 다른 분포를 갖기 때문에 실제 사용환경인 모바일에서는 모형성능이 좋을리가 없다. 따라서 이런 방식은 권장하지 않는다.\n",
    "\n",
    "(추천하는) 두번째 방법은 크롤링 데이터 200k 전부와 모바일 데이터중 절반을 훈련 데이터(205k)로 사용하고, 모바일 데이터 2.5k를 개발 데이터, 나머지 2.5k를 훈련 데이터로 사용하는 것이다. 이렇게 하면 훈련 데이터의 분포가 개발/테스트 데이터의 분포와 달라지지만 장기적으로 모바일 환경에서 더 나은 성능을 기대할 수 있다. (추후 개발 데이터 분포가 개발/테스트 데이터와 다른 상황에 대처하는 방법에 대해 알아볼 것이다.)\n",
    "\n",
    "또 다른 예로 자동차에 장착하여 음성인식으로 동작하는 제품을 만들려고하는데, 실제 자동차안에서 녹음한 음성 데이터가 많지 않다. 이런 경우 자동차가 아니더라도 많은 음성 데이터를 구매하거나 다른 종류의 음성 데이터를 획득할수는 있고 이를 테스트 데이터에 추가하여 학습에 사용할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-2]. Bias and Variance with mismatched data distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-3]. Addressing data mismatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3]. Learning from multiple tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3-1]. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3-2]. Multi-task learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4]. End-to-end deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-1]. What is end-to-end deep learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [4-2]. Whether to use end-to-end deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
