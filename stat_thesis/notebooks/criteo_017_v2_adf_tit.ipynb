{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train = r'C:\\Temp\\dac.tar\\train.txt' # for criteo\n",
    "#test  =  r'C:\\Temp\\dac.tar\\test.txt' # for criteo\n",
    "train = r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # for titanic\n",
    "test = r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/test.csv' # for titanic\n",
    "\n",
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(fpath, fheader, delimiter, ylab,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "        \n",
    "    f = open(fpath)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fheader, delimiter=delimiter)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[ylab] == '1' else 0.\n",
    "        del row[ylab]\n",
    "        del row['PassengerId'] # just for titanic\n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss_comparison(c):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "    x1 = range(len(c[0]))\n",
    "    plt.plot(x1, c[0], 'r')\n",
    "\n",
    "    x2 = range(len(c[1]))\n",
    "    plt.plot(x2, c[1], 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    \n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "\n",
    "    f = open(train)\n",
    "    \n",
    "    # for criteo\n",
    "    #fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "    \n",
    "    # for titanic\n",
    "    fn = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked']\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=',')):  # for titanic(comma seperated)\n",
    "        del row['PassengerId'] # for titanic\n",
    "        if t == 0:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        #y = 1. if row['Label'] == '1' else 0.\n",
    "        #del row['Label']\n",
    "        y = 1. if row['Survived'] == '1' else 0.\n",
    "        del row['Survived']\n",
    "\n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                arr_log_loss_sgd_test.append(\n",
    "                    get_validation_metrics(\n",
    "                        train\n",
    "                        , fn\n",
    "                        #, '\\t' # for criteo \n",
    "                        , ','  # for titanic\n",
    "                        \n",
    "                        #, 'Label' # for criteo\n",
    "                        , 'Survived' # for titanic\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug) / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    if f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test = get_validation_metrics(\n",
    "                        train\n",
    "                        , fn\n",
    "                        #, '\\t' # for criteo \n",
    "                        , ','  # for titanic\n",
    "            \n",
    "                        #, 'Label' # for criteo\n",
    "                        , 'Survived' # for titanic\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug) / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        return((w, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    #theta_t_v[x] += ((a_i**2) * delta_v) + abs(theta_t_m[x])/min((n_iter+1.), 3000.)\n",
    "    #theta_t_v[x] += ((a_i**2) * delta_v) + abs(theta_t_m[x])/(n_iter+1.)\n",
    "    #theta_t_v[x] += ((a_i**2) * delta_v / np.sqrt(n[x] + 1.))\n",
    "    #theta_t_v[x] += ((a_i**2) * delta_v) + 1. / np.sqrt(n[x] + 1.)\n",
    "    #theta_t_v[x] += ((a_i**2) * delta_v) + abs(theta_t_m[x])/np.sqrt(n[x] + 1.)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(train)\n",
    "    \n",
    "    # for criteo\n",
    "    #fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "    \n",
    "    # for titanic\n",
    "    fn = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked']\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter='\\t')):\n",
    "    \n",
    "        del row['PassengerId'] # for titanic\n",
    "        if t == 0: # for criteo \n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        #y = 1. if row['Label'] == '1' else 0.\n",
    "        #del row['Label']\n",
    "        y = 1. if row['Survived'] == '1' else 0.\n",
    "        del row['Survived']\n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                arr_log_loss_adf_test.append(\n",
    "                    get_validation_metrics(\n",
    "                        train\n",
    "                        , fn\n",
    "                        #, '\\t' # for criteo \n",
    "                        , ','  # for titanic\n",
    "                        , 'Label'\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug) / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test = get_validation_metrics(\n",
    "                        train\n",
    "                        , fn\n",
    "                        #, '\\t' # for criteo \n",
    "                        , ','  # for titanic\n",
    "                        , 'Label'\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug) / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, rt_log_loss_adf_training, rt_log_loss_adf_test))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find best parameters.(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_metric_check_point: 10\n",
      "num_status_check_point: 1\n",
      "num_train_data_start  : 1\n",
      "num_train_data_end    : 400\n",
      "num_train_data_size   : 400\n",
      "num_test_data_start   : 401\n",
      "num_test_data_end     : 891\n",
      "num_test_data_size    : 491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_best_param = DataSize(10      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_best_param = DataSize(10      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 400        #train_start, train_size\n",
    "                         , 401, 491)    #test_start, test_size\n",
    "\n",
    "ds_best_param.display()\n",
    "ds_best_param.num_train_data_end - ds_test_param.num_train_data_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , ['Survived']# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , ['Label']# _ylab\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD : alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1e-05\n",
      "2016-05-13 21:45:08.588000, i:0, param:1e-05, log-loss(tr:0.694840799321, te:0.694500345543)\n",
      "alpha: 0.0600098\n",
      "2016-05-13 21:45:08.655000, i:1, param:0.0600098, log-loss(tr:0.547329835713, te:0.552875174839)\n",
      "alpha: 0.1200096\n",
      "2016-05-13 21:45:08.731000, i:2, param:0.1200096, log-loss(tr:0.468284924083, te:0.5071635419)\n",
      "alpha: 0.1800094\n",
      "2016-05-13 21:45:08.791000, i:3, param:0.1800094, log-loss(tr:0.412626952506, te:0.483559439094)\n",
      "alpha: 0.2400092\n",
      "2016-05-13 21:45:08.857000, i:4, param:0.2400092, log-loss(tr:0.369655497828, te:0.469847361033)\n",
      "alpha: 0.300009\n",
      "2016-05-13 21:45:08.915000, i:5, param:0.300009, log-loss(tr:0.334393534638, te:0.461169908947)\n",
      "alpha: 0.3600088\n",
      "2016-05-13 21:45:08.988000, i:6, param:0.3600088, log-loss(tr:0.304271086176, te:0.455291214184)\n",
      "alpha: 0.4200086\n",
      "2016-05-13 21:45:09.047000, i:7, param:0.4200086, log-loss(tr:0.277863360035, te:0.451089501586)\n",
      "alpha: 0.4800084\n",
      "2016-05-13 21:45:09.109000, i:8, param:0.4800084, log-loss(tr:0.254329052853, te:0.447970652479)\n",
      "alpha: 0.5400082\n",
      "2016-05-13 21:45:09.185000, i:9, param:0.5400082, log-loss(tr:0.233140265274, te:0.445606637595)\n",
      "alpha: 0.600008\n",
      "2016-05-13 21:45:09.254000, i:10, param:0.600008, log-loss(tr:0.213944446091, te:0.443809034476)\n",
      "alpha: 0.6600078\n",
      "2016-05-13 21:45:09.314000, i:11, param:0.6600078, log-loss(tr:0.196490478556, te:0.442464876478)\n",
      "alpha: 0.7200076\n",
      "2016-05-13 21:45:09.398000, i:12, param:0.7200076, log-loss(tr:0.180587766718, te:0.441503080914)\n",
      "alpha: 0.7800074\n",
      "2016-05-13 21:45:09.461000, i:13, param:0.7800074, log-loss(tr:0.166083072842, te:0.440876474214)\n",
      "alpha: 0.8400072\n",
      "2016-05-13 21:45:09.541000, i:14, param:0.8400072, log-loss(tr:0.152847218727, te:0.440551985846)\n",
      "alpha: 0.900007\n",
      "2016-05-13 21:45:09.601000, i:15, param:0.900007, log-loss(tr:0.140767386667, te:0.44050519869)\n",
      "alpha: 0.9600068\n",
      "2016-05-13 21:45:09.665000, i:16, param:0.9600068, log-loss(tr:0.129742637877, te:0.440717250363)\n",
      "alpha: 1.0200066\n",
      "2016-05-13 21:45:09.732000, i:17, param:1.0200066, log-loss(tr:0.119681288631, te:0.441173014123)\n",
      "alpha: 1.0800064\n",
      "2016-05-13 21:45:09.797000, i:18, param:1.0800064, log-loss(tr:0.110499357558, te:0.441859983949)\n",
      "alpha: 1.1400062\n",
      "2016-05-13 21:45:09.870000, i:19, param:1.1400062, log-loss(tr:0.102119624357, te:0.442767556169)\n",
      "alpha: 1.200006\n",
      "2016-05-13 21:45:09.959000, i:20, param:1.200006, log-loss(tr:0.0944710287064, te:0.443886544688)\n",
      "alpha: 1.2600058\n",
      "2016-05-13 21:45:10.023000, i:21, param:1.2600058, log-loss(tr:0.0874882482219, te:0.445208843783)\n",
      "alpha: 1.3200056\n",
      "2016-05-13 21:45:10.091000, i:22, param:1.3200056, log-loss(tr:0.0811113602665, te:0.446727191713)\n",
      "alpha: 1.3800054\n",
      "2016-05-13 21:45:10.164000, i:23, param:1.3800054, log-loss(tr:0.0752855331799, te:0.448435007446)\n",
      "alpha: 1.4400052\n",
      "2016-05-13 21:45:10.226000, i:24, param:1.4400052, log-loss(tr:0.0699607186778, te:0.450326281375)\n",
      "alpha: 1.500005\n",
      "2016-05-13 21:45:10.293000, i:25, param:1.500005, log-loss(tr:0.0650913341792, te:0.4523955047)\n",
      "alpha: 1.5600048\n",
      "2016-05-13 21:45:10.364000, i:26, param:1.5600048, log-loss(tr:0.0606359346473, te:0.454637624165)\n",
      "alpha: 1.6200046\n",
      "2016-05-13 21:45:10.431000, i:27, param:1.6200046, log-loss(tr:0.0565568797521, te:0.457048010695)\n",
      "alpha: 1.6800044\n",
      "2016-05-13 21:45:10.507000, i:28, param:1.6800044, log-loss(tr:0.0528200048906, te:0.45962243266)\n",
      "alpha: 1.7400042\n",
      "2016-05-13 21:45:10.568000, i:29, param:1.7400042, log-loss(tr:0.049394304741, te:0.462357027142)\n",
      "alpha: 1.800004\n",
      "2016-05-13 21:45:10.629000, i:30, param:1.800004, log-loss(tr:0.0462516364484, te:0.465248265438)\n",
      "alpha: 1.8600038\n",
      "2016-05-13 21:45:10.699000, i:31, param:1.8600038, log-loss(tr:0.0433664470753, te:0.468292911693)\n",
      "alpha: 1.9200036\n",
      "2016-05-13 21:45:10.767000, i:32, param:1.9200036, log-loss(tr:0.0407155272946, te:0.471487975863)\n",
      "alpha: 1.9800034\n",
      "2016-05-13 21:45:10.826000, i:33, param:1.9800034, log-loss(tr:0.0382777909993, te:0.474830663722)\n",
      "alpha: 2.0400032\n",
      "2016-05-13 21:45:10.887000, i:34, param:2.0400032, log-loss(tr:0.0360340788473, te:0.47831832749)\n",
      "alpha: 2.100003\n",
      "2016-05-13 21:45:10.955000, i:35, param:2.100003, log-loss(tr:0.0339669828623, te:0.481948420764)\n",
      "alpha: 2.1600028\n",
      "2016-05-13 21:45:11.018000, i:36, param:2.1600028, log-loss(tr:0.032060688994, te:0.48571846097)\n",
      "alpha: 2.2200026\n",
      "2016-05-13 21:45:11.077000, i:37, param:2.2200026, log-loss(tr:0.0303008348088, te:0.489626001721)\n",
      "alpha: 2.2800024\n",
      "2016-05-13 21:45:11.138000, i:38, param:2.2800024, log-loss(tr:0.028674380029, te:0.493668616443)\n",
      "alpha: 2.3400022\n",
      "2016-05-13 21:45:11.199000, i:39, param:2.3400022, log-loss(tr:0.0271694882372, te:0.497843893556)\n",
      "alpha: 2.400002\n",
      "2016-05-13 21:45:11.258000, i:40, param:2.400002, log-loss(tr:0.0257754185834, te:0.502149442532)\n",
      "alpha: 2.4600018\n",
      "2016-05-13 21:45:11.319000, i:41, param:2.4600018, log-loss(tr:0.0244824266858, te:0.506582909356)\n",
      "alpha: 2.5200016\n",
      "2016-05-13 21:45:11.383000, i:42, param:2.5200016, log-loss(tr:0.0232816741053, te:0.511141999306)\n",
      "alpha: 2.5800014\n",
      "2016-05-13 21:45:11.450000, i:43, param:2.5800014, log-loss(tr:0.0221651458257, te:0.515824504566)\n",
      "alpha: 2.6400012\n",
      "2016-05-13 21:45:11.509000, i:44, param:2.6400012, log-loss(tr:0.0211255751436, te:0.520628333997)\n",
      "alpha: 2.700001\n",
      "2016-05-13 21:45:11.569000, i:45, param:2.700001, log-loss(tr:0.0201563753297, te:0.525551542372)\n",
      "alpha: 2.7600008\n",
      "2016-05-13 21:45:11.648000, i:46, param:2.7600008, log-loss(tr:0.0192515774007, te:0.530592356515)\n",
      "alpha: 2.8200006\n",
      "2016-05-13 21:45:11.712000, i:47, param:2.8200006, log-loss(tr:0.0184057733334, te:0.535749196111)\n",
      "alpha: 2.8800004\n",
      "2016-05-13 21:45:11.773000, i:48, param:2.8800004, log-loss(tr:0.017614064126, te:0.541020687295)\n",
      "alpha: 2.9400002\n",
      "2016-05-13 21:45:11.833000, i:49, param:2.9400002, log-loss(tr:0.0168720121873, te:0.546405667677)\n",
      "---Total execution time: 3.30799984932 seconds ---\n"
     ]
    }
   ],
   "source": [
    "arr_alpha = list(np.linspace(.00001, 3., 50, endpoint=False))\n",
    "#arr_alpha = list(np.log(arr_alpha))\n",
    "\n",
    "arr_log_loss_sgd_train_best_alpha = [0]*len(arr_alpha)\n",
    "arr_log_loss_sgd_test_best_alpha = [0]*len(arr_alpha)\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(0,len(arr_alpha)):\n",
    "    print('alpha: %s' %(arr_alpha[i]))\n",
    "    param, arr_log_loss_sgd_train_best_alpha[i], arr_log_loss_sgd_test_best_alpha[i] = sgd_training(alpha =\n",
    "             arr_alpha[i]\n",
    "             , D = 2**20\n",
    "             , f_debug = False\n",
    "             , f_step_validation = False\n",
    "             , f_validation = True\n",
    "             , c_ds = ds_best_param)\n",
    "             \n",
    "    print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_alpha[i]\n",
    "                                                     , arr_log_loss_sgd_train_best_alpha[i]\n",
    "                                                     , arr_log_loss_sgd_test_best_alpha[i]))\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 0.90000699999999989, 0.4405051986901799)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAv8AAAFwCAYAAAAv9RSyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiIqIEwck/EREREVGC+A8xooZDK824jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2011f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(arr_alpha, arr_log_loss_sgd_train_best_alpha, marker='o', color='r')\n",
    "plt.plot(arr_alpha, arr_log_loss_sgd_test_best_alpha, marker='o', color='b')\n",
    "\n",
    "ndarr_test = np.array(arr_log_loss_sgd_test_best_alpha)\n",
    "(ndarr_test.argmin(), arr_alpha[ndarr_test.argmin()], arr_log_loss_sgd_test_best_alpha[ndarr_test.argmin()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF : variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-36c19647c1d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m              \u001b[1;33m,\u001b[0m \u001b[0mf_step_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m              \u001b[1;33m,\u001b[0m \u001b[0mf_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m              , c_ds = ds_best_param)\n\u001b[0m\u001b[0;32m     16\u001b[0m     print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_var[i]\n\u001b[0;32m     17\u001b[0m                                                      \u001b[1;33m,\u001b[0m \u001b[0marr_log_loss_adf_train_best_var\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-123-ce222242fd5a>\u001b[0m in \u001b[0;36madf_training\u001b[1;34m(variance, D, f_debug, f_step_validation, f_validation, c_ds)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_x_mmh3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Label'"
     ]
    }
   ],
   "source": [
    "arr_var = list(np.linspace(.0001, 3.1, 20, endpoint=False))\n",
    "#arr_var = list(np.log(arr_var))\n",
    "\n",
    "arr_log_loss_adf_train_best_var = [0]*len(arr_var)\n",
    "arr_log_loss_adf_test_best_var = [0]*len(arr_var)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0,len(arr_var)):\n",
    "    param, arr_log_loss_adf_train_best_var[i], arr_log_loss_adf_test_best_var[i] = adf_training(variance = arr_var[i]\n",
    "             , D = 2**20\n",
    "             , f_debug = False\n",
    "             , f_step_validation = False\n",
    "             , f_validation = True\n",
    "             , c_ds = ds_best_param)\n",
    "    print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_var[i]\n",
    "                                                     , arr_log_loss_adf_train_best_var[i]\n",
    "                                                     , arr_log_loss_adf_test_best_var[i]))\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(arr_var, arr_log_loss_adf_train_best_var, marker='o', color= 'r')\n",
    "plt.plot(arr_var, arr_log_loss_adf_test_best_var, marker='o', color= 'b')\n",
    "\n",
    "ndarr_test = np.array(arr_log_loss_adf_test_best_var)\n",
    "(ndarr_test.argmin(), arr_var[ndarr_test.argmin()], arr_log_loss_adf_test_best_var[ndarr_test.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
