{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version info\n",
    ">v011 - deleted testing codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 750 (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import pymc3 as pm\n",
    "import scipy.optimize as so\n",
    "\n",
    "#from pymc3 import Model, sample, find_MAP, summary\n",
    "#from pymc3 import NUTS, Metropolis, Slice\n",
    "#from pymc3 import Normal, Uniform\n",
    "#from scipy import optimize\n",
    "#from pymc3 import traceplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing barley data(explatory variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Loading data file\n",
    "#barley_raw = pd.read_csv('./data/barley_01.csv', sep=',', header=0, index_col=0)\n",
    "barley_raw = pd.read_table('./data/barley_01.txt', sep='\\t', header=0, index_col=0)\n",
    "\n",
    "#Explorering data\n",
    "if debug:\n",
    "    barley_raw.head()\n",
    "    barley_raw.info()\n",
    "\n",
    "#Transposing\n",
    "barley_t = barley_raw.transpose()\n",
    "if debug:\n",
    "    print(barley_t.iloc[0:5, 0:5])\n",
    "\n",
    "# 39, 96, 116, 103 th DH lines removed for marker mapping(146 marker mappings)\n",
    "# and also 33 th DH line should be removed for QTL analysis(145 lines)\n",
    "barley = barley_t.drop(labels=barley_t.index[[39-1, 96-1, 116-1, 103-1, 33-1]])\n",
    "\n",
    "barley.head()\n",
    "\n",
    "#Imputed missing(-) to 1 temporarily, I'll use automatic imputation feature of PyMC\n",
    "#[http://stronginference.com/missing-data-imputation.html]\n",
    "barley.replace(['A', 'B', '-'], [0,1,1], inplace=True)\n",
    "\n",
    "if debug:\n",
    "    print(barley.ix[:6,10:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and preprocessing heading data(response variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "heading_raw = pd.read_table('./data/HED_01.txt', sep='\\t', header=0, index_col=0)\n",
    "heading_raw.replace([-9999.0, -9999], [float('NaN'), float('NaN')], inplace=True)\n",
    "if debug:\n",
    "    print(heading_raw.head())\n",
    "    \n",
    "# Averaging 'days to heading' over all environments for each line.\n",
    "heading = heading_raw.mean(skipna=True)\n",
    "if debug:\n",
    "    heading.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing with small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_n = 20\n",
    "num_p = 2\n",
    "X = barley.ix[:num_n,:num_p]\n",
    "Y = heading.ix[:num_n]\n",
    "\n",
    "X.ix[:,0]\n",
    "\n",
    "niter = 1000\n",
    "\n",
    "basic_model = pm.Model()\n",
    "\n",
    "with basic_model:\n",
    "    # Priors\n",
    "    beta0 = pm.Normal('beta0', mu=0, sd=100, shape=1)\n",
    "    beta1 = pm.Normal('beta1', mu=0, sd=100, shape=1)\n",
    "    beta2 = pm.Normal('beta2', mu=0, sd=100, shape=1)\n",
    "    sigma = pm.Uniform('sigma', lower=0, upper=20)\n",
    "    \n",
    "    # \n",
    "    y_est = beta0 + beta1*X.ix[:,0] + beta2*X.ix[:,1]\n",
    "    \n",
    "    # \n",
    "    likelihood = pm.Normal('y', mu=y_est, sd=sigma, observed=Y)\n",
    "    \n",
    "    # inference\n",
    "    start = pm.find_MAP()\n",
    "    trace = pm.sample(niter, start=start, random_seed=2015, progressbar=True)\n",
    "    pm.traceplot(trace)\n",
    "\n",
    "pm.summary(trace)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
