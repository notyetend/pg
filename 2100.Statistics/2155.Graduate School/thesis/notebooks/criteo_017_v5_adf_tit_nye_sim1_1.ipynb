{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "            \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?: sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 1000        #train_start, train_size\n",
    "                         , 1001, 1000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 0.30817508697509766 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 0.4612619876861572 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'accuracy': 0.71599999999999997, 'precision': 0.37966101694915255, 'fp': 183, 'recall': 0.5258215962441315, 'tp': 112, 'tn': 604, 'f1_score': 0.44094488188976377, 'tot': 1000, 'fn': 101}, 0.5703298035967919)\n"
     ]
    }
   ],
   "source": [
    "sim1_sgd = get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test\n",
    "print(sim1_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'accuracy': 0.70199999999999996, 'precision': 0.34317343173431736, 'fp': 178, 'recall': 0.43661971830985913, 'tp': 93, 'tn': 609, 'f1_score': 0.38429752066115702, 'tot': 1000, 'fn': 120}, 0.5703053673521401)\n"
     ]
    }
   ],
   "source": [
    "sim1_adf = get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test\n",
    "print(sim1_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.71711676241268019, 0.70265046441290679)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5a8a5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')\n",
    "    \n",
    "sim1_auc = (roc_auc_sgd, roc_auc_adf)\n",
    "print(sim1_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
