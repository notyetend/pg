{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "            \n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        # Balancing 0 and 1\n",
    "        if((y == 0.) & (np.random.binomial(1, 0.65) == 1)):\n",
    "            continue\n",
    "            \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?: sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 1000000        #train_start, train_size\n",
    "                         , 1000001, 1000000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 226.40464687347412 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 292.78665804862976 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'precision': 0.44975906616271116, 'f1_score': 0.54259324692267963, 'fn': 78495, 'fp': 207596, 'tot': 1000000, 'tp': 169686, 'accuracy': 0.71390900000000002, 'tn': 544223, 'recall': 0.68371873753429957}, 0.5596582211712917)\n"
     ]
    }
   ],
   "source": [
    "sim1_sgd = get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test\n",
    "print(sim1_sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'precision': 0.45150424782262333, 'f1_score': 0.54285140336357285, 'fn': 79285, 'fp': 205178, 'tot': 1000000, 'tp': 168896, 'accuracy': 0.71553699999999998, 'tn': 546641, 'recall': 0.68053557685721311}, 0.5571698148722777)\n"
     ]
    }
   ],
   "source": [
    "sim1_adf = get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test\n",
    "print(sim1_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.77572177258192621, 0.77649363071454358)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRESkACUGEREp4P8BBgoMwaYaZdkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xf202f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')\n",
    "    \n",
    "sim1_auc = (roc_auc_sgd, roc_auc_adf)\n",
    "print(sim1_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
