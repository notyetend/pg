{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅데이터 분석을 위한 실시간 로지스틱 회귀모형에 관현 연구\n",
    "## : 베이지안 접근법을 중심으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 배경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 새로운 특성의 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 많은 (범주형)변수\n",
    "> - 유동적인 범주값, 추가적인 범주가 지속적으로 추가됨\n",
    "> - 수천만건 이상의 sample size\n",
    "> - 실시간에 가까운 분석 필요\n",
    "> - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 새로운 특성의 데이터를 위한 분석 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 대규모의 분산 데이터 처리(Scalable Massive Distributed Data Processing)\n",
    "> - **해싱을 이용한 가변수 코딩(Feature Hashing)**\n",
    "> - **온라인 최적화(Stochastic Gradient Descent, Assumed Density Filtering)**\n",
    "> - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***---***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 우리는 데이터 폭증의 시대에 살고 있다. 웹 로그, IoT기기 로그, 게임 로그 등 단일 서비스에서 하루에 발생하는 로그의 양은 상상을 초월한다. 예를들어 facebook의 하루 로그 크기는 600TB정도로서 기존의 통계 분석 방법으로는 간단한 인사이트 조차 얻기 어려운 경우가 많다. 그리고 데이터의 규모가 커진 것 뿐만 아니라 급변하는 사용자 요구 사항과 경쟁자의 출현에 맞서 거의 실시간으로 이러한 데이터를 분석해 빠른 의사결정을 하거나 즉각적인 서비스를 제공하는 등의 대응을 해야하는 상황에 직면하고 있다. 또한 데이터의 건수가 많아지는 문제와 더불어 다수의 범주형 변수와 각 범주형 변수마다 수백 수천개의 범주가 있고 시간이 지남에 따라 예측할 수 없는 다양한 범주가 추가될 수 있는 형태의 데이터를 분석해야 하는 경우도 생겨난다.\n",
    "\n",
    "> 예를들어 TrueSkill과 같이 다량의 플레이어 게임 메칭 데이터를 이용해 플레이어의 승률을 계산하여 최적의 게임 메칭 상태를 찾는 문제\\citep{Herbrich2006}, 특정 Facebook 사용자의 timeline에 다양한 조건의 광고 중 어떤 광고를 노출 시켜야 광고 클릭 확률이 높을 것인지를 예측하는 문제\\citep{He2014}, 매출의 대부분을 차지하는 고부가 가치 유저(High-Valued Player)가 게임에서 이탈할 확률을 계산하는 문제\\citep{Runge2014} 등은 대규모 데이터 분석과 빠른 예측이 비즈니스의 성패를 좌우하는 경우라고 할 수 있다. 이러한 문제를 풀기 위해서는 규모 가변적이고 대규모의 분산 데이터 처리(Scalable Massive Distributed Data Processing)를 위한 하드웨어와 소프트웨어, 그리고 이에 맞는 분석 방법론이 필요하고 본 논문에서는 분석 방법론에 대해 고찰해 볼 것이다.\n",
    " \n",
    "> 앞서의 상황과 같이 유동적 다변량의 다샘플 데이터를 실시간으로 분석하는 것은 기존 배치방식의 통계 분석으로는 효과적이지 않다. 가령 데이터가 스트리밍으로 유입되고 이를 분석 데이터에 추가하고 모수 값을 계산해야하는 상황에서 매번 전체 데이터에 대해 모형 적합을 수행해서는 실시간에 가까운 예측 결과를 내놓기 어렵다. 또한 새로운 변수 혹은 범주가 데이터 세트에 추가될 때마다 모수 벡터를 다시 구성하고 모형 적합을 다시 수행하는 것은 좋은 접근법이라 할 수 없다. \n",
    "\n",
    "> 본 논문에서는 배치 방식에 대비되는 온라인 모형 적합 방법을 샘플 수가 수천만건에 이르고 다수의 범주형 변수, 그리고 범주의 개수가 유동적인 대규모 데이터에 적용하기 위한 모형 적합 방법과 해싱을 이용한 가변수 코딩(Feature Hashing)에 대해 고려해 보고 각 방법의 특성에 대해서 고찰해 볼 것이다. 또한 가상 데이터와 실제 데이터에에 각 방법론의 적용해 보고 각각의 특성을 실증적으로 살펴볼 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 해싱을 이용한 가변수 코딩(Feature Hashing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 해시?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 해시 함수(hash function)는 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 알고리즘.   \n",
    "> - 암호화에 많이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 암호화 해시: 복호화가 어려워야 함, (MD5, SHA)\n",
    "> - 비암호화 해시: 분포적 특성과 해싱 속도가 중요, (murmur, city, spooky)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mmh3\n",
    "mmh3.hash128('mategoryStr')\n",
    "# producing integer between 0 and 2^128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from spooky import hash128, hash64, hash32\n",
    "hash32('myCategoryStri')\n",
    "# producing integer between 0 and 2^32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Local image](./images/feature_hashing_overview.PNG \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다수의 변수가 포함되어 있거나 범주형 변수의 범주가 많은 자료를 분석하고자 하는 경우 차원을 축소(Dimensionality reduction)하고 가변수 값의 성김(sparsity)으로 인한 많은 메모리 사용량 문제를 해결하고, 빠르게 데이터 레코드에 해당하는 메모리 상의 feature 벡터의 값에 접근하게 하고, 온라인 학습에서는 매 분석 시점마다 범주형 변수의 범주가 추가될 수도 있는 문제를 해결하기 위해 Hashing Trick(Feature Hashing)을 사용한다.\n",
    "\n",
    "> 해싱 방식은 크게 암호방식과 비암호방식으로 나뉜다. 암호방식은 해싱 성능 보다는 해시값 복호화가 어려워야 한다는 중요한 특성을 갖도록 고안된 방식이다. 반면 비암호화 방식은 복호과가 가능하느냐는 중요하지 않고 해싱을 수행하는 속도와 해시 결과의 분포적 특성에 중점을 둔 방식이다. 여기서 분포적 특성이란 입력값이 문자열 상으로 유사하더라도 그 결과는 어느 구간에 밀집되지 않고 전체 해시 공간에 고르게 분포하는 것을 말한다.\\citep{Ramadhian2013} 속도 측면에서는 대표적인 암호화 해시 방식인 SHA-1이 0.09 bytes/cycle의 해싱 속도를 갖는 반면 비암호화 해시의 하나인 MurmurHash의 경우 1 byte/cycle의 속도로서 거의 10배 빠르다. \n",
    "\n",
    "> 물론 Feature Hashing을 사용하는 것이 장점만이 있는 것은 아니다. 대표적인 문제로 해시 충돌을 들 수 있다. 분포도가 양호한 해시 방식을 사용하는 것이 가장 우선 이겠으나 해시 충돌은 발생할 수 있는 문제이고, 이를 줄이기 위해 해시 함수에 입력될 문자열을 모든 변수의 범주를 통틀어 가능한 유일 하도록 매핑하는 작업을 하거나 피쳐 벡터(feature vector)의 크기를 고려하여 해시 테이블 크기를 조정 하는 것도 한 방법이다.\n",
    "\n",
    "> 구체적으로 해싱을 가변수(dummy variable) 설정에 어떻게 사용되는지 살펴보자. 샘플 수가 $N$인 가변수 생성 전 데이터에서 범주형인 $j$번째 변수 $x_j$에 $C_1 , C_2 , \\cdots , C_{K_j}$의 $K_j$개 범주가 있다고 해 보자. 일반적인 가변수 코딩에서는 $K_j$개의 범주에 대해 $K_j - 1$개의 가변수를 설정하는데 그럴 경우 각 가변수 벡터는 $K_j - 2$개의 0과 1개의 1로 구성된다. 그런데 범주의 수 $K_j$가 커지고 샘플 수가 많아지면 가변수 매트릭스의 성김(sparsity)이 심해지고 정보량에 비해 메모리 사용량과 처리 부하가 커지게 된다. 또한 스트리밍으로 유입되는 새로운 데이터에서 $x_j$에 기존에 없던 범주($C_{K_j + 1}$)가 등장할 경우 가변수 설정과 적합을 다시 진행해야 한다. \n",
    " 반면 Feature Hashing을 적용할 경우를 살펴보자. $x_j$의 $k(0 \\leq k \\geq K_j)$번째 범주 $C_k$를 문자열 그대로 혹은 전체 범주에 대한 유일성을 보장하기 위해 $x_j C_k$를 문자열 형태로 해시 함수의 입력으로 넣는다. 예를들어 64비트 해시 함수를 사용할 경우 1과 $2^{64}$ 사이의 숫자($h_jk$)를 출력 값으로 얻게 된다. 이 숫자는 모수 벡터의 인덱스를 의미하기 때문에 $i$번재 샘플의 $j$번째 변수 $x_j$는 0과 1로 이루어진 벡터가 아니라 단순히 숫자 $h_ijk$로 표현된다. 만약 변수 변환 이후 대략적인 전체 모수 벡터의 길이가 $2^64$보다 월등히 작을 경우 적당한 숫자 $L$로 $h_ijk$를 모듈러 연산하여 모수 벡터의 길이를 $L$로 제한할 수 있다. 즉 $L$이 충분히 클 경우 대략 $L$개까지 범주 수가 늘어나더라도 가변수를 다시 설정하지 않아도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 온라인 최적화 알고리즘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. 확률적 경사 하강법(Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> 최적화(optimization) 알고리즘의 하나인 경사하강법(Gradient descent)에서는 전체 샘플 데이터를 스캔 할 때마다 회귀 계수 추정치를 갱신해 나간다. 비용함수(cost function)를 $J(w) = \\frac{1}{2} \\sum_{i}(target^{(i)} - output^{(i)})^{2}$ 라 할때 길이가 j인 계수 벡터(weight vector) $w_i$를 $w_{i+1}=w_{i}+\\Delta w$로 갱신하는 매 반복에서 $j$개의 모수 추정치($w$)를 얼마만큼 줄일지 혹은 늘릴지 $\\Delta w$ 값을 결정해야 한다. 여기에서 $\\Delta w$는 아래와 같다.\n",
    "\\begin{eqnarray}\n",
    "\\Delta w_{j} \t&=& -\\alpha \\frac{\\delta J}{\\delta w_{j}} \\\\\n",
    "\t\t\t\t\t\t\t&=& -\\alpha \\sum_{i}(target^{(i)} - output^{(i)})(-x^{(i)_{j}}) \\\\\n",
    "\t\t\t\t\t\t\t&=& \\alpha \\sum_{i}(target^{(i)} - output^{(i)})(x^{(i)_{j}})\n",
    "\\end{eqnarray}\n",
    "즉 비용함수(cost function)의 경사도가 크면 그만큼 많이 $w$값을 수정하게 되는데, 학습 계수(learning rate, step size) $\\alpha$에 비례하여 수정치가 결정된다.\n",
    "\n",
    "> 경사하강법에서는 한번 $w$값을 수정하기 위하여 전체 샘플 데이터를 스캔하게 된다. 그런데 이런 방식은 샘플의 수가 많은 경우 \n",
    "비용함수 $J(w)$를 최소로 하는 $w$값을 찾기 까지 그 처리 시간이 길어 지게 된다. 모수에 대한 학습(learning)이나 추론(inference)를 진행할 때 데이터의 크기가 작거나 데이터의 수집으로부터 예측까지 시간적 여유가 있을 경우 데이터 전체를 한꺼번에 활용하는 일괄 처리(batch processing) 방식을 사용한다. 반면 데이터를 한꺼번에 처리하기에 그 크기가 지나치게 크거나 스트리밍(streaming)으로 유입되는 데이터에 대해서 실시간으로 예측을 처리해야 하는 경우 온라인 학습(online learning)을 사용해야 할 필요성이 있다.\n",
    "\n",
    "> 이처럼 매 갱신에서 전체 샘플 데이터를 사용하는 대신 샘플 하나 혹은 일부분만을 사용하여 $w$ 값을 갱신해 가는 경사하강법을 확률적 경사 하강법(Stochastic Gradient Descent, Online Gradient Descent)이라 하며, 확률적 이라는 단어에서 알 수 있듯이 $J(w)$를 최소로 하는 $w$값을 확률적 근사방법으로 찾아가는 것이다. 하나의 샘플만을 이용해 $w$의 갱신 방향과 크기를 결정하기 때문에 경사하강법과는 달리 $J(w)$값이 커지는 경우도 있으나 샘플 수가 충분할 경우 $J(w)$의 전역 최소값으로 수렴하는 $w$를 찾을 수 있는 것으로 알려져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 본 연구에서는 전체 파라미터 벡터에 동일한 step size 초기값을 설정하고, iteration이 증가하면서 각 hashed-feature가 등장하는 횟수로 step size를 나눈다.  \n",
    "> - 즉 특정 hashed-feature가 많이 등장할 수록 해당 회귀 모수에 대한 step-size가 감소하게 되고, 자주 등장하지 않는 hashed-feature의 경우 비교적 큰 step-size를 갖게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [알고리즘]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simplified version of SGD\n",
    "c_fi = fi_titanic\n",
    "\n",
    "D = 2 ** 20\n",
    "alpha = 0.92000539999999997 # initial value for setp size alpha\n",
    "w = [0.] * D  # parameter vector\n",
    "n = np.array([0.] * (D))\n",
    "\n",
    "f = open(c_fi.file_path)\n",
    "for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "    if t == 0:\n",
    "        continue\n",
    "    del row['PassengerId']\n",
    "    \n",
    "    y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "    del row[c_fi.ylab]\n",
    "    \n",
    "    x = get_x_mmh3(row, D)\n",
    "    p = get_p(x, w)\n",
    "    w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. 추정된 밀도 필터링(Assumed Density Filtering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 추정된 밀도 필터링(Assumed-density filtering, ADF) 이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 추정된 밀도 필터링(Assumed-density filtering, ADF)는 베이지안 네트워크 혹은 여타의 통계 모형에서 사후분포를 근사적으로 계산하는 방법으로서 통계학에는 Lauritzen, 1992이 제안. 분야에 따라 달리 불림\n",
    " \n",
    " > - 추정된 밀도 필터링(Assumed-density filtering)  \n",
    " > - 온라인 베이지안 학습(On-line Bayesian learning)  \n",
    " > - 적률 대응(Moment matching)  \n",
    " > - 약한 주변화(Weak marginalization)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  ADF에서는 사후분포를 가우시안과 같은 특정 분포로 근사하는 방법으로서 예측-갱신-투영(predict-update-project)과정을 반복한다. \n",
    " \n",
    "> - 예측(predict): 모수 $\\theta$에 대한 $t-1$ 시점의 사전분포, $q_{t-1}(\\theta_{t-1})$와 $t$시점의 관측치를 이용하여 이후 시점 $t$에서의 $\\theta$에 대한 사후예측분포, $q_{t|t-1}(\\theta_{t})$를 구함\n",
    "> - 갱신(update): 앞서 구한 사전분포와 사후예측분포를 이용하여 $\\theta$에 대한 사후분포, $\\hat{p}(\\theta_t)$를 구함 \n",
    "> - 투영(project): 마지막으로 이 사후 분포가 다루기 쉬운 형태가 아닌 경우가 빈번하기 때문에 다루기 쉬운 분포로 투영(project)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 근사 사전분포: \n",
    "$$q_{t-1}(\\theta_{t-1}) \\approx p(\\theta_{t-1}|y_{1:t-1})$$\n",
    "<br>\n",
    "- 1단계 사후예측분포: \n",
    "$$q_{t|t-1}(\\theta_t) = \\int p(\\theta_t | \\theta_{t-1}) q_{t-1}(\\theta_{t-1}) d\\theta_{t-1}$$\n",
    "<br>\n",
    "- 사후분포:\n",
    "$$\\hat{p}(\\theta_t) = \\frac{1}{Z_t}p(y_t | \\theta_t)q_{t|t-1}(\\theta_t)$$\n",
    "<br>\n",
    "- 정규화 상수(normalizing constant):\n",
    "$$Z_t = \\int p(y_t | \\theta_{t-1})q_{t|t-1}(\\theta_{t})d\\theta_{t}$$\n",
    "<br>\n",
    "- 근사 사후분포:\n",
    "$$q(\\theta_t) = \\arg\\min_{q \\in Q} \\mathrm{KL}(\\hat{p}(\\theta_t || q(\\theta_t)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 지수족에서의 추정된 밀도 필터링(Assumed-density filtering, ADF) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 투영하려는 분포 $q$가 지수족에 속할 경우 단순히 적률 대응(moment matching)만으로 $q(\\theta_t)$를 구할수 있다. 따라서 일반화 선형모형에 적률 대응을 적용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 편의를 위해 설명변수와 회귀계수의 선형식(systematic component)을 $s_t=\\theta_t^T x_t$라 하고, 만약 $\\theta_t$에 대한 1단계 사후예측분포, $q_{t|t-1}(\\theta_t)$가$\\prod_i N(\\theta_{t,i};\\mu_{t|t-1,i},\\sigma^2_{t|t-1,i})$라면 $s_t$의 사후 예측분포, $q_{t|t-1}(s_t)$ 는 아래와 같다.\n",
    "\n",
    "> \\begin{eqnarray}\n",
    "   q_{t|t-1}(s_{t}) &\\equiv& N(s_t;m_{t|t-1}, {v}_{t|t-1})\n",
    "\\\\ m_{t|t-1} &=& \\sum^N_{i=1}x_{t,i}\\mu_{t|t-1,i}\n",
    "\\\\ {v}_{t|t-1} &=& \\sum^N_{i=1}x^2_{t,i}{\\sigma}^2_{t|t-1,i}\n",
    "\\end{eqnarray}\n",
    "\n",
    "> 이때 $s_t$의 사후분포, $q_t(s_t)$는 아래와 같다.\n",
    "\n",
    "> \\begin{eqnarray}\n",
    " q_t(s_t) &\\equiv& N(s_t; m_t, v_t)\n",
    " \\\\ m_t &=& \\int s_t \\frac{1}{z_t} f(y_t|s_t) q_{t|t-1}(s_t)ds_t\n",
    " \\\\ v_t &=& \\int s^2_t \\frac{1}{z_t} f(y_t|s_t) q_{t|t-1}(s_t) ds_t - m_t^2  \n",
    "\\\\ z_t &=& \\int f(y_t|s_t) q_{t|t-1}(s_t)ds_t\n",
    "\\\\ f(y_t|s_t) &\\equiv& Ber(y_t;\\pi = sigmoid(s_t))\n",
    "\\\\ & =& \\pi^{y_t} (1-\\pi)^{(1-y_t)}, \\quad y_t \\in \\{0,1\\}\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 가우시안 구적법(Gaussian quadrature)을 이용해 위 적분식 근사\n",
    "$$\\int^b_a W(x)f(x)dx \\approx \\sum^N_{j=1}w_j f(x_j)$$\n",
    "$$\\chi=\\chi'\\sqrt{2}\\sigma_{s_t}+\\mu_{s_t}$$ \n",
    "$$\\omega_i = \\frac{\\omega'}{\\sqrt{\\pi}}$$\n",
    "\n",
    "> \\begin{eqnarray}\n",
    "q_t(s_t) &=& N(s_t; \\tilde{m}_t, \\tilde{v}_t)\n",
    "\\\\ \\tilde{m}_t &=& \\frac{1}{\\tilde{z}_t} \\sum_i \\chi_i f(y_t; \\chi_i ) \\omega_i\n",
    "\\\\ \\tilde{v}_t &=& \\frac{1}{\\tilde{z}_t} \\sum_i \\chi^2_i f(y_t; \\chi_i ) \\omega_i - \\tilde{m}^2_t\n",
    "\\\\ \\tilde{z}_t &=& \\sum_i f(y_t; \\chi_i ) \\omega_i\n",
    "\\end{eqnarray}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_v = 0.52007399999999993 # best for titanic\n",
    "\n",
    "theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "theta_t_v = np.array([init_v] * (D)) # variance of thetas at t\n",
    "n = np.array([0.] * D)\n",
    "\n",
    "f = open(c_fi.file_path)\n",
    "for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "\n",
    "    if t == 0:\n",
    "        continue\n",
    "    del row['PassengerId']\n",
    "    \n",
    "    y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "    del row[c_fi.ylab]\n",
    "\n",
    "    x = get_x_mmh3(row, D)\n",
    "\n",
    "    # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "    s_t_m_old = sum(theta_t_m[x])\n",
    "    s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "    # Posterior distribution for s_t\n",
    "    s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "    # Changes in s_t\n",
    "    delta_m = s_t_m - s_t_m_old\n",
    "    delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "    # Updating theta\n",
    "    update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "    #p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 실험"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. 실험(타이타닉 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> - 소규모 데이터를 이용한 실험을 위해 891건의 타이타닉 생존자 데이터를 이용  \n",
    "> - 데이터는 생존여부(0, 1)를 나타내는 'Survived'와 탑승자의 특성을 나타내는 8가지 변수로 구성됨.\n",
    "> - 초기 800건을 훈련 데이터, 나머지 91건을 테스트 데이터로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 최적 초기값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> SGD는 step size의 초기값($\\alpha_{init}$)에, ADF는 회귀 계수 분포의 초기 분산값($V_{init}$)에 큰 영향을 받음.  \n",
    "> 주어진 데이터에 최적인 $\\alpha_{init}$과 $V_{init}$를 찾기 위해 각 값을 변화시키면서, 훈련 데이터와 테스트 데이터에 대한 log-loss를 관찰함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $logloss = -\\frac{1}{N}\\sum_{i=1}^N {(y_i\\log(p_i) + (1 - y_i)\\log(1 - p_i))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Stochastic Gadient Descent**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/best_param_sgd_T.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | Index     | $\\alpha$          |  log-loss |\n",
    "|----------|:-------:|:--------------:|\n",
    "| log-loss      | 11 | 0.11000779999999999 | 0.46879230769345764"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  테스트 데이터에 최소 log-loss를 갖는 $\\alpha$값은 0.11000779999999999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Assumed Density Filtering**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/best_param_adf_T.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | Index     | $\\alpha$          |  log-loss |\n",
    "|----------|:-------:|:--------------:|\n",
    "| log-loss      | 13 | 0.52007399999999993 | 0.39539652671035114\n",
    "\n",
    "> 테스트 데이터에 최소 log-loss를 갖는 분산값은 0.52007399999999993"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 훈련 데이터 크기에 따른 log-loss 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 16건의 훈련 데이터를 더 사용할 때마다 그때의 회귀 계수 벡터를 이용하여 91건의 테스트 데이터에 대한 log-loss 추이를 두 방법론(SGD, ADF)에 대해 비교한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_comparison_T.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 전반적으로 ADF에 비해 SGD의 log-loss가 낮음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_roc_T.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | SGD     | ADF          |\n",
    "|----------|:-------:|:--------------:|\n",
    "| AUC      |0.90041279669762642 | 0.88802889576883381  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. 실험(온라인 광고 데이터)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Criteo에서 'Kaggle 대회'를 위해 공개한 4천 5백만건 상당의 온라인 광고 데이터를 사용하였다. 데이터는 웹사이트 방문자가 해당 광고를 클릭 했으냐 혹은 하지 않았느냐를 나타내는 이항 반응변수 Label과 39개의 설명변수로 구성되어 있다. 그리고 각 설명변수는 범주형으로서 범주는 500개 이상으로 실제 데이터의 경우 훈련 데이터에 없던 범주가 새롭게 등장 할 수도 있는 특성을 갖는다. 이러한 데이터를 일괄처리(batch) 방식으로 처리한다면 대략 $19,500 \\times 45,000,000$ 크기의 매트릭스 연산을 수행해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 최적 초기값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Stochastic Gadient Descent**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ![Local image](./images/best_param_sgd_C.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>**Assumed Density Filtering**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/best_param_adf_C.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 훈련 데이터 크기에 따른 log-loss 비교( 훈련 데이터: 1만건, 테스트 데이터 1천건)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_comparison_C.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_roc_C.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | SGD     | ADF          |\n",
    "|----------|:-------:|:--------------:|\n",
    "| AUC      | 0.75874125874125875 | 0.75699300699300698 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 훈련 데이터 크기에 따른 log-loss 비교 ( 훈련 데이터: 100만건, 테스트 데이터 10만건)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_comparison_CC.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![Local image](./images/step_vali_roc_CC.png \"Tooltip for local image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | SGD     | ADF          |\n",
    "|----------|:-------:|:--------------:|\n",
    "| AUC      | 0.78110714529429526 | 0.78198942683050354|\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 맺음말"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> 본 논문에서는 다변수 대용량 데이터에 대한 실시간 모형 적합 방법과 구현시 고려 사항에 대해 고찰해 보았다. 우선 데이터의 규모가 커질 경우 배치 방식의 한계점으로 인하여 온라인 방식의 모형 적합 방법을 적용해야 했고, 대표적인 온라인 모형 적합 방법인 확률적 경사 하강법(Stochastic Gradient Descent)과 이 방법의 베이지안 접근이라 할 수 있는 추정된 밀도 필터링(Assumed-Density Filtering) 방법을 사용하여 예측 결과의 추이를 살펴보았다. \n",
    "\n",
    "> 일반적으로 베이지안 접근 방법은 대규모 데이터 처리에 적합하지 않다는 주장이 많다. 하지만 추정된 밀도 필터링과 같은 근사 분포를 사용하는 방법론을 사용할 경우 실시간 처리가 필수적인 온라인 러닝에 있어서도 충분히 만족스러운 속도로 분석을 진행 할 수 있음을 확인 할 수 있었다. 또한 컴퓨팅 속도를 향상 시킬 수 있는 프로그래밍 언어, GPU 컴퓨팅, 분산 처리 기법등을 적용할 경우 방법론 선택에 대한 제약은 크지 않다고 할 수 있다.\n",
    "\n",
    "> 실제로 동일한 알고리즘을 R과 Pthon을 통해 모두 구현해 보았는데 절대적으로 Python을 이용한 구현이 실행속도 면에서 압도적이었다. 4500만건 트레이닝 상황에서 R을 이용한 구현에서는 대략 2주정도 실행 시간이 예상되었으나 Python을 이용한 구현에서는 불과 2시간만에 결과를 얻을 수 있었다. 물론 구현 방식과 사용하는 패키지에 따라서 차이가 있겠으나 빠른 실행 시간이 필요한 상황에서는 어떤 프로그래밍 언어를 선택하느냐가 중요한 요소일 수 있다.\n",
    "\n",
    "> 모수 벡터 설정 및 변수 코딩과 관련하여 다범주 다변수 데이터를 실시간 분석해야할 경우 해싱을 이용한 접근 방법을 사용하는 것이 효과적임을 확인할 수 있었다. 우선 단순히 차원 축소 뿐만 아니라 각 셈플 벡터의 크기가 줄어 메모리 사용량이 줄어들고 모수 벡터에 대한 빠른 접근이 가능하여 실행 성능 향상 효과를 얻을 수 있었고 대략적인 변수 규모만 지정하면 범주가 추가될 경우에도 다시 가변수 코딩이나 적합을 수행할 필요가 없는 장점을 확인 할 수 있었다.\n",
    "\n",
    ">  확률적 경사 하강법의 경우 step size $\\alpha$를 어떻게 조절 하느냐가 예측 결과에 아주 큰 영향을 주었다. $\\alpha$를 반복횟수에 반비례하여 조절할 경우 우수한 예측 결과를 얻을 수 있었으나 $\\alpha$의 초기값에 따라 모형의 성능이 크게 좌우 되었다. 반면 추정된 밀도 필터링의 경우 각 모수 분포의 분산($\\sigma$) 초기값에 따라 모형의 성능이 변할 수 있음을 확인 할 수 있었다. 또한 $\\sigma$값에 따라 확률적 경사하강법에 비해 초기에 낮은 log-loss값을 보여주기도 했으나, 적합 반복이 증가할 경우 두 모형 사이에 절대적인 우위를 확인할 수는 없았다. 결국 확률적 경사 하강법에서는 step size $\\alpha$, 추정된 밀도 필터링에서는 각 모수 분포의 분산($\\sigma$) 초기값을 적절히 설정하느냐가 모형의 성능을 결정하는 중요한 요소임을 알 수 있었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [부록 - 구현]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation SGD for titanic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from csv import DictReader\n",
    "from math import exp, log, sqrt\n",
    "import numpy as np\n",
    "import mmh3\n",
    "import time\n",
    "from spooky import hash128, hash64, hash32\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = 2 ** 20\n",
    "rand_seed = 1004\n",
    "\n",
    "num_poly = 10\n",
    "xxi, wwi = np.polynomial.hermite.hermgauss(num_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSize:\n",
    "    def __init__(self\n",
    "                 , num_metric_check_point\n",
    "                 , num_status_check_point\n",
    "                 , num_train_data_start\n",
    "                 , num_train_data_size\n",
    "                 , num_test_data_start\n",
    "                 , num_test_data_size):\n",
    "        \n",
    "        self.num_metric_check_point = num_metric_check_point\n",
    "        self.num_status_check_point = num_status_check_point\n",
    "        \n",
    "        self.num_train_data_start = num_train_data_start\n",
    "        self.num_train_data_end = self.num_train_data_start + num_train_data_size - 1 # fixed\n",
    "        \n",
    "        self.num_test_data_start = num_test_data_start\n",
    "        self.num_test_data_end = self.num_test_data_start + num_test_data_size - 1 # fixed\n",
    "        \n",
    "    def display(self):\n",
    "        print(\"num_metric_check_point: %s\" %(self.num_metric_check_point))\n",
    "        print(\"num_status_check_point: %s\" %(self.num_status_check_point))\n",
    "        print(\"num_train_data_start  : %s\" %(self.num_train_data_start))\n",
    "        print(\"num_train_data_end    : %s\" %(self.num_train_data_end))\n",
    "        print(\"num_train_data_size   : %s\" %(self.num_train_data_end - self.num_train_data_start + 1))\n",
    "        print(\"num_test_data_start   : %s\" %(self.num_test_data_start))\n",
    "        print(\"num_test_data_end     : %s\" %(self.num_test_data_end))\n",
    "        print(\"num_test_data_size    : %s\" %(self.num_test_data_end - self.num_test_data_start + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FileInfo:\n",
    "    def __init__(self\n",
    "                , _file_path\n",
    "                , _f_having_header\n",
    "                , _l_header_names\n",
    "                , _seperator\n",
    "                , _l_skip_columns\n",
    "                , _ylab):\n",
    "        self.file_path = _file_path\n",
    "        self.f_having_header = _f_having_header\n",
    "        self.l_header_names = _l_header_names\n",
    "        self.seperator = _seperator\n",
    "        self.l_skip_columns = _l_skip_columns\n",
    "        self.ylab = _ylab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fi_titanic = FileInfo(\n",
    "                r'C:/My/Playground/Git/2016_Thesis/100_Simulation/data/train.csv' # _file_path\n",
    "                , True # _f_having_header\n",
    "                , ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex'\n",
    "                   , 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin' , 'Embarked'] # _l_header_names\n",
    "                , ',' # _seperator\n",
    "                , ['PassengerId']# _l_skip_columns\n",
    "                , 'Survived'# _ylab\n",
    "                )\n",
    "\n",
    "fi_criteo = FileInfo(\n",
    "                r'C:\\Temp\\dac.tar\\train.txt' # _file_path\n",
    "                , False # _f_having_header\n",
    "                , ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))] # _l_header_names\n",
    "                , '\\t' # _seperator\n",
    "                , []# _l_skip_columns\n",
    "                , 'Label'# _ylab\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_mmh3(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = mmh3.hash128(str(key) + str(value), seed=rand_seed, x64arch=True) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# csv_row must be dict\n",
    "def get_x_spooky(csv_row, D):\n",
    "    x = [0]\n",
    "    for key, value in csv_row.items():\n",
    "        index = hash32(str(key) + str(value)) % D\n",
    "        x.append(index)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_p(x, w):\n",
    "    wTx = 0.\n",
    "    for i in x:  # do wTx\n",
    "        wTx += w[i] * 1.  # w[i] * x[i], but if i in x we got x[i] = 1.\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# w must be numpy ndarray\n",
    "def get_p_cat(x, w):\n",
    "    wTx = sum(w[x])\n",
    "    return 1. / (1. + exp(-max(min(wTx, 20.), -20.)))  # bounded sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logloss(p, y):\n",
    "    p = max(min(p, 1. - 10e-12), 10e-12)\n",
    "    return -log(p) if y == 1. else -log(1. - p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_validation_metrics(c_fi,start, end, wlen, w, f_debug):\n",
    "    \n",
    "    log_loss = 0.\n",
    "    arr_y = []\n",
    "    arr_p = []\n",
    "        \n",
    "    f = open(c_fi.file_path)\n",
    "    for t, row in enumerate(DictReader(f, fieldnames=c_fi.l_header_names, delimiter=c_fi.seperator)):\n",
    "        if t == 0:\n",
    "            continue # just for titanic\n",
    "        \n",
    "        if t < start: # fixed\n",
    "            continue;\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        arr_y.append(y)\n",
    "        \n",
    "        if(len(c_fi.l_skip_columns) > 0):\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        x = get_x_mmh3(row, wlen)\n",
    "        \n",
    "        p = 0\n",
    "        if(isinstance(w, list)):\n",
    "            p = get_p(x, w)\n",
    "        else:\n",
    "            p = get_p_cat(x, w)\n",
    "        arr_p.append(p)\n",
    "        \n",
    "        log_loss += logloss(p, y)   \n",
    "        \n",
    "        if f_debug:\n",
    "            if t >= 1:  # fixed\n",
    "                print(' [get_validation_metrics] %s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss/t))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= end: # fixed\n",
    "            break;\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return(log_loss, arr_y, arr_p)\n",
    "\n",
    "#fn = ['Label'] + [ 'I' + str(i) for i in list(range(1,14))] + [ 'C' + str(i) for i in list(range(1,27))]\n",
    "#get_validation_metrics(train, fn, '\\t', 'Label', num_test_data_start, num_test_data_end, D, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_log_loss(arr_log_loss):\n",
    "    plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "    x = range(len(arr_log_loss))\n",
    "    plt.plot(x, arr_log_loss, label='log_loss', marker='o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w_withn(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha / (sqrt(n[i]) + 1.)\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_w(w, n, x, p, y, alpha):\n",
    "    for i in x:\n",
    "        w[i] -= (p - y) * alpha\n",
    "        n[i] += 1.\n",
    "    return w, n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_training(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    w = [0.] * D  # weights\n",
    "    n = np.array([0.] * (D))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    log_loss_sgd_training = 0.\n",
    "    arr_log_loss_sgd_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):  # for titanic(comma seperated)\n",
    "        \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "        \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "        \n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "\n",
    "        x = get_x_mmh3(row, D)\n",
    "        p = get_p(x, w)\n",
    "        w, n = update_w_withn(w, n, x, p, y, alpha)\n",
    "\n",
    "        p = get_p(x, w)\n",
    "        log_loss_sgd_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if t % c_ds.num_status_check_point == 0 and t >= 1:  # for titanic\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_sgd_training/t))\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "\n",
    "                arr_log_loss_sgd_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "                \n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "\n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    # Return different variables as mode selected.\n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_sgd_test)\n",
    "    elif f_validation:\n",
    "        rt_log_loss_sgd_training = log_loss_sgd_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_sgd_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , w\n",
    "                        , f_debug)\n",
    "        \n",
    "        rt_log_loss_sgd_test = rt_log_loss_sgd_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((w, arr_y, arr_p, rt_log_loss_sgd_training, rt_log_loss_sgd_test))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# s_t_m_old and s_t_v_old must be numpy ndarray\n",
    "def get_s_t_new(y, s_t_m_old, s_t_v_old):\n",
    "\n",
    "    wi = wwi / np.sqrt(np.pi)\n",
    "    xi = xxi * np.sqrt(2) * np.sqrt(s_t_v_old) + s_t_m_old\n",
    "    \n",
    "    fw = 0.\n",
    "    if(y==1):\n",
    "        fw = (1. / (1. + np.exp(-xi))) * wi\n",
    "    else:\n",
    "        fw = ((np.exp(-xi)) / (1. + np.exp(-xi))) * wi\n",
    "\n",
    "    z_t = sum(fw)\n",
    "    s_t_m_new = 1. / z_t * sum(xi * fw)\n",
    "    s_t_v_new = 1. / z_t * sum((xi**2) * fw) - s_t_m_new**2\n",
    "        \n",
    "    return (s_t_m_new, s_t_v_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# theta_t_v must be numpy ndarray\n",
    "def get_a_i_cat(x, theta_t_v):\n",
    "    return theta_t_v[x] / sum(theta_t_v[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, n_iter, n):\n",
    "    a_i = get_a_i_cat(x, theta_t_v)\n",
    "    theta_t_m[x] += (a_i * delta_m)\n",
    "    theta_t_v[x] += ((a_i**2) * delta_v)\n",
    "    n[x] += 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trainning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adf_training(variance, D, f_debug, f_step_validation, f_validation, c_ds, c_fi):\n",
    "    theta_t_m = np.array([0.] * (D)) # mean of thetas at t\n",
    "    theta_t_v = np.array([variance] * (D)) # variance of thetas at t\n",
    "    n = np.array([0.] * D)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    log_loss_adf_training = 0.\n",
    "    arr_log_loss_adf_test = []\n",
    "    \n",
    "    f = open(c_fi.file_path)\n",
    "    fn = c_fi.l_header_names\n",
    "    \n",
    "    for t, row in enumerate(DictReader(f, fieldnames=fn, delimiter=c_fi.seperator)):\n",
    "    \n",
    "        if len(c_fi.l_skip_columns) > 0 :\n",
    "            for i in range(len(c_fi.l_skip_columns)):\n",
    "                del row[(c_fi.l_skip_columns)[i]] # for titanic\n",
    "        \n",
    "        if t == 0 & c_fi.f_having_header:\n",
    "            continue\n",
    "            \n",
    "        if t < c_ds.num_train_data_start:\n",
    "            continue\n",
    "        # Start of ...\n",
    "\n",
    "\n",
    "        y = 1. if row[c_fi.ylab] == '1' else 0.\n",
    "        del row[c_fi.ylab]\n",
    "        \n",
    "        x = get_x_mmh3(row, D)\n",
    "\n",
    "        # Predictive distribution for s_t ~ N(s_t_m_old, s_t_v_old)\n",
    "        s_t_m_old = sum(theta_t_m[x])\n",
    "        s_t_v_old = sum(theta_t_v[x])\n",
    "\n",
    "        # Posterior distribution for s_t\n",
    "        s_t_m, s_t_v = get_s_t_new(y, s_t_m_old, s_t_v_old)\n",
    "\n",
    "        # Changes in s_t\n",
    "        delta_m = s_t_m - s_t_m_old\n",
    "        delta_v = s_t_v - s_t_v_old\n",
    "\n",
    "        # Updating theta\n",
    "        update_theta_cat(x, theta_t_m, theta_t_v, delta_m, delta_v, t, n)\n",
    "\n",
    "        p = get_p_cat(x, theta_t_m)\n",
    "\n",
    "        log_loss_adf_training += logloss(p, y)\n",
    "        \n",
    "        if f_debug:\n",
    "            if y == 1.:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "            if t % c_ds.num_status_check_point == 0 and t > 1:\n",
    "                print('%s\\tencountered: %d\\t y=%d: %f, loss:%f' % (\n",
    "                    datetime.now(), (t), y, p, log_loss_adf_training/t))\n",
    "\n",
    "        if f_step_validation:\n",
    "            if t % c_ds.num_metric_check_point == 0 and t > 1:\n",
    "                rt_log_loss, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "                \n",
    "                arr_log_loss_adf_test.append(rt_log_loss / (c_ds.num_test_data_end - c_ds.num_test_data_start))\n",
    "\n",
    "        # End of ...\n",
    "        if t >= c_ds.num_train_data_end:\n",
    "            break\n",
    "    f.close()\n",
    "    \n",
    "    if f_debug:\n",
    "        print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    if f_step_validation:\n",
    "        return(arr_log_loss_adf_test)\n",
    "    \n",
    "    if f_validation:\n",
    "        rt_log_loss_adf_training = log_loss_adf_training / (c_ds.num_train_data_end - c_ds.num_train_data_start)\n",
    "        \n",
    "        rt_log_loss_adf_test, arr_y, arr_p = get_validation_metrics(\n",
    "                        c_fi\n",
    "                        , c_ds.num_test_data_start\n",
    "                        , c_ds.num_test_data_end\n",
    "                        , D\n",
    "                        , theta_t_m\n",
    "                        , f_debug)\n",
    "        rt_log_loss_adf_test = rt_log_loss_adf_test / (c_ds.num_test_data_end - c_ds.num_test_data_start)\n",
    "        \n",
    "        return((theta_t_m, arr_y, arr_p, rt_log_loss_adf_training, rt_log_loss_adf_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Choose Data-set to simulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEST_DATA = 'C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's find best parameters.(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_best_param_titanic = DataSize(10      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 700        #train_start, train_size\n",
    "                         , 701, 191)    #test_start, test_size\n",
    "\n",
    "ds_best_param_criteo = DataSize(10      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 3000        #train_start, train_size\n",
    "                         , 3001, 1000)    #test_start, test_size\n",
    "\n",
    "ds_best_param_criteo = DataSize(10      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 10000        #train_start, train_size\n",
    "                         , 10001, 10000)    #test_start, test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD : alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-05-31 21:10:10.209000, i:0, param:1e-05, log-loss(tr:0.6918403589, te:0.691255258181)\n",
      "2016-05-31 21:10:12.728000, i:1, param:0.0100098, log-loss(tr:0.490446897113, te:0.509753970584)\n",
      "2016-05-31 21:10:15.119000, i:2, param:0.0200096, log-loss(tr:0.462550298588, te:0.49581485713)\n",
      "2016-05-31 21:10:17.801000, i:3, param:0.0300094, log-loss(tr:0.441380485122, te:0.487640995587)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f0edafac4cee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m                  \u001b[1;33m,\u001b[0m \u001b[0mf_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                  \u001b[1;33m,\u001b[0m \u001b[0mc_ds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_best_param_criteo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                  , c_fi = fi_criteo)\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_alpha[i]\n",
      "\u001b[1;32m<ipython-input-15-272d3b7c1351>\u001b[0m in \u001b[0;36msgd_training\u001b[1;34m(alpha, D, f_debug, f_step_validation, f_validation, c_ds, c_fi)\u001b[0m\n\u001b[0;32m     69\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                         \u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m                         , f_debug)\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mrt_log_loss_sgd_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrt_log_loss_sgd_test\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_test_data_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc_ds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_test_data_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-0cbf4a4f7c5e>\u001b[0m in \u001b[0;36mget_validation_metrics\u001b[1;34m(c_fi, start, end, wlen, w, f_debug)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mdel\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_fi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml_skip_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# for titanic\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_x_mmh3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-293193c5f3f6>\u001b[0m in \u001b[0;36mget_x_mmh3\u001b[1;34m(csv_row, D)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmmh3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhash128\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrand_seed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx64arch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    arr_alpha = list(np.linspace(.00001, 2., 50, endpoint=False))\n",
    "    \n",
    "    arr_log_loss_sgd_train_best_alpha = [0]*len(arr_alpha)\n",
    "    arr_log_loss_sgd_test_best_alpha = [0]*len(arr_alpha)\n",
    "    \n",
    "    for i in range(0,len(arr_alpha)):\n",
    "        param, arr_y, arr_p, arr_log_loss_sgd_train_best_alpha[i], arr_log_loss_sgd_test_best_alpha[i] = sgd_training(alpha =\n",
    "                 arr_alpha[i]\n",
    "                 , D = 2**20\n",
    "                 , f_debug = False\n",
    "                 , f_step_validation = False\n",
    "                 , f_validation = True\n",
    "                 , c_ds = ds_best_param_titanic\n",
    "                 , c_fi = fi_titanic)\n",
    "\n",
    "        print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_alpha[i]\n",
    "                                                         , arr_log_loss_sgd_train_best_alpha[i]\n",
    "                                                         , arr_log_loss_sgd_test_best_alpha[i]))\n",
    "elif(TEST_DATA == 'C'):\n",
    "    arr_alpha = list(np.linspace(.00001, .5, 50, endpoint=False))\n",
    "    \n",
    "    arr_log_loss_sgd_train_best_alpha = [0]*len(arr_alpha)\n",
    "    arr_log_loss_sgd_test_best_alpha = [0]*len(arr_alpha)\n",
    "\n",
    "    for i in range(0,len(arr_alpha)):\n",
    "        param, arr_y, arr_p, arr_log_loss_sgd_train_best_alpha[i], arr_log_loss_sgd_test_best_alpha[i] = sgd_training(alpha =\n",
    "                 arr_alpha[i]\n",
    "                 , D = 2**20\n",
    "                 , f_debug = False\n",
    "                 , f_step_validation = False\n",
    "                 , f_validation = True\n",
    "                 , c_ds = ds_best_param_criteo\n",
    "                 , c_fi = fi_criteo)\n",
    "\n",
    "        print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_alpha[i]\n",
    "                                                         , arr_log_loss_sgd_train_best_alpha[i]\n",
    "                                                         , arr_log_loss_sgd_test_best_alpha[i]))\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(arr_alpha, arr_log_loss_sgd_train_best_alpha, marker='o', color='r', label='training data')\n",
    "plt.plot(arr_alpha, arr_log_loss_sgd_test_best_alpha, marker='o', color='b', label='test data')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('log-loss per iteration')\n",
    "plt.title('Best alpha')\n",
    "\n",
    "ndarr_test = np.array(arr_log_loss_sgd_test_best_alpha)\n",
    "print((ndarr_test.argmin(), arr_alpha[ndarr_test.argmin()], arr_log_loss_sgd_test_best_alpha[ndarr_test.argmin()]))\n",
    "\n",
    "plt.axvline(arr_alpha[ndarr_test.argmin()], color = 'g')\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/best_param_sgd_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/best_param_sgd_C.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF : variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    arr_var = list(np.linspace(.0001, 2., 50, endpoint=False))\n",
    "    arr_log_loss_adf_train_best_var = [0]*len(arr_var)\n",
    "    arr_log_loss_adf_test_best_var = [0]*len(arr_var)\n",
    "\n",
    "    for i in range(0,len(arr_var)):\n",
    "        param, arr_y, arr_p, arr_log_loss_adf_train_best_var[i], arr_log_loss_adf_test_best_var[i] = adf_training(variance = arr_var[i]\n",
    "                 , D = 2**20\n",
    "                 , f_debug = False\n",
    "                 , f_step_validation = False\n",
    "                 , f_validation = True\n",
    "                 , c_ds = ds_best_param_titanic\n",
    "                 , c_fi = fi_titanic)\n",
    "\n",
    "        print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_var[i]\n",
    "                                                         , arr_log_loss_adf_train_best_var[i]\n",
    "                                                         , arr_log_loss_adf_test_best_var[i]))\n",
    "\n",
    "elif(TEST_DATA == 'C'):\n",
    "    arr_var = list(np.linspace(.0001, .2, 50, endpoint=False))\n",
    "    arr_log_loss_adf_train_best_var = [0]*len(arr_var)\n",
    "    arr_log_loss_adf_test_best_var = [0]*len(arr_var)\n",
    "    \n",
    "    for i in range(0,len(arr_var)):\n",
    "        param, arr_y, arr_p, arr_log_loss_adf_train_best_var[i], arr_log_loss_adf_test_best_var[i] = adf_training(variance = arr_var[i]\n",
    "                 , D = 2**20\n",
    "                 , f_debug = False\n",
    "                 , f_step_validation = False\n",
    "                 , f_validation = True\n",
    "                 , c_ds = ds_best_param_criteo\n",
    "                 , c_fi = fi_criteo)\n",
    "        print('%s, i:%s, param:%s, log-loss(tr:%s, te:%s)' %(datetime.now(), i, arr_var[i]\n",
    "                                                         , arr_log_loss_adf_train_best_var[i]\n",
    "                                                         , arr_log_loss_adf_test_best_var[i]))\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(arr_var, arr_log_loss_adf_train_best_var, marker='o', color= 'r', label='training data')\n",
    "plt.plot(arr_var, arr_log_loss_adf_test_best_var, marker='o', color= 'b', label='test data')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('variance')\n",
    "plt.ylabel('log-loss per iteration')\n",
    "plt.title('Best variance')\n",
    "\n",
    "ndarr_test = np.array(arr_log_loss_adf_test_best_var)\n",
    "print((ndarr_test.argmin(), arr_var[ndarr_test.argmin()], arr_log_loss_adf_test_best_var[ndarr_test.argmin()]))\n",
    "\n",
    "plt.axvline(arr_var[ndarr_test.argmin()], color = 'g')\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/best_param_adf_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/best_param_adf_C.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Tracing log-loss as the number of sample grows(step_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ds_step_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_step_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 1000        #train_start, train_size\n",
    "                         , 1001, 100)    #test_start, test_size\n",
    "\n",
    "ds_step_vali_criteo = DataSize(np.round(10000/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 10000        #train_start, train_size\n",
    "                         , 10001, 1000)    #test_start, test_size\n",
    "\n",
    "\n",
    "ds_step_vali_titanic.display()\n",
    "ds_step_vali_criteo.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    arr_log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = True\n",
    "                                             , f_validation = False\n",
    "                                             , c_ds = ds_step_vali_titanic\n",
    "                                             #, c_ds = ds_step_vali_criteo\n",
    "                                             , c_fi = fi_titanic)\n",
    "                                             #, c_fi = fi_criteo)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    alpha = 0.11000779999999999\n",
    "    arr_log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = True\n",
    "                                             , f_validation = False\n",
    "                                             #, c_ds = ds_step_vali_titanic\n",
    "                                             , c_ds = ds_step_vali_criteo\n",
    "                                             #, c_fi = fi_titanic)\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_log_loss(arr_log_loss_sgd_test)\n",
    "\n",
    "ndarr_log_loss_sgd_test = np.array(arr_log_loss_sgd_test)\n",
    "(ndarr_log_loss_sgd_test.argmin(), arr_log_loss_sgd_test[ndarr_log_loss_sgd_test.argmin()])\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_sgd_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_sgd_C.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    arr_log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = True\n",
    "                                             , f_validation = False\n",
    "                                             , c_ds = ds_step_vali_titanic\n",
    "                                             #, c_ds = ds_step_vali_criteo\n",
    "                                             , c_fi = fi_titanic)\n",
    "                                             #, c_fi = fi_criteo)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    arr_log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = True\n",
    "                                             , f_validation = False\n",
    "                                             #, c_ds = ds_step_vali_titanic\n",
    "                                             , c_ds = ds_step_vali_criteo\n",
    "                                             #, c_fi = fi_titanic)\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_log_loss(arr_log_loss_adf_test)\n",
    "\n",
    "ndarr_log_loss_adf_test = np.array(arr_log_loss_adf_test)\n",
    "(ndarr_log_loss_adf_test.argmin(), arr_log_loss_adf_test[ndarr_log_loss_adf_test.argmin()])\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_adf_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_adf_C.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(num=None, figsize=(13, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "x1 = range(len(arr_log_loss_adf_test))\n",
    "plt.plot(x1, arr_log_loss_adf_test, marker='o', color = 'r', label='ADF')\n",
    "x2 = range(len(arr_log_loss_sgd_test))\n",
    "plt.plot(x2, arr_log_loss_sgd_test, marker='o', color = 'b', label='SGD')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('Check points')\n",
    "plt.ylabel('log-loss per iteration')\n",
    "plt.title('Comparison')\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_comparison_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_comparison_C.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds_more_vali_titanic = DataSize(np.round(800/50)      # num_metric_check_point\n",
    "                         , 1      # num_status_check_point\n",
    "                         , 1, 800        #train_start, train_size\n",
    "                         , 801, 91)    #test_start, test_size\n",
    "\n",
    "ds_more_vali_criteo = DataSize(np.round(1000/50)      # num_metric_check_point\n",
    "                         , 100      # num_status_check_point\n",
    "                         , 1, 100000        #train_start, train_size\n",
    "                         , 100001, 100000)    #test_start, test_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 19.9530000687 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    alpha = 0.92000539999999997 # best for titanic\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    alpha = 0.100008 # best for criteo\n",
    "    param_w, arr_sgd_y, arr_sgd_p, log_loss_sgd_train, log_loss_sgd_test = sgd_training(alpha = alpha\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "    \n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Total execution time: 29.8380000591 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    init_v = 0.52007399999999993 # best for titanic\n",
    "    #init_v = 0.0052007399999999993 # best for titanic\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_titanic\n",
    "                                             , c_fi = fi_titanic)\n",
    "elif(TEST_DATA == 'C'):\n",
    "    init_v = 0.024088000000000002 # best for criteo\n",
    "    param_theta, arr_adf_y, arr_adf_p, log_loss_adf_train, log_loss_adf_test = adf_training(variance = init_v\n",
    "                                             , D = 2**20\n",
    "                                             , f_debug = False\n",
    "                                             , f_step_validation = False\n",
    "                                             , f_validation = True\n",
    "                                             , c_ds = ds_more_vali_criteo\n",
    "                                             , c_fi = fi_criteo)\n",
    "\n",
    "\n",
    "print(\"---Total execution time: %s seconds ---\" % (time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_arr_sgd_p = np.array(arr_sgd_p[0:10]) >= .5\n",
    "np_arr_sgd_y = np.array(arr_sgd_y[0:10]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False,  True,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr_sgd_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_arr_sgd_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, False, False, False, False,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np_arr_sgd_y == True) & (np_arr_sgd_p == True)#True Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = (np_arr_sgd_y == True) & (np_arr_sgd_p == True)#True Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np_arr_sgd_y == False) & (np_arr_sgd_p == True)#False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False,  True, False, False, False], dtype=bool)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np_arr_sgd_y == True) & (np_arr_sgd_p == False)#False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True, False,  True,  True,  True, False, False,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np_arr_sgd_y == False) & (np_arr_sgd_p == False)#True Negative"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "               1    0\n",
    "             -----------\n",
    "Prediction 1 | TP | FP |\n",
    "             -----------\n",
    "Prediction 0 | FN | TN |\n",
    "             -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_binary_metric(y, p):\n",
    "    np_y = np.array(y) == 1\n",
    "    np_p = np.array(p) >= 0.5\n",
    "    \n",
    "    total = len(y)\n",
    "    \n",
    "    tp = (np_y == True) & (np_p == True)#True Positive\n",
    "    fp = (np_y == False) & (np_p == True)#False Positive\n",
    "    fn = (np_y == True) & (np_p == False)#False Negative\n",
    "    tn = (np_y == False) & (np_p == False)#True Negative\n",
    "    \n",
    "    tpn = sum(tp)\n",
    "    fpn = sum(fp)\n",
    "    fnn = sum(fn)\n",
    "    tnn = sum(tn)\n",
    "    \n",
    "    accuracy = 1.0 * (tpn + tnn) / total # ratio of correct prediction in the total observation.\n",
    "    precision = 1.0 * tpn / (tpn + fpn) # ratio of correct positive observation in the positive prediction.\n",
    "    recall = 1.0 * tpn / (tpn + fnn) # sensitivity, true positive rate,\n",
    "    f1_score = 2.0 * (recall * precision) / (recall + precision)\n",
    "    \n",
    "    return {'tot':total\n",
    "            , 'tp':tpn\n",
    "            , 'fp':fpn\n",
    "            , 'fn':fnn\n",
    "            , 'tn':tnn\n",
    "            , 'accuracy':accuracy\n",
    "            , 'precision':precision\n",
    "            , 'recall':recall\n",
    "           , 'f1_score':f1_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7761,\n",
       "  'f1_score': 0.41196554259901247,\n",
       "  'fn': 18180,\n",
       "  'fp': 4210,\n",
       "  'precision': 0.650709366962582,\n",
       "  'recall': 0.30138723436959614,\n",
       "  'tn': 69767,\n",
       "  'tot': 100000,\n",
       "  'tp': 7843},\n",
       " 0.4760498823777171)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_binary_metric(arr_sgd_y, arr_sgd_p), log_loss_sgd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.77579,\n",
       "  'f1_score': 0.41258613010558304,\n",
       "  'fn': 18149,\n",
       "  'fp': 4272,\n",
       "  'precision': 0.6482792688951095,\n",
       "  'recall': 0.302578488260385,\n",
       "  'tn': 69705,\n",
       "  'tot': 100000,\n",
       "  'tp': 7874},\n",
       " 0.4759999401341652)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_binary_metric(arr_adf_y, arr_adf_p), log_loss_adf_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxhhjMvT/nfjjgaSoi7kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x80a4080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#fpr_sgd = dict()\n",
    "#tpr_sgd = dict()\n",
    "#roc_auc_sgd = dict()\n",
    "\n",
    "fpr_sgd, tpr_sgd, _ = roc_curve(arr_sgd_y, arr_sgd_p)\n",
    "roc_auc_sgd = auc(fpr_sgd, tpr_sgd) #auc\n",
    "\n",
    "fpr_adf, tpr_adf, _ = roc_curve(arr_adf_y, arr_adf_p)\n",
    "roc_auc_adf = auc(fpr_adf, tpr_adf) #auc\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr_sgd, tpr_sgd, label='SGD', color='b')\n",
    "plt.plot(fpr_adf, tpr_adf, label='ADF', color='r')\n",
    "\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "#plt.show() # or use command %matplotlib inline\n",
    "\n",
    "if(TEST_DATA == 'T'):\n",
    "    plt.savefig('./images/step_vali_roc_T.png')\n",
    "elif(TEST_DATA == 'C'):\n",
    "    plt.savefig('./images/step_vali_roc_C.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.73820793449699706, 0.73644858801108803)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(roc_auc_sgd, roc_auc_adf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
