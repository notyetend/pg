{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera의 Neural Networks for Machine Learning 강의를 정리한 내용임.   \n",
    "2016.10.17. by Dongwan Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week2. The Perceptron Learning Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2주차에서는 **'neural network'의 종류(4가지)**와   \n",
    "1세대 Neural network라 할 수 있는 **Perceptron**에 대해서 알아볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작전에 몇가지 용어에 대해 알아보면"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Unit**: 앞서 배웠던 '뉴런'으로서 하나의 function / kernel 이라 할 수 있음.    \n",
    "이 함수를 **activation function**이라 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_unit.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - **Layer**: 동일 단계의 unit들을 지칭함,      \n",
    "입력값을 받는 layer를 **input layer**,      \n",
    "출력값을 내놓는 layer를 **output layer**,      \n",
    "input layer와 output layer 사이에 하나 이상의 layer들을 **hidden layer**라 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_neural_net.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2a. An overview of the main types of neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> unit(neuron)들이 연결되는 방식에 따라    \n",
    "neural network를 크게 아래 4가지로 나눠 볼 수 있음\n",
    "\n",
    "> - Feed-forward neural networks\n",
    "> - Recurrent networks\n",
    "> - Symmetrically connected networks\n",
    "> - Symmetrically connected networks with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Feed-forward neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 'input layer'로 입력을 받아    \n",
    "'hidden layer'를 따라    \n",
    "'output layer'까지    \n",
    "<u>한 방향</u>으로 transformation이 진행되는 형태\n",
    "\n",
    "\n",
    "> - hidden layer가 하나 이상일 경우, 'deep neural networks'라 부름  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_feed_forward.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - unit간 순환 연결을 갖는 형태\n",
    "> - network내에 상태가 기억되는 특성을 갖음   \n",
    "> - train하기 쉽지 않음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_recurrent_network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Symmetrically connected networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - recurrent network의 특별한 케이스로서,    \n",
    "unit간에 동일한 weight의 상호 연결을 갖는 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_symmetric.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hidden unit이 없는 symmetrically connected networks를 **Hopfield network**라 함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Hopfield-net.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (4) Symmetrically connected networks with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Hidden unit을 포함하는    \n",
    "symmetrically connected networks를 **Boltzmann machine**라 함   \n",
    "(파랑색 unit이 hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Boltzmannexamplev2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Boltzmann machine에서 hidden unit간 연결을 제거한    \n",
    "**Restricted Boltzmann machine(RBM)**도 있음   \n",
    "(나중에 배우게 됨)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Restricted_Boltzmann_machine.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2b. Perceptrons: The first generation of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 이제 **Perceptrons의 역사**에 대해서 예기해 보면...        \n",
    "1957년 프랑크 로젠블라트(Frank Rosenblatt)가 제안한 feedforward network로서Input layer와 output layer만을 갖는 형태\n",
    "\n",
    "\n",
    "> - 'Principle of Neurodynamitcs'(Rosenblatt, Frank (1962)) 이 책에서 다양한 종류의 Perceptron과 강점을 소개함\n",
    "\n",
    "\n",
    "> - 1969년 Minsky와 Papert이 'Perceptrons'라는 책에서 Perceptrons의 한계를 밝힘, 그런데 사람들은 이런 한계가 모든 Neural network에도 적용되는 것이라고 생각하게 되고, Neural network의 암흑기가 오게 됨. ㅜ_ㅜ\n",
    "\n",
    "\n",
    "> - 1970년대 Geoffrey Hinton이 Neural network를 연구하기 시작했을때, AI 분야의 사람들이 '그건 틀렸다는게 밝혀 졌자나' 라고 했다고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_perceptron.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 <u>'여기 모인 사람들이 오늘 야식을 먹을까 말까'</u> 예측한다고 해 보자.   \n",
    "주어진 데이터는    \n",
    "'오늘 점심 메뉴'(한식, 중식, 일식 중 하나),   \n",
    "'스트레스 지수(-5~5)',     \n",
    "'배고픔 지수(-5~5)' 라고 해 보자. (raw input data / matrix)\n",
    "\n",
    "> 이때 feature vector는 점심 메뉴($x_1, x_2$), 스트레스 지수($x_3$), 배포픔 지수($x_4$)가 되고,   \n",
    "여러 데이터 point에 아래 조건을 잘 만족시키는 $w_i$들을 찾게 됨\n",
    "\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위에서 threshold $\\theta$ 가 등장하는데, 이 값을 모델에 넣어서 같이 추론할 수 있음    \n",
    "(Week1에서 Binary threshold neurons page에 나옴)\n",
    "> threshold는 사실 -1 * bias로 바꿔 생각하면 모형은 아래와 같음.($b = -\\theta)$\n",
    "\n",
    "> $$z = b + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq 0 \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> 또한 bias unit은 입력값이 1인 unit이라 할 수 있음.($bias = b = b \\cdot x_0, ~x_0 = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_bias.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그렇다면 $w_i$들을 어떻게 구할 것인가?   \n",
    "\n",
    "> 앞서와 같은 binary output neuron에서는    \n",
    "input에 따라 model output과 true output을 비교하여 3가지 경우로 나뉠 수 있다.\n",
    "\n",
    "> - true output = model output (correct)\n",
    "> - true output = 1, but model output = 0 (incorrect, false negative)\n",
    "> - true output = 0, but model output = 1 (incorrect, false positive)\n",
    "\n",
    "> 첫번째 경우에는 기존의 $w_i$를 그대로 두고     \n",
    "두번째 경우 $z$값이 실제보다 작게 나온 것 이므로, $w_i$를 $w_i + x_i$로 수정     \n",
    "세번째 경우 $z$값이 실제보다 크게 나온 것 이므로, $w_i$를 $w_i - x_i$로 수정\n",
    "\n",
    "> 이 방법을 사용하면 (물론 해가 존재한다면)    \n",
    "모든 training cases에 들어맞는 $w_i$들을 찾을 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2c. A geometrical view of perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **hyper-plane** 이란?\n",
    "\n",
    "> n차원 유클리드 공간에서의 hyperplane이란, n차원 주변공간(ambient space)을 둘로 나누는 n-1차원인 부분공간(subspace)을 의미한다.\n",
    "\n",
    "> 즉 1차원인 선을 둘로 나누는 것은 점이고\n",
    "2차원인 평면을 둘로 나누는 것은 선이고\n",
    "3차원인 공간을 둘로 나누는 것은 평면이다.  \n",
    "여기서 점, 선, 평면이 각 차원에서의 hyperplane이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weight space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - weight 하나당 차원 하나로 구성되는 space.\n",
    "\n",
    "\n",
    "> - 이 space의 점 하나는 weight 쌍 하나를 의미.\n",
    "\n",
    "\n",
    "> - threshold를 제거하고 생각하면,   \n",
    "하나의 training case(or sample)은 원점을 지나는 hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 아래와 같은 모델을 생각 해보자.\n",
    "> $$z = w_1 x_1 + w_2 x_2$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq 0 \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> weight이 두개($w_1, w_2$)이므로 weight space는 2차원 공간, 즉 평면이다.     \n",
    "> 또한  $z$값은 $vector~(w_1, w_2)$와 $vector~(x_1, x_2)$의 내적이라 할 수 있다.   \n",
    "\n",
    "\n",
    "> 즉 두 vector의 사잇각이 90도 보다 작다면 그 내적값은 양수가 되고, 모델 예측값 $y$는 1이 된다.   \n",
    "반면 사잇각이 90도 보다 크다면 그 내적값은 음수가 되고, 모델 예측값 $y$는 0이 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 아래 그림과 같이 대략 $y=1$, $x_1 = 1, x_2 = 3$의 training data 하나가 있을 때,   \n",
    "$z = w_1 x_1 + w_2 x_2$ 값이 0보다 커야 1으로 예측하게 되므로,   \n",
    "'good weight vector'들은 hyperplane 윗쪽에 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 반면 아래와 같이 대략 $y=0$, $x_1 = 3, x_2 = 3$의 training data 하나가 있을 때,    \n",
    "$z = w_1 x_1 + w_2 x_2$ 값이 0보다 작아야 0으로 예측하게 되므로,   \n",
    "'good weight vector'들은 hyperplane 아래쪽에 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모든 data sample에 들어맞는 weight point를 찾아야 하므로,   \n",
    "(앞서의 경우에서는) 두 가지 경우를 모두 만족시키는 weight vector들이 찾아야 한다.    \n",
    "따라서 아래와 같이 두 hyper-plane의 사잇 공간의 점들이 적절한 weight이라 할 수 있다.    \n",
    "Perceptron과 같은 선형-이항 분류에서는 weight들이 존재하는 공간이 꼭지점(apex)이 원점인 hyper-cone 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2d. Why the learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 Perceptron이 옳은 예측을 하게 되면, 현재의 weight vector에 input vector를 더하고,    \n",
    "그렇지 않을 경우 input vector을 뺀다고 했었다.\n",
    "\n",
    "> 이런 과정이 결국 feasible weights(적절한? 괜찮은? weights)에 도달하게 해주는 이유를 생각 해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 우선 현재의 weight이 괜찮은 녀석인지를 판단하기 위한 기준 혹은 measure가 필요한데,    \n",
    "여기에서는 feasible weight과 현재의 weight 사이의 **squared distance** ($d_{a}^2 + d_{b}^2$)를 기준으로 잡는다.    \n",
    "결국 이 squared distance가 줄어들면 점차 좋은 weight에 근접해 간다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그런데 아래 그림에서처럼 '노란색 weight'과 같이    \n",
    "경계(검은 선)와의 거리가 input vector의 길이보다 작을 경우     \n",
    "current weight에 input vector를 더해도 squared distance가 줄어들지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space4.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그래서 모든 weight들과 current weight을 비교하는 것이 아니라      \n",
    "경계(검은 선)에서 최소한 input vector만큼은 떨어져 있는 weight들과 비교하게 되는데,    \n",
    "이 강의에서는 이들을 **generously feasible weight vector**라 한다.\n",
    "\n",
    "> 이렇게 margin을 갖게 되면 percrptron이 잘못된 예측을 하게 될 때마다, weight을 수정하게 되고     \n",
    "모든 'generously feasible weight vector'들과의 거리가 줄어들게 된다.\n",
    "\n",
    "> 결국 일정 횟수의 mistake이후에는 적절한 weight(space)를 찾게 된다. (물론 이런 space가 존재한다는 가정 하에서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space5.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2e. What perceptrons can't do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이제 Perceptrons의 한계에 대해 알아본다.\n",
    "\n",
    "> 사실 모든 input case에 대해 각각의 unit을 사용하도록, feature를 coding한다면 Perceptrons으로 모든 문제를 풀 수 있다.    \n",
    "하지만 이런 방식은 실용적이지도 않고 일반적인 룰을 적용할수도 없다.  \n",
    "또한 feature가 한번 결정되고 나면, 이 Perceptron이 풀 수 있는 문제가 매우 제한된다. \n",
    "\n",
    "> 두가지 예를 통해 어떤 한계가 있는지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex1 - XOR Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1, 1) -> 1; (0, 0) -> 1; (1, 0) -> 0; (0, 1) -> 0\n",
    "\n",
    "> 위와 같이 두 입력값이 1로 같을 경우 1이 output이고,    \n",
    "두 입력값이 다를 경우 0을 output으로 하는 데이터가 있다.   \n",
    "이 데이터를 Perceptrons으로 풀어보면... 모형은 아래와 같고, \n",
    "\n",
    "> $$z = w_1 x_1 + w_2 x_2$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> 각각의 training case를 위 식에 넣어주면 \n",
    "$$1 \\cdot w_1 + 1 \\cdot w_2 \\geq \\theta$$\n",
    "$$0 \\cdot w_1 + 0 \\cdot w_2 \\geq \\theta$$\n",
    "$$1 \\cdot w_1 + 0 \\cdot w_2  <   \\theta$$\n",
    "$$0 \\cdot w_1 + 1 \\cdot w_2  <   \\theta$$\n",
    "위와 같은 부등식을 얻게 되는데,    \n",
    "이런 조건을 만족시키는 $(w_1, w_2)$는 존재하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이를 기하학적으로 살펴볼텐데, 이번에는 data-space에서 생각해 보기로 한다.   \n",
    "\n",
    "> 앞서는 weight-space, 즉 공간에 weight-point가 존재하고,    \n",
    "input hyper-plane이 이들을 'good weights'와 'bad weights'로 나누는 형태 였고(**weight-space**)    \n",
    "\n",
    "> 이번에는 공간에 data-point가 존재하고, weight plane이    \n",
    "data-point들을 $y=1$인 경우와 $y=0$인 경우로 나누려 하는 형태이다. (**data-space**)\n",
    "\n",
    "> 아래 그림에서 weight plane은 weight vector와 수직이고 원점에서 $\\theta$만큼 떨어진 직선이다.   \n",
    "그런데 4개의 점을 $y=0$인 점들과 $y=1$인 점들로 나누는 직선은 존재하지 않는다.    \n",
    "> 즉 linearly seperable 하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_data_space1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 물론 feature coding을 조금 바꿔서,     \n",
    "(1, 1) -> 1을 (0, 1, 0, 0) -> 1으로   \n",
    "(0, 0) -> 1을 (0, 0, 0, 0) -> 1으로    \n",
    "(1, 0) -> 0을 (0, 0, 1, 0) -> 0으로    \n",
    "(0, 1) -> 0을 (0, 0, 0, 1) -> 0으로 바꾸면,  \n",
    "\n",
    "> 모델은 아래와 같이 바뀌고\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "> 아래와 같은 weight solution을 찾을 수 있다.\n",
    "> $$w_2 \\geq \\theta$$\n",
    "$$0 \\geq \\theta$$\n",
    "$$w_3 < \\theta$$\n",
    "$$w_4 < \\theta$$\n",
    "\n",
    "\n",
    "> <u>Feature learning이 미리 잘 되어 있다면 Perceptrons로도 많은 것을 할 수 있다는 의미. -> 결국 hidden layer를 써야 한다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex2 - Discriminating simple patterns under translation with wrap-around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1969년 Minsky와 Papert이 'Perceptrons'라는 책에서 'Group Invariance Theorem'으로 밝힌 내용임,\n",
    "\n",
    "> 16개 pixel로 구성된 흑/백 pattern이 존재하는데,    \n",
    "아래의 pattern A는 4개의 pixel이 표시되어 있고,     \n",
    "전체 패턴을 회전/순환 할 경우 나타날 수 있는 16가지의 패턴을 모두 pattern A로 간주한다.   \n",
    "또한 pattern A에 대한 output은 $y=1$이라 하자.\n",
    "\n",
    "> pattern B는 pattern A와 마찬가지로 4개 pixel이 표시되어 있으나    \n",
    "pattern A를 회전/순환하여 얻을 수 없으므로 pattern A와는 다른 pattern이다.      \n",
    "pattern B에 대한 output은 $y=0$이라 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_simple_pattern.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 pixel을 feature라 생각하면 모델은 아래와 같다.\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + ~...~ + w_{14} x_{14} + w_{15} x_{15} + w_{16} x_{16}$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "> 우선 pattern A의 모든 경우를 이용하여 모델을 풀어보면,      \n",
    "첫번째 case를 이용하여 $w_3 + w_6 + w_7 + w_{10} \\geq \\theta$을 얻을 수 있고,   \n",
    "나머지 15가지 회전/순환 case를 이용하여 총 16개의 부등식을 얻을 수 있다.   \n",
    "또한 이들 부등식 다 더하면 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) \\geq \\theta$를 얻게 된다.\n",
    "\n",
    "> 다음으로 pattern B의 모든 경우를 이용하여 모델을 풀어보면,     \n",
    "첫번째 case를 이용하여 $w_3 + w_4 + w_8 + w_9 \\geq \\theta$을 얻을 수 있고,   \n",
    "나머지 15가지 회전/순환 case를 이용하여 총 16개의 부등식을 얻을 수 있다.   \n",
    "또한 이들 부등식 다 더하면 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) < \\theta$를 얻게 된다.\n",
    "\n",
    "\n",
    "> 결국 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) \\geq \\theta$와    \n",
    "$4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) < \\theta$ 를     \n",
    "모두 만족시키는 solution은 존재하지 않다는 것을 알 수 있다.\n",
    "\n",
    "> <u>Translation with wrap-around가 허용되는 상황에서는 Perceptrons로 패턴을 구분할 수 없다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위 문제를 Perceptrons로 풀기 위해,     \n",
    "예를들어 각 pattern에서 검은 pixel들의 분산?과 같의 추가 정보를 feature로 입력 해 줘야 한다.(단순히 A, B의 경우에 한함)    \n",
    "이렇게 필요한 feature를 직접 추가하는 것을    \n",
    "강의에서는 'hand-coded feature detectors'라고 표현함.   \n",
    "(문제가 해결되기는 하지만 옳바른 접근 방법은 아니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Solution? - Learning with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 hand-coded feature detectors를 이용하면 문제를 풀수 있다고 했는데,   \n",
    "이런 부분들 까지 모델에 포함하여 문제를 해결하는 것이 좋을 것이다.   \n",
    "\n",
    "> 즉 'adaptive, non-linear hidden unit'추가하여       \n",
    "모델에서 feature detecting을 할 수 있도록 하는 것(to make learn feature detector)이 좋을 것이다.\n",
    "다만 이런 모델을 어떻게 train할 것인지가 문제이고,\n",
    "\n",
    "> 이어지는 강의에서 이런 내용들을 배우게 될 것이다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
