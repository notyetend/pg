{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera의 Neural Networks for Machine Learning 강의를 정리한 내용임.   \n",
    "2017.01.03. by Dongwan Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week13. Stacking RBMs to make Deep Belief Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 13a, The ups and downs of backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A brief history of backpropagation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "multi layer NN을 위한 Backpropagation은 1970년대, 1980년대에 여러 사람에 의해 고안되었다. 우선 1969년 Bryson와 Ho가 control theory라는 이름으로 linear한 backpropagation을 제안 했다. 그리고 1974년 Werbos가 이것이 non-linear한 형태에도 적용된을 밝혀 냈다. 1981년에는 Rumelhart, Wiliams 그리고 Hinton이 (Werbos의 발견을 모른체) 같은 내용을 제안한다. 1985년에는 Parker와 LeCun이 각각 backpropagation을 고안했다.      \n",
    "\n",
    "당시에는 backpropagation을 이용해 multiple layers of non-linear feature detector를 효과적으로 학습시키는 것이 가능하리라 생각되었지만, 1990년대가 되어서는 machine learning 연구자 대부분의 backprogatation을 이용한 연구를 포기하게 된다. \n",
    "\n",
    "물론 심리학 연구나 신용카드 부정탐지와 같은 실용적인 분야에서는 여전히 backpropagation을 사용하고 있었으나, machine learning 분야에서는 SVM(support vector machine)이 우위를 점하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why backpropagation failed</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1990년대 backpropagation이 실패했던 이유는 우선 multiple hidden layer 모델에서 잘 동작하지 않았었고, recurrent net이나 deep auto-encoder에도 효과적이지 않았다. 또한 당시 SVM이 더 잘 동작하고 이론적으로도 명확하고 재현가능하며 전문 지식 또한 적게 필요한 장점이 있었다.\n",
    "\n",
    "하지만 backpropagation이 실패했던 진짜 이유는 다른데에 있다. 우선 당시 이를 계산하기에 너무 느렸고, labeled dataset의 크기가 너무 작았었고, deep network의 크기가 너무 작았으며, weight가 잘 초기화 하지 않았던 문제가 있었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>A spectrum of machine learning tasks</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_stat_vs_ai.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why Support Vector Machines where never a good bet for Artificial Intelligence tasks that need good representations</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_svm.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 13b, Belief Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>What is wrong with back-propagation?</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1990년대 back-propagation의 문제점은 당시에는 충분한 크기의 labeled training data가 없었다는 점이다. 또한 대다수의 데이터가 unlabeled라는 점이다. 또한 hidden layer가 많아질 경우 학습 속도가 매우 느려지게 된다. (이 문제의 원인은 weight들의 초기값을 잘? 설정하지 못했기 때문) 또 다른 문제는 poor local optima에 빠지는 것이었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Overcoming the limitations of back-propagation by using unsurpervised learning</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poor local optima에 빠지는 문제에 대한 해결책으로...   \n",
    "input-output pair에 대해 network를 학습시키는 것이 아니라 input data 만을 이용해 network를 unsupervised learning 시키는 것이다. 즉 RBM과 같이, generative model에서 input data가 나올 확률을 가장 높게 하도록 weight들을 학습시키는 것이다.($\\arg\\max_w p(x)$)\n",
    "\n",
    "이를 위해 몇가지 generative model을 떠올려 볼 수 있는데, 이번 강의에서는 두번째 그리고 세번째에 대해서 논해보겠다.\n",
    "- Boltzmann machine과 같은 energy-based model\n",
    "- idealized neuron을 이용한 causal model\n",
    "- 혹은 위 둘이 섞인 형태?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Artificial Intelligence and Probability</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1970년대와 1980년대 초반 AI 연구자들은 '확률'이란 개념을 별로 좋아하지 않았다. 확률이란건 현상을 탐구하는데 있어 불확실성만을 더하는 요소일 뿐이라고 생각했었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The marriage of graph theory and probability theory</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "하지만 AI 분야에서는 1980년대 들어 의료 진단 혹은 자원 탐사와 같은 불확실성을 다뤄야 하는 실용적인 문제들에 직면하게 되었는데, (AI 분야에서는 '확률'을 싫어 했기 때문에) 확률을 사용하지 않고 불확실성을 다루는 방법들을 만들어내게 된다. \n",
    "\n",
    "이후 Pearl, Heckerman, Lauritzen 등이 Graphical model을 소개 했는데, 이를 이용하면 여러 요인간의 상관관계를 graph로 표현할 수 있고, 각 노드의 확률을 계산할 수 있게 된다.\n",
    "\n",
    "Graphical model 중 directed acyclic graph(방향성을 갖는 비순환 그래프)의 특수한 형태를 Belief Nets이라 부르는데,이때 unobserved node에 대한 확률을 계산할 수 있는 inference algorithm을 사용할 수 있다. 그런데 connection이 많은(densely connected nodes) 경우 서로 영향을 줄 수 있는 node의 수가 기하급수적으로 증가하기 때문에 연결이 많지 않은(sparsely connected) 경우에만 효과적이라는 단점이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Belief Nets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic varible들로 구성된 directed acylic graph(방향성을 갖는 비순환 그래프)를 Belief Net이라 하는데, 아래와 같은 network에서 visible variable만을 관찰할 수 있다고 가정할 때 두가지 해결해야하는 문제를 생각해 볼 수 있다.\n",
    "첫번째는 inference 문제로서 visible variable을 관찰했을 때, unobserved variable의 상태를 추론하는 것이고, 두번째는 learning 문제로서 전체 network에서 training data가 나올 확률이 더 높아지도록 variable간의 interaction(weights)을 잘 조절하는 문제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_belief_net.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Graphical Models versus Neural Networks</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Graphical model: 예를들어 여러 요인과 질병과의 상관 모델을 만들 경우 전문가(의사)가 그래프의 구조를 정의하도록 하고, 연구자들은 inference에만 집중 했었다.(즉 hidden state을 알아내는 문제) 또한 이 경우 graph는 sparsely connected한 특성을 갖었다.\n",
    "- Neural nets: graphical model과 달리 learning에 집중하고 있었다. 수작업으로 어떤 지식을 만드는 방법(전문가가 graph 구조를 설계하는 등)은 바람직하지 않은 것이고, 데이터를 통해 어떤 지식을 구체화 구조화 하는 방법이 더 나은 것이라고 생각 했었다. 그래서 모델의 해석이나 inference를 용이하게 하는 방법들에는 큰 관심이 없었다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Two types of generative neural network composed of stochastic binary neurons</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두가지 종류의 idealized neurons(stochastic binary neurons)를 이용한 generative model이 있다.\n",
    "- Energy-based model: Boltzmann machine과 같은 symmetric connection을 사용하는 NN\n",
    "- Causal model: Sigmoid Belief Net과 같은 directed acyclic graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 13c, Learning Sigmoid Belief Nets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid belief net을 학습시키는 것이 왜 어려운지에 대해서 알아보자. 그리고 학습을 가능케 하는 두가지 방법에 대해서 알아볼 것이다. 좋은 뉴스는 Boltzmann machines와 달리 두개의 phase가 필요하지는 않다는 것이다. Sigmoid belief net에서는 Boltzmann machine에서 Positive phase와 같은 하나의 phase만 있으면 된다. 이게 가능한 이유는 Sigmoid belief net은 locally normalized model이기 때문이다. 그래서 partion function이나 이것의 derivative를 생각할 필요가 없다. 또 한가지 좋은 점은 만약 우리가 data vector가 주어졌을 때 posterior distribution of hidden unit에서 unbiased sample을 얻을 수 있다면 학습이 매우 쉬워진다는 것이다. 이런 상황이 되면 mini-batch stochastic방식으로 Maximum likelihood learning에 따라 gradient를 따라가면 학습이 진행될 수 있다. 그런데 한가지 문제는 posterior distribution of hidden unit에서 unbiased sample을 얻기가 어렵다는 점이다. 그 이유는 <u>Explaining away</u> 때문인데 이에 대해서도 알아볼 것이다.(중요)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Learning Sigmoid Belief Nets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 Sigmoid Belief Net을 학습시키는 것이 어려운 이유에 대해서 알아보자. 우리가 알다시피 학습이 진행되고 나서는 unbiased sample을 얻는 것이 쉽다. 이 말은 우리가 network의 weight들을 결정하고 나면 network에서 state vector를 sampling해서 network가 나타내려는 것이 무엇인지 알수 있게 된다. 이런 sampling은 top layer에서부터 state 값을 생성시켜서 layer by layer로 state값을 생성시키는 과정이다. 이렇게 하는 이유는 이 모델이 causal model이기 때문이다.\n",
    "\n",
    "하지만 우리가 weight들을 안다 하더라도 visible effect들만을 관측해서는 hidden causes(upper hidden layer)의 posterior distribution을 추론하는 것은 쉽지 않다. 이것이 어려운 이유는 우리가 관측한 visible effect을 유발할 수 있는 hidden causes의 경우의 수가 hidden node의 수에 exponential 하게 많기 때문이다. 그렇기 때문에 hidden causes(upper hidden layer)의 posterior distribution에서 sampling 하는 것은 더더욱 어렵다고 할 수 있다. (stochastic gradient descent를 할 경우 이런 sample이 필요한데 말이다.)\n",
    "\n",
    "이렇게 posterior distribution에서 sampling을 하는 것이 어렵기 때문에 파라미터가 매우 많은 Sigmoid belief net을 학습시키는 것은 쉽지 않아 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_sigmoid_belief_net1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The learning rule for sigmoid belief nets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아무튼 posterior distribution에서 sample을 얻는 것이 어렵다고 했는데...    \n",
    "우선 만약 이런 sample이 있을 경우에는 learning을 어떻게 진행하는지 알아보자.   \n",
    "(쉽지 않겠지만) 만약 (given observed data) hidden state들의 posterior distribution에서 뽑은 sample들이 있다면 learning이 쉬워진다.\n",
    "\n",
    "아래 그림은 sigmoid belief net의 일부인데, 각 unit이 0과 1의 binary 값을 갖는다고 가정하다. node $j$의 state값은 $s_j$이고 전체 unit들의 state vector를 global configuration이고 이것이 바로 posterior distribution에서 뽑은 sample이라 할 수 있다.\n",
    "\n",
    "Maximum likelihood learning을 하기 위해 해야 하는 것은 단지 unit $i$의 state값이 unit $j$들에 의해 나왔을 log probability를 가장 높아지도록 weight들을 조정하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_sigmoid_belief_net2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 unit $i$의 parent들이 unit $i$의 값을 1로 만들 확률은 아래와 같이 국지적이고 간단하게(local & simple) 계산되는데, Maximum likelihood learning을 위해서는 이 확률 값을 $s_i$에 최대한 가깝게 만들어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$p_i \\equiv p(s_i = 1) = \\frac{1}{1 + \\mathrm{exp}\\left( -b_i - \\sum_j s_j w_{ij}\\right)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 $w_{ji}$에 대한 gradient는 아래와 같이 계산되는데, 이 값은 unit $j$의 binary state에 unit $i$의 binary state과 $p_i$의 차이를 곱한 값에 비례한다. \n",
    "$$\\Delta w_{ji} = \\epsilon ~ s_j (s_i - p_i )$$\n",
    "결국 모드 hidden node들의 state값을 알게 되면(sample을 얻으면) maximum likelihood learning을 하는 것은 매우 쉬워진다.(물론 stochastic 한 방법을 사용할 때 그러하다.)\n",
    "\n",
    "즉 sample을 얻고 weight들을 update하고, sample을 또 얻고 weight들을 update하는 과정을 반복할 수 있게 된다. (mini-batch 방식에서는 하나의 batch에서 각 sample에 대해 $\\Delta w_{ij}$들을 구하고 이들의 평균 값으로 weight을 update하게 된다. 그리고 다음 batch에 대해 이 과정을 반복한다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Exmpaining away(Judea Pearl)</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 본론으로 돌아가서 왜 posterior distribution에서 sample을 얻는 것이 어려운지에 대해서 생각해보자.($\\sigma \\equiv sigmoid$)\n",
    "\n",
    "그 이유는 leaf node들의 state vector가 주어졌을 때 hidden node들에 대한 posterior distribution에서 unbiased sample을 얻기가 어려워서 인데, 이런 현상을 **Explaining away**라 부른다.\n",
    "\n",
    "아래 예를 보면, 두개의 hidden cause(truck hits house, earthquake)가 있고 하나의 관측요소(house jumps)가 있다. 그리고 각 node에 (0이 아닌) bias값이 있음을 알 수 있다. 또한 두개의 원인 중 하나라도 발생하지 않았다면 관측 현상이 발생하지 않을 것임을 알 수 있다. 그런데 만약 두 원인중 하나가 발생한다면 (즉 두 hidden unit 중 하나의 state값이 1이라면) 20이 -20을 상쇄하므로 (bias가 사라져서) 50%의 확률($\\sigma(0)$)로 house jump가 발생할 것임을 알 수 있다.\n",
    "\n",
    "물론 각 원인은 bias값이 -10이므로 발생 확률이 높지 않다.($\\sigma(-10) = -0000453978687025$) 하지만 이 확률은 아무런 원인이 없이 house jumping이 발생할 확률($\\sigma(-20)=-0000000020611537$보다는 큰 값이다. 따라서 house jump가 관측됐다면 (아무 원인 없이 house jumping이 발생했다기 보다는) 두 원인중 어떤 하나가 발생했으리라고 추론할 수 있다.(두 원인이 동시에 발생할 확률($\\sigma(-10) \\times \\sigma(-10) = \\sigma(-20)$)은 더더욱 낮으므로 하나만 발생했으리라 추론, 여기에서는 house jumping이 아무런 원인 없이 발생할 확률과 두 원인이 동시에 발생할 확률이 같음)\n",
    "\n",
    "<u>따라서 만약 [earthquake]가 관측된다면 이 사실은 [truck hits house]가 관측될 확률을 낮추게되는 효과를 갖는다.</u> 즉 hose jumping이 관측되었을 때 [earthquake]와 [truck hits house]는 서로 anti-correlation(음의 상관관계)를 갖는다.\n",
    "(즉 집이 흔들렸을 때, 원인이 무엇일지 생각하게 되고 아무런 증거가 없을 때에는 트럭 사고와 지진의 확률을 동일하게 50%로 생각할 것이다. 그런데 지진 뉴스를 보는 순간 지진이 원인일 확률은 매우 높아지게 되고 상대적으로 트럭사고의 확률은 매우 낮아지게 된다. 즉 이런 anti-correlation은 data 가 주어졌을 때의 조건부 확률에 관한 논의 이다. 따라서 (모델 자체만 봐서는) hose jumping에 대한 정보가 없을 때 [earthquake]와 [truck hits house]는 서로 independent라 할 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_sigmoid_belief_net_ex.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 [house jumps]가 관측되었을 때, [earthquake]는 발생했고 [truak hits house[는 발생하지 않았을 확률은 아래와 같다.(계산해보면 거의 0.5에 가까운 값을 얻을 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "P(h_1 = 0, h_2 = 1 ~ | ~ v=1) &= \\frac{P(v=1 ~ | ~ h_1 = 0, h_2 = 1) ~ P(h_1 = 0, h_2 = 1)}{P(v=1)} \\\\\n",
    "&= \n",
    "\\frac{P(v=1 ~ | ~ h_1 = 0, h_2 = 1) ~ P(h_1 = 0, h_2 = 1)}{P(v=1 ~ | ~ h_1 = 0, h_2 = 0) ~ P(h_1 = 0, h_2 = 0) + P(v=1 ~ | ~ h_1 = 0, h_2 = 1) ~ P(h_1 = 0, h_2 = 1) + P(v=1 ~ | ~ h_1 = 1, h_2 = 0) ~ P(h_1 = 1, h_2 = 0) + P(v=1 ~ | ~ h_1 = 1, h_2 = 1) ~ P(h_1 = 1, h_2 = 1)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 [house jumps]가 관측되었고 [truck hits house]는 아니라는 사실이 알려져 있을 때, [earthquake]가 발생했을 확률은 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "P(h_2 = 1 ~ | ~ v = 1, h_1 = 0) &= \\frac{P(v=1, h_1 = 0, h_2 = 1)}{P(v = 1, h_1 = 0)} \\\\\n",
    "&=\\frac{P(v=1, h_1 = 0, h_2 = 1)}{P(v = 1, h_1 = 0, h_2 = 0) + P(v = 1, h_1 = 0, h_2 = 1)}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def s(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bias_h1 = -10\n",
    "bias_h2 = -10\n",
    "bias_v = -20\n",
    "w1 = 20\n",
    "w2 = 20\n",
    "s_v = 1\n",
    "s_h1 = 0\n",
    "s_h2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_v_given_h1_h2 = s(bias_v + s_h1 * w1 + s_h2 * w2); p_v_given_h1_h2\n",
    "\n",
    "p_h1_h2 = s(bias_h1) * s(bias_h2); p_h1_h2\n",
    "\n",
    "p_h1_h2_v = p_v_given_h1_h2 * p_h1_h2; p_h1_h2_v; p_h1_h2_v\n",
    "\n",
    "delta_w1 = s_h1 * (s_v - p_v_given_h1_h2); delta_w1\n",
    "\n",
    "delta_w2 = s_h2 * (s_v - p_v_given_h1_h2); delta_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마찬가지 방법으로 [house jumps]가 관측되었을 때, 원인들의 다른 경우 확률들도 계산해보면 아래와 같다.\n",
    "\n",
    "$$P(h_1 = 1, h_2 = 1 ~ | ~ v=1) = 0.0001\\\\\n",
    "P(h_1 = 1, h_2 = 0 ~ | ~ v=1) = 0.4999\\\\\n",
    "P(h_1 = 0, h_2 = 1 ~ | ~ v=1) = 0.4999\\\\\n",
    "P(h_1 = 0, h_2 = 0 ~ | ~ v=1) = 0.0001\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 [house jumps]가 관측되었을 때, 두 원인 모두 발생하지 않았거나, 두 원인 모두 발생했을 확률은 매우 낮음을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이와 같이 하나의 결과에 여러 원인이 작용할 때, prior(결과에 대한 정보가 없을 때)에서는 각 원인들이 독립적일지라도 결과가 관측되고 나면 각 원인들의 확률이 서로 종속적인 관계를 갖게 되는 것을 **explaining away**라 한다. (하나의 원인이 결과를 다 설명하게 되어 다른 원인은 별 의미가 없어지게 되기 때문이 이렇게 부르는 것이 아닌가 싶다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why it's hard to learn sigmoid belief nets on layer at a time</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림과 같이 hidden layer가 여럿인 network를 생각해 볼 수 있다.(아래에서부터 data layer, 첫번째 hidden layer, 두번째 hidden layer, 세번째 hidden layer라 부르겠다.)     \n",
    "이때 첫번째 hidden variables와 data 사이의 weights $W$를 학습시키고 싶은데\n",
    "let's see what it takes to learn data. 우선 첫번째 hidden layer의 variable들에 대한 posterior distribution이 factorial이 아니다.(즉 layer내의 각 variable들이 서로 독립이 아니다.) 이는 explaining away 때문에 자명하다. 심지어 단 하나의 hidden layer가 있다 해도 data를 관측하는 순간 이들을 서로 독립적이라 할 수 없다.\n",
    "\n",
    "그런데 심지어 hidden layer가 여럿이기 때문에 prior distribution에도 의존적이다.(not independent) 즉 두번째 hidden layer는 첫번째 hidden layer의 prior가 되고 이는 첫번째 hidden layer의 variables들이 서로 dependent하게 만든다. \n",
    "\n",
    "$W$를 학습시키기 위해서는 첫번째 hidden layer의 posterior distribution을 알아야 한다. 혹은 최소한 posterior distribution에 대한 approximation distribution이라도 알아야만 한다. 많이 양보해서.. approximation distribution을 알고 있다고 해더라도 prior를 계산하기 위해서는 두번째 세번째 hidden layer 연결하는 weight들도 알아야만 한다.\n",
    "\n",
    "그런데 그런데 weight들까지도 알고 있다 하더라도, prior를 계산하기 위해서는 윗단의 hidden variable들을 integrate out 해야만 하는데 그러기 위해서는 윗단 hidden variable들의 모든 경우의 수에 대한 계산이 필요하다. 따라서 이런 접근 방법은 가망이 없다 할 수 있고 이런 이유들 때문에 sigmoid belief net의 wegith들을 학습시키기가 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_multiLayer.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Some methods for learning deep belief nets</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래서 deep belief net을 학습시키기 위한 다른 접근 방법이 필요하다.     \n",
    "\n",
    "첫번째 접근 방법은 Monte Carlo method인데 좋은 시도이기는 하나 variable이 많아지고 layer가 깊어지면 학습속도가 현저하게 떨어지는 문제를 갖고 있다.      \n",
    "\n",
    "두번째 접근 방법은 variational method인데, 이 방법에서는 posterior distribution에서 unbiased sample을 뽑는것을 아예 포기하고 그냥 approximate distribution에서 sample을 뽑고 maximum likelihood learning을 하겠다는 것이다. 과연 이렇게 근사 분포를 사용한  log proabability가 의미가 있을지 의문이 들지만, 실제로는 이렇게 구한 log probability가 실제 log probability의 low bound라는 사실이 알려져 있다. 따라서 low bound를 높인다면 실제 log probability가 가까워질 것이라고 생각할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 13d, The wake-sleep algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초창기 Sigmoid belief net을 학습시키는 방법으로 Wake-sleep algorithm이 있다. 얼핏 보면 Boltzmann machine을 학습시킬때 사용한 2-phase(Postive and negative) 방법과 유사해 보이지만 Boltzmann machine은 undirected graphical model이고 Sigmoid belief net은 은 directed graphical mode이라서 전혀 다른 방법이라 할 수 있다.\n",
    "\n",
    "Wake-sleep algorithm는 사실 일종의 Variational method라고 할 수 있다. Variational method의 아이디어는 정확한 사후분포를 계산하기 어렵기 때문에 좀더 계산이 편한 어떤 근사분포를 구하고 이 근사 분포를 이용해 maximum likelihood learning을 하겠다는 것이다. \n",
    "\n",
    "Wake-sleep algorithm을 이용한 학습과정에서 weight은 두가지 목표에 맞도록 변화하는데, 첫번째는 전체 model이 data를 잘 반영하도록 하는 것(model more likely to generate the observed data)이고, 두번째는 근사 사후분포가 실제 사후분포의 좋은 근사 분포가 되도록 하는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>An apparently crazy idea</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 어떻게 사후 분포의 근사 분포를 구할까?\n",
    "\n",
    "Sigmoid Belief Net과 같은 모델을 학습시키는 것은 쉽지 않다. 그 이유는 (데이터가 주어졌을 때 hidden configuration에 대한) 사후분포에서 sample을 뽑기가 어렵기 때문이다. \n",
    "\n",
    "실제 사후분포가 아니라 여러 복잡도가 제거된 다른 분포를 사후분포로 사용할텐데, 우선 이 근사분포가 hidden unit 분포의 곱으로 표현(factorize)된다고 가정할 것이다.(즉 데이터가 주어졌을 때 각 hidden layer의 unit들이 서로 독립이라는 가정임)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Factorial distributions</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서의 가정을 간단히 살펴보면...    \n",
    "어떤 hidden layer의 3개의 unit의 state이 1일 확률이 각각 0.3, 0.6, 0.8일 때,    \n",
    "이 hidden unit이 각각 (1, 0, 1)일 확률이 단순히 각 unit 확률의 곱으로 표현된다는 것이다. (즉 3 hidden unit이 서로 독립이라는 것임)\n",
    "$$p(1, 0, 1) = 0.3 \\times (1-0.6) \\times 0.8$$\n",
    "\n",
    "(서로 독립인 확률 변수 각각의 확률분포를 Factorial distribution이라 함)\n",
    "\n",
    "일반적으로 길이가 $N$인 binary vector의 경우 $2^N -1$(depth $N$의 binary tree를 생각해보면 됨, 다만 확률합이 1이므로 1을 빼줌)의 degree of freedom을 갖는다. 반면 factorial distribution의 경우 (서로 독립이라는 가정 때문에) degree of freedom이 $N$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The wake-sleep algorithm</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wake-sleep algorithm에서는 두가지의 weight을 사용하는데    \n",
    "아래 그림에서 녹색 화살표는 generative weights로서 데이터에 대한 probability distribution을 정의하는 weights이고   \n",
    "빨간색 화살표는 recognition weights로서 approximate posterior distribution을 구하는데 사용되는 weights이다.  \n",
    "(recognition weights을 이용해 각 hidden layer의 근사 사후 분포인 factorial distribution을 구하게 된다.)\n",
    "\n",
    "algorithm은 wake phase와 sleep phase로 구성되는데  \n",
    "우선 wake phase에서는 (아래 그림의 아래에서 위로 빨간 화살표를 따라) visible layer에서부터 데이터를 입력하여 recognition weights를 이용해 forward pass를 진행한다. 이때 각 unit의 activation function은 stochastic binary decision function이다.(이때 각 layer의 unit들은 서로 독립이라 가정한다.) 이렇게 stochastic forward pass를 진행하여 각 hidden layer의 state을 결정하면 이 state vector가 true posterior에서의 sample(given data)이라 가정하여 maximum likelihood learning을 진행하고 학습의 결과는 (recognition weight이 아니라) generative weights에 반영한다.\n",
    "\n",
    "sleep phase에서는 (wake phase와 반대로) top hidden layer의 state을 random으로 할당하고 (녹색 화살표를 따라) 반대로 forward pass를 진행한다. 이때도 각 hidden layer의 unit들이 서로 독립이라 가정한다. 대신 이때에는 generative weights들을 이용하여 stochastic forward pass를 진행하고, 이렇게 생성된 각 layer의 state vector가 true model에서 뽑힌 unbiased sample이라 가정하고 recognition weight을 학습시킨다.\n",
    "\n",
    "이렇게 두 phase를 번갈아가면서 반복하여 서로의 weights를 학습시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_wake_sleep.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The flaws in the wake-sleep algorithm</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_problem_of_ws.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Mode averaging</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 간단한 network에서 wake-sleep algorithm을 생각해 보자.   \n",
    "우선 sleep phase에서 top hidden layer의 state은 거의 항상 0일 것이다.($\\because ~ p(s_j=1) = \\frac{1}{1 + e^{-10}} \\approx 0$) 또한 이 때문에 visible unit은 거의 항상 0일 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/13_mode_averaging.PNG\"/>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
