{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kullback-Leibler divergence\n",
    "> - Murphy, ML, 2.8.2\n",
    "> - wiki\n",
    "> - Bishop, PRaML, 1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 두 probability distrubution $p$와 $q$의 차이를 측정하는 방법으로 Kullback-Leibler divergence(KL divergence, relative entropy)라는 것이 있다.\n",
    "\n",
    "$p$와 $q$가 discrete probability distribution일 경우 아래와 같이 정의된다.\n",
    "$$\\mathbb{KL}(p||q) \\triangleq \\sum_{k=1}^{K}p(k) \\log\\frac{p(k)}{q(k)}$$\n",
    "\n",
    "또한 $p$와 $q$가 continuous probability distribution 경우에는 아래와 같이 정의된다.\n",
    "$$\\mathbb{KL}(p||q) \\triangleq \\int p(x) \\log \\frac{p(x)}{q(x)}dx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 값에 대해 아래와 같은 해석이 가능하다.\n",
    "- $\\mathbf{E}\\left[ \\log p(x) - \\log q(x)) \\right]$, 즉 $p$와 $q$의 logarithmic difference의 기댓값.\n",
    "- belief를 prior probability distribution $q$에서 posterior probability distribution $p$로 바꿨을 때 추가로 얻게된 정보\n",
    "- 실제 분포 $p$를 $q$로 근사 했을 때 잃게 되는 정보량\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mixtures of Gaussians\n",
    "> - Bishop, PRaML, 1.6.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian distribution이 중요한 해석적 특성들을 갖고 있기는 하지만, 실제 데이터를 modelling할 때는 한계가 많다. 따라서 간단한 분포들의 선형 결합(linear combination)을 통해 어떤 혼합 분포(Mixture distribution)을 만들어 보다 복잡한 형태의 분포를 modelling하게 된다. 혼합의 재료로 Gaussian distribution을 사용하는 분포를 Misture of Gaussian이라 하고 형태는 아래와 같다.\n",
    "\n",
    "$$p(x) = \\sum_{K}^{k=1} \\pi_k \\mathcal{N}(x|\\mu_k , \\Sigma_k)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### EM Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Kalmal filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###### Variational Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
