{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6. Learning Best Practices for Model Evaluation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - pandas.**read_csv**를 이용한 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "                 ,header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 1번째 컬럼을 $\\mathbf{y}$로 사용, 2번째부터 끝까지 컬럼을 $\\mathbf{X}$로 사용\n",
    "> - sklearn.preprocessing.**LabelEncoder**를 이용해 y의 label(M: 악성, B: 양성)을 각각 1과 0으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "X = df.loc[:, 2:].values\n",
    "y = df.loc[:, 1].values\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "\n",
    "le.transform(['M', 'B'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - sklearn.cross_validation.**train_test_split**을 이용해 training set과 test set을 8:2로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - sklearn.pipeline.**Pipeline**에 두개의 transformer(StandardScaler, PCA)와 estimator(LogisticRegression)을 설정\n",
    "> - 앞서 train_test_split을 이용해 나눈 training set 데이터를 이용해 모형 학습\n",
    "> - test set 데이터를 이용해 모형의 정확도를 확인         \n",
    "※ 정확도(accuracy)는 전체 예측 중 '정'예측의 비율      \n",
    "$$ACC = \\frac{TP + TN}{FP + FN + TP + TN} = 1 - ERR$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe_lr = Pipeline([('scl', StandardScaler())\n",
    "                    , ('pca', PCA(n_components=2))\n",
    "                    , ('clf', LogisticRegression(random_state=1))])\n",
    "\n",
    "pipe_lr.fit(X_train, y_train)                    \n",
    "print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K겹 교차 검증(K-fold cross validation)과 층화 교차 검증(stratified coss validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> sklearn.cross_validation.**StratifiedKFold**를 이용한 층화된 교차 검증(stratified cross-validation)\n",
    "> - 각 fold의 $\\mathbf{y}$ label 비율이 256:153으로 일정하게 유지됨을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [256 153], Acc: 0.891\n",
      "Fold: 2, Class dist.: [256 153], Acc: 0.978\n",
      "Fold: 3, Class dist.: [256 153], Acc: 0.978\n",
      "Fold: 4, Class dist.: [256 153], Acc: 0.913\n",
      "Fold: 5, Class dist.: [256 153], Acc: 0.935\n",
      "Fold: 6, Class dist.: [257 153], Acc: 0.978\n",
      "Fold: 7, Class dist.: [257 153], Acc: 0.933\n",
      "Fold: 8, Class dist.: [257 153], Acc: 0.956\n",
      "Fold: 9, Class dist.: [257 153], Acc: 0.978\n",
      "Fold: 10, Class dist.: [257 153], Acc: 0.956\n",
      "CV accuracy: 0.950 +/- 0.029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "kfold = StratifiedKFold(y=y_train\n",
    "                       , n_folds=10\n",
    "                       , random_state=0)\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, np.bincount(y_train[train]), score))\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - numpy.bincount()는 ndarray에 있는 0의 건수와 1의 건수를 각각 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(np.array([1, 0, 0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[285 170]\n"
     ]
    }
   ],
   "source": [
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263736263736264"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "285 / (285 + 170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6259168704156479"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "256 / (256 + 153)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 10건만으로 테스트 해 보면 아래와 같이 0과 1의 비율이 3:2로 일정하게 유지됨을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 1 1 0]\n",
      "Fold: 1, Class dist.: [3 2], Acc: 1.000\n",
      "Fold: 2, Class dist.: [3 2], Acc: 1.000\n",
      "CV accuracy: 1.000 +/- 0.000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "print(y_train[0:10])\n",
    "kfold = StratifiedKFold(y=y_train[0:10]\n",
    "                       , n_folds=2\n",
    "                       , random_state=0)\n",
    "scores = []\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, np.bincount(y_train[train]), score))\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 앞서 sklearn.cross_validation.**StratifiedKFold**를 이용해 했던 일을      \n",
    "sklearn.cross_validation.**cross_val_score**을 이용해서도 할 수 있으며      \n",
    "이것을 이용할 경우 multi-core를 활용할 수 있다.(n_jobs: 코어 수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.89130435  0.97826087  0.97826087  0.91304348  0.93478261  0.97777778\n",
      "  0.93333333  0.95555556  0.97777778  0.95555556]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(estimator=pipe_lr\n",
    "                         , X=X_train\n",
    "                         , y=y_train\n",
    "                         , cv=10\n",
    "                         , n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 곡선(learning curves)과 검정 곡선(validation curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40  81 122 163 204 245 286 327 368 409]\n",
      "[[ 1.          0.975       0.975       0.975       0.975       0.975       0.975\n",
      "   0.975       0.975       0.975     ]\n",
      " [ 1.          0.98765432  0.98765432  0.98765432  0.98765432  0.98765432\n",
      "   0.98765432  0.98765432  0.98765432  0.98765432]\n",
      " [ 0.99180328  0.98360656  0.99180328  0.99180328  0.99180328  0.99180328\n",
      "   0.99180328  0.99180328  0.99180328  0.99180328]\n",
      " [ 0.99386503  0.98773006  0.98773006  0.99386503  0.98773006  0.98773006\n",
      "   0.98773006  0.98773006  0.98773006  0.98773006]\n",
      " [ 0.99509804  0.99019608  0.99019608  0.99509804  0.99019608  0.99019608\n",
      "   0.99019608  0.99019608  0.99019608  0.99019608]\n",
      " [ 0.99183673  0.9877551   0.99183673  0.99183673  0.99183673  0.99183673\n",
      "   0.99183673  0.99183673  0.99183673  0.99183673]\n",
      " [ 0.99300699  0.99300699  0.99300699  0.99300699  0.99300699  0.99300699\n",
      "   0.99300699  0.99300699  0.99300699  0.99300699]\n",
      " [ 0.99082569  0.98776758  0.99082569  0.99082569  0.99082569  0.99082569\n",
      "   0.99388379  0.99082569  0.99388379  0.99388379]\n",
      " [ 0.98913043  0.98913043  0.99184783  0.99456522  0.99184783  0.98913043\n",
      "   0.99184783  0.99184783  0.99184783  0.99184783]\n",
      " [ 0.99022005  0.98777506  0.99022005  0.99022005  0.99266504  0.99266504\n",
      "   0.99266504  0.99266504  0.99266504  0.99266504]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.learning_curve import learning_curve\n",
    "pipe_lr = Pipeline([('scl', StandardScaler())\n",
    "                    , ('clf', LogisticRegression(penalty='l2', random_state=0))])\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr\n",
    "                                                        , X=X_train\n",
    "                                                        , y=y_train\n",
    "                                                        , train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "                                                        , cv=10\n",
    "                                                        , n_jobs=1)\n",
    "print(train_sizes[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.learning_curve import learning_curve\n",
    "pipe_lr = Pipeline([('scl', StandardScaler())\n",
    "                    , ('clf', LogisticRegression(penalty='l2', random_state=0))])\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr\n",
    "                                                        , X=X_train\n",
    "                                                        , y=y_train\n",
    "                                                        , train_sizes=np.linspace(0.1, 1.0, 10)\n",
    "                                                        , cv=10\n",
    "                                                        , n_jobs=1)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "plt.plot(train_sizes, train_mean,\n",
    "color='blue', marker='o',\n",
    "markersize=5,\n",
    "label='training accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "train_mean + train_std,\n",
    "train_mean - train_std,\n",
    "alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean,\n",
    "color='green', linestyle='--',\n",
    "marker='s', markersize=5,\n",
    "label='validation accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "test_mean + test_std,\n",
    "test_mean - test_std,\n",
    "alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.8, 1.0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1,  0.2,  0.3,  0.4,  0.5,  0.6,  0.7,  0.8,  0.9,  1. ])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.1, 1.0, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가 기준(Accuracy, Precision, Recall, F1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환자가 암에 걸렸는지 진단하는 상황이라 해 보자.      \n",
    "암을 진단하는 것은 쉬운 일이 아니라 할 때              \n",
    "진단이 맞고 틀리는 경우는 아래 4가지 상황이 가능하다.     \n",
    "1. 암에 걸린 환자를 암에 걸렸다고 하는 경우\n",
    "2. 암에 걸린 환자를 암에 안 걸렸다고 하는 경우\n",
    "3. 암에 안 걸린 환자를 암에 안 걸렸다고 하는 경우\n",
    "4. 암에 안 걸린 환자를 암에 안 걸렸다고 하는 경우\n",
    "\n",
    "실제 암에 걸린 상황을 Positive라 하고, 암에 걸리지 않은 상황을 Negative라 하면    \n",
    "위 상황을 아래와 같이 표현할 수 있다.\n",
    "1. True Positive(TP)\n",
    "2. False Positive(FP)\n",
    "3. True Negative(TN)\n",
    "4. False Negative(FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 값(Actual/True Class)과 예측값(Predicted class)를 아래와 같은 **confusion matrix**로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/06_conf.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 조금만 암의 징후가 보여도 암이라 예측하는 의사 a와       \n",
    "정말 암이라는 확신이 있을 때에만 암이라 진단하는 의사 b가    \n",
    "100명의 환자에 대해     \n",
    "발병율 10%인 암에 대해 아래와 같은 예측을 했다고 하자.   \n",
    "(실제로 100명중 10명이 암에 걸렸다고 가정)\n",
    "\n",
    "즉 의사a는 20명(TP+FP)을 암이라 진단 했는데, 그들 중 8명(TP)만 정말 암에 걸린 환자이고     \n",
    "반변 의사b는 10명(TP+FP)을 암이라 진단 했는데, 그들 중 4명(TP)만 정말 암에 걸린 환자이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_tp = 8; a_fn = 2\n",
    "a_fp = 12; a_tn = 78\n",
    "\n",
    "b_tp = 4; b_fn = 6\n",
    "b_fp = 6; b_tn = 84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 의사 중 누가 더 좋은 결정을 한 것인가?    \n",
    "이에 대한 판단은 그 기준에 따라 달라지게 된다.\n",
    "\n",
    "우선 암이든 아니든 잘 예측한 비율을 따져보면    \n",
    "의사a는 암에 걸린 10명 중 8명(TP)에 대해, 암에 걸리지 않은 90명 중 78명(TN)에게 맞는(True) 진단을 내렸다. 이는 전체 환자중 86%이다.\n",
    "\n",
    "반면 의사b는 암에 걸린 10명 중 4명(TP)에 대해, 암에 걸리지 않은 90명 중 84명(TN)에게 맞는(True) 진단을 내렸다. 이는 전체 환자 중 88%이다.\n",
    "\n",
    "이렇게 전체 예측 중 True 예측의 비율을 정확도(Accuracy)라 하며 아래와 같이 계산한다.\n",
    "$$ACC = \\frac{TP + TN}{FP + FN + TP + TN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사a의 Accuracy:  0.86\n",
      "의사b의 Accuracy:  0.88\n"
     ]
    }
   ],
   "source": [
    "def get_acc(tp, fn, fp, tn):\n",
    "    return (tp + tn) / (fp + fn + tp + tn)\n",
    "\n",
    "print('의사a의 Accuracy: ', get_acc(a_tp, a_fn, a_fp, a_tn))\n",
    "print('의사b의 Accuracy: ', get_acc(b_tp, b_fn, b_fp, b_tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 의사b의 진단이 더 나은 것인가?    \n",
    "이번에는 기준을 바꿔서 '암이라고 진단한 환자 중 정말 암에 걸린 사람의 비율'을 보면   \n",
    "의사a는 20명을 암이라 진단 했고 이들 중 8명이 진짜 암 환자이므로 40%이고    \n",
    "의사b는 10명을 암이라 진단 했고 이들 중 4명이 진짜 암 환자이므로 그 비율은 40%이다.\n",
    "\n",
    "이렇게 Positive로 예측한 것들 중 True Positive의 비율을 정밀도(Precision)이라 하며 아래와 같이 계산한다.\n",
    "$$PRE = \\frac{TP}{TP + FP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사a의 Precision:  0.4\n",
      "의사b의 Precision:  0.4\n"
     ]
    }
   ],
   "source": [
    "def get_pre(tp, fn, fp, tn):\n",
    "    return tp / (tp + fp)\n",
    "a_pre = get_pre(a_tp, a_fn, a_fp, a_tn)\n",
    "b_pre = get_pre(b_tp, b_fn, b_fp, b_tn)\n",
    "print('의사a의 Precision: ', a_pre)\n",
    "print('의사b의 Precision: ', b_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 기준으로 '정말 암에 걸린 사람 중, 암이라 진단 받은 사람의 비율'을 보면    \n",
    "의사a는 암에 걸린 10명 중 8명을 암이라 진단해서 그 비율은 80%이고   \n",
    "의사b는 암에 걸린 10명 중 4명을 암이라 진단해서 그 비율은 40%이다.\n",
    "\n",
    "이렇게 True Positive 중 Positive라고 잘 예측한 비율을 재현율(Recall)이라 하며 아래와 같이 계산한다.(Recall을 Sensitivity, True-positive rate, Probability of detection이라고도 함) \n",
    "$$REC = \\frac{TP}{FN + TP}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사a의 Recall:  0.8\n",
      "의사b의 Recall:  0.4\n"
     ]
    }
   ],
   "source": [
    "def get_rec(tp, fn, fp, tn):\n",
    "    return (tp) / (fn + tp)\n",
    "a_rec = get_rec(a_tp, a_fn, a_fp, a_tn)\n",
    "b_rec = get_rec(b_tp, b_fn, b_fp, b_tn)\n",
    "print('의사a의 Recall: ', a_rec)\n",
    "print('의사b의 Recall: ', b_rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 대충 그냥 다 암이라고 진단하면 Recall이 높아지게 되고        \n",
    "아주 정말 암 같아야 암이라고 진단하면 Precision이 높아지게 된다.\n",
    "\n",
    "즉 판단의 기준(근거가 몇%이상이어야 Positive라 판단하는가)에 따라 하나의 평가 기준으로는 우열을 가리기 어려운 상황이 생기게 된다.\n",
    "\n",
    "두 지표(Recall, Precision)을 절충한 지표로 **F1-score**가 있으며 아래와 같이 계산한다.\n",
    "$$F1 = 2 ~ \\frac{PRE \\times REC}{PRE + REC}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "의사a의 F1-score:  0.5333333333333333\n",
      "의사b의 F1-score:  0.4000000000000001\n"
     ]
    }
   ],
   "source": [
    "def get_f1(pre, rec):\n",
    "    return 2 * (pre * rec) / (pre + rec)\n",
    "print('의사a의 F1-score: ', get_f1(a_pre, a_rec))\n",
    "print('의사b의 F1-score: ', get_f1(b_pre, b_rec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고로 가설검정에서 False Positive(귀무가설을 잘못 기각)를 **Type 1 error**라고,    \n",
    "False Negative(귀무가설을 잘못 기각하지 못함)를 **Type 2 error**라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 의사a가 더 좋은 의사인가?    \n",
    "모르겠습니다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 의사의 예와 같이 암이라는 증거가 충분한 경우(예를들어 90%이상 확신하는 경우) 암이라 진단할 수도 있고 암 이라는 증거가 조금만 보여도(예를들어 50%이상 확신하는 경우) 암이라 진단할 수도 있다.\n",
    "\n",
    "즉 판단의 기준(decision threshold)에 따라 암 환자를 암이라고 예측하는 비율이 달라지게 된다. 이렇게 decision threshold에 따른 True Positive의 비율(암 환자를 암이라 진단하는 비율)과 False Positive의 비율(암 환자를 정상이라 진단하는 비율)을 그래프로 표현해 볼 수 있는데, 이를 **ROC Curve**(Receiver Operating Characteristic Curve혹은 Relative Operating Characteristic Curve)라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "곡선 아래의 면적을 **AUC**(Area Under the Curve)라 하며 이 값이 클 수록 좋은 모형이라 할 수 있다.(이에 대한 반론도 있으며 DeltaP등의 다른 평가 지표를 사용하기도 한다.)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
