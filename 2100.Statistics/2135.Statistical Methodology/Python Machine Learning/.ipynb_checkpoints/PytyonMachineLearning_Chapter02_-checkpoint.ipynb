{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2. Training Machine Learning Algorithms for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 supervised learning을 설명하면서       \n",
    "label이 범주형 변수일 경우 <u>Classification</u> problem이고,      \n",
    "label이 연속일 경우 <u>Regression</u> problem이라고 했었다.\n",
    "\n",
    "Chapter2에서는 <u>Classification</u> 알고리즘 중 (아주) 고전이라고 할 수 있는        \n",
    "**Perceptrons**와 **Adaptive linear neurans**에 대해서 알아보고,        \n",
    "기본적인 최적화(optimization) 기법에 대해서도 알아보자.     \n",
    "(Classification problem에 대한 connectionist적 관점에서의 접근)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Artificial neurons</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An **artificial neuron** is a <u>mathematical function</u> conceived as a model of <u>biological neurons</u>. Artificial neurons are the constitutive units in an artificial neural network. Depending on the specific model used they may be called a <u>semi-linear unit, Nv neuron, binary neuron, linear threshold function, or McCulloch–Pitts (MCP) neuron.</u>\n",
    "<div align=\"right\">Reference: https://en.wikipedia.org/wiki/Artificial_neuron</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'어떤 입력들이 들어오고 이들을 종합하여 어떤 출력을 내놓는 것'을 표현할 수 있는 다양한 방법이 있다. 우선 수학적으로는 y = f(x1, x2, ..., xp)와 같은 함수를 생각해볼 수 있다.\n",
    "\n",
    "인공지능과 뇌과학 분야에서는 두뇌에서 일어나는 연산/판단 과정을 알아내기 위해 다양한 시도를 했는데, 뉴런을 어떤 수학적 함수로 표현하는 하는 것도 그런 시도들 중 하나였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_artificial_neurons.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 생물학적 neuron을 수학적 함수로 표현하는 시도 중 하나가 **Artificial neuron**인데, Warren McCullock and Walter Pits가 1943년 고안한 것으로 **McCulloch–Pitts (MCP) neuron**이라고도 부른다.(멕컬릭 엔 핏츠 뉴런)\n",
    "\n",
    "artificial neuron에 대한 기본 아이디어는 뉴런이 여러 다양한 입력을 받아 어떤 계산을 하고 그 계산의 합(혹은 함수의 출력값)이 어떤 임계치보다 크면 어떤 1을 내보내고, 임계치($\\theta$) 보다 작을 경우 -1을 출력으로 내보내는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것을 수학적으로 표현하면 하나의 뉴런에 들어오는 다양한 입력 각각을 $x_1, x_2, \\dots, x_p$이라 하고        \n",
    "이들의 연산이 단순히 가중합(weighted sum)이라 가정하면 그 연산 합은 아래와 같다.\n",
    "$$z = x_1 w_1 + x_2 w_2 + \\dots + x_p w_p$$\n",
    "\n",
    "이때 z가 임계치를 넘느냐 넘지 않느냐에 따라 아래와 같이 표현할 수 있다. \n",
    "$$z = \\sum_{i} x_i w_i$$   \n",
    "$$\\phi(z) = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ -1 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "혹은 임계치를 bias로 바꿔서 표현할 수 도 있다.($\\theta = -b$)    \n",
    "$$z = b + \\sum_{i} x_i w_i$$   \n",
    "$$\\phi(z) = \\begin{cases} 1 & \\rm{if} ~ z \\geq 0 \\\\ -1 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "이를 그래프로 아래와 같이 나타낼 수 있다. \n",
    "이런 판단을 하는 함수를 activation function이라 부름, 수학적으로는 sign function이라 부름."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_artificial_neurons_graph.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 함수의 입력과 출력과의 관계는       \n",
    "weight($w_1, w_2, \\dots , w_p$)들이 정해져 있을 때,                \n",
    "어떤 데이터 값들에는 1을 출력하고,       \n",
    "다른 데이터 값들에는 -1을 출력하고 있다.     \n",
    "즉 입력들을 두개의 그룹으로 나누고 있다는 것을 알 수 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 입력 변수가 $x_1$과 $x_2$으로 두개만 있고    \n",
    "데이터도 아래의 단 두건만 있다고 가정해 보자.\n",
    "$$\\mathbf{X} = \\left(\n",
    "\\begin{array}{c}\n",
    "1 & 1\\\\\n",
    "2 & 1\\\\\n",
    "\\end{array}\n",
    "\\right)$$\n",
    "\n",
    "그때의 함수 $w_1 x_1 + w_2 x_2 > \\theta$, $x_2 > \\frac{\\theta}{w_2} - \\frac{w_1}{w_2}x_2$는 어떤 직선으로서      \n",
    "입력들을 두개의 그룹으로 나누는 직선이다.      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면 어떻게 적절한 $w_1$과 $w_2$값을 찾을 수 있을까?     \n",
    "(결국 모델을 학습시킨다는 것은 이 $w_1$과 $w_2$을 찾는 것이다.)\n",
    "\n",
    "어떻게 $w_1$과 $w_2$찾을 수 있을까? \n",
    "- 해석적 접근: 닫힌 해(Closed form solution)\n",
    "$$w_1 + w_2 > \\theta\\\\, 2w_1 + w_2 < \\theta$$\n",
    "<br>\n",
    "$$w_1 <  0, w_2 > \\theta$$\n",
    "\n",
    "- 반복적 방법(Iterative method)      \n",
    "-- 뉴튼 랩슨법(Newton-Raphson method)       \n",
    "-- 최대 우도 경사 하강법(ML gradient ascent methods)     \n",
    "-- ... 등등  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Perceptron learning rule</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight($w$)들을 찾는 반복적 방법(모형을 학습시키는 방법)으로 1957년 F.Rosenblatt가 제안한 방법으로 **Perceptrons**가 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1. 모든 weight($w_1, w_2, \\dots , w_p$)들을 0으로 초기화\n",
<<<<<<< HEAD
    "> 2. 각 데이터 건에 대하여 잘 예측했다면 $w_j$를 그대로 둠        \n",
    "잘못 예측했다면 $w_j$를 $x_j$에 비례하여 감소 혹은 증가      \n",
    "(실제 1인데 -1로 예측한 경우 증가, 실제 -1인데 1로 예측한 경우 감소)   \n",
    "$$w_j := w_j + \\eta ( y^{(i)} - \\hat{y}^{(i)}) x_j^{(i)}$$\n",
=======
    "> 2. 각 데이터 건에 대하여 잘 예측했다면 $w_j$를 변경하지 않음  \n",
    "잘못 예측했다면 $w_j$를 $x_j$에 비례하여 감소\n",
    "$$w_j := w_j + \\eta ( y^{(i)} - y^{(i)}) x_j^{(i)}$$\n",
>>>>>>> e9bf209a8cf587e167ecb978c4812fdd7e6bc2c4
    "\n",
    "> 3. 더 이상 weight들의 (큰) 변화가 없을 때까지 2를 반복\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "###### <u>Implementation using Python</u>"
=======
    "Perceptrons가 나왔을 당시만해도 대단히 충격적이고 멋진 방법론이었으나...      \n",
    "linearly sperable 하지 않은 문제는 풀수 없다는 치명적인 단점이 있다.    \n",
    "(현실의 문제는 대부분 linearly sperable 하지 않음)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### <u>Implementing a perceptron</u>"
>>>>>>> e9bf209a8cf587e167ecb978c4812fdd7e6bc2c4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
<<<<<<< HEAD
    "다음 시간에..."
=======
    "다음시간에..."
>>>>>>> e9bf209a8cf587e167ecb978c4812fdd7e6bc2c4
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
