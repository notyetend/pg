{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Introduction and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Graphical Model이 뭔지 알기 위해       \n",
    "우선 이것이 쓰일만한 예를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번 째 예로 의사가 환자를 진찰하는 상황은 그 환자에 대한 여러 요인, 증상, 검사결과가 주어졌을 때 이 환자의 질병이 무엇인지 또는 어떤 처치에 대한 결과가 어떨지를 찾아내려는 것이다.        \n",
    "\n",
    "또 다른 예로 이런 그림이 주어져 있을 때 각 pixel 혹은 그림의 조각들이 각각 어떤 사물(grass, sky, cow, horse) 을 나타내는지 알아내는 문제를 생각해볼 수 있다.\n",
    "\n",
    "이 두가지 예의 공통점은 무엇일까? 우선 두 문제 모두 추론해야 하는 대단히 많은 변수들이 있다는 점이다. 두번째 공통점은 이런 문제의 정답이 불확실하다는 점이고, PGM은 이런 문제를 다루기 위한 framework라고 할 수 있다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Graphical <u>Model</u> \n",
    "\n",
    "모형은 어떤 상황을 구성하는 변수들이 무엇이고 이들이 서로 어떤 상호작용을 하는지를 나타내는 선언적 표현(declarative representation)이라 할 수 있다. 여기서 선언적(declarative)라는 표현을 쓴 것은 모형이 알고리즘 혹은 모형을 학습시키는 것과 독립적이라서 그 자체로 의미가 있다는 것이다.   \n",
    "\n",
    "모형이 그 자체로 의미를 갖는 다는 것은 몇가지 장점을 갖는데 우선 하나의 모형이 주어졌을 때 이 모형을 기반으로 해당 상황을 풀 수 있는 다양한 알고리이 존재할 수 있다는 것을 의미한다. 즉 어떤 알고리즘은 정확도가 높은 장점이 있고 다른 알고리즘은 설명력이 높은 장점이 있을 수 있고 혹은 정확도와 설명력이 적절히 균형작힌 알고리즘을 사용할 수도 있다는 것이다.\n",
    "\n",
    "또 다른 장점은 알고리즘과 독립적으로 모형을 만들 수 있다는 것인데, 어떤 업에 대한 전문가의 노하우 혹은 통계적 기계학습 방법을 이용한 지식 혹은 이 둘을 결합한 모형을 만들 수 있게 되는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Probabilistic</u> Graphical Model\n",
    "\n",
    "이는 PGM이 많은 불확실성(uncertainty)를 모형화하기 위해 사용되기 때문이다.     \n",
    "그렇다면 불확실성의 원인은 무엇일까?     \n",
    "- Partial knowledge of state of the world: 예를들어 의사는 환자에 대한 모든 증상을 알 수는 없는 상황 때문에 그 환자의 질병을 정확히 진단할 수 없다.\n",
    "- Noisy observations: 예를들어 환자의 혈압을 측정할 수 있지만 이런 측정 결과 또한 알수 없는 여러 요인에 의해 측정할 때마다 다른 값을 얻게 된다.\n",
    "- Phenomena not covered by our model: 가능한 모든 상황을 모형에 포함시킬수는 없는  한계(modeling limitations) 때문에 불확실성이 나타나기도 한다. 예를들어 우리 모형에 포함되어 있지 않은 (아주 드문 혹은 고려 대상이 아닌) 질병이 환자의 증상을 유발했을 수도 있다. \n",
    "- Inherent stochasticity: 세상은 원래 불확실성으로 가득차 있을지도 모를 일이다.  이때문에 알수 없는 많은 것들이 작은 원인이 되어 서로 영향을 주고 받고, 결국 우리는 이 모든 것을 모형에 포함시킬 수 없게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률론은 이런 불확실성을 다룰 수 있게 해 주는       \n",
    "어떤 원칙과 도구들을 제공하는 틀(framework)이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probabilistic Graphical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 Probabilistic Graphical Model을 이용해 세상의 어떤 상태에 대한 선언적 모형을 만들 수 있고 그 현상에 대한 불확실성을 확률분포로 표현하게 된다. 또한 이 모형을 이용해 다양한 근거가 주어졌을 때 미지의 상태에 대한 추론이 가능하게 된다.\n",
    "\n",
    "또한 PGM은 확률론 및 통계 이론에 근간에 두고 있기 때문에 이미 연구된 통계적 학습방법의 다양한 학습 기법들을 사용하여 PGM의 모형들을 학습시킬 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic <u>Graphical</u> Model \n",
    "\n",
    "PGM은 불확실성을 다루는 확률론의 아이디어와 많은 원인이 포함된 문제를 **연결**로 표현하는 아이디어가 혼합된 것이라서, Graphical 이란 단어에는 현상을 모형화하는 CS의 관점이 반영된 것이라 할 수 있다.\n",
    "\n",
    "앞서 의사의 진단 문제와 그림을 판별하는 문제에서와 같이 많은 변수를 포함하는 문제는      \n",
    "각각 continuous, categorical 혹은 binary일 수 있는 확률변수들(random variables) $X_1, X_2, \\dots X_n$에 대한        \n",
    "결합 확률 분포(joint probability distribution) $P(X_1, X_2, \\dots X_n)$를 추론하는 것이 그 핵심이다. \n",
    "\n",
    "예를들어 $n$개의 확률변수가 모두 이항변수일 경우, $2^n$개의 가능한 상황이 있기 때문에 이 모든 상황에 대한 확률을 알아내는 것은 쉬운 일이 아니다. 이를 보다 쉽게 다루기 위해 우리는 Probabilistic Graphical Model이라는 방법을 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGM은 크게 Bayesian networks와 Markov networks로 나눌 수 있는데,     \n",
    "아래 그림은 아주 간단한 Bayesian network이다.\n",
    "\n",
    "그림은 node(원)과 directed edge(선)로 구성되는데,          \n",
    "각 node는 확률변수(random variable) $X_i$를 나타내고      \n",
    "edge는 변수간의 확률적 연결(probabilistic connections)를 나타낸다.\n",
    "\n",
    "아래 예는 어떤 학생이 어떤 과목에서 어떤 학점(Letter)을 받을지를 bayesian network로 모형화 한 것이다. 이때 학생이 받을 학점은 확률변수라 할 수 있고, 이에 영향을 줄 수 있는 Difficulty, Intelligence, Grade, SAT라는 다른 확률변수들도 모형에 포함되어 있다.\n",
    "\n",
    "얼핏 보기에 과목의 난이도와 학생의 지적 능력이 해당 과목의 시험 점수에 영향을 주고 이것이 학점에 영향을 주며, 또한 학생의 지적 능력은 그 학생의 SAT 성적에도 영향을 주는 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_bayes_net.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 제시된 다른 종류의 PGM은 Markov network이다.      \n",
    "앞서 bayesian network와 다른 점은 undirected connection을 사용한다는 점 이다.\n",
    "\n",
    "아래 예에서는 A, B, C, D 4개의 확률변수가 undirected graph를 구성하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_markov_net.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 두 graphical model은 아주 간단한 예이고,    \n",
    "실제 사용되는 Bayesian network 모형은 아래 왼쪽과 같이 복잡할 수 있다. 이 모형은 Computer-based Patient Case Simulation system, CPCS라 불리며 480개의 node와 900개 이상의 edge로 구성되어 환자 진단을 모형화 한 것이다. \n",
    "\n",
    "아래 우측의 예는 image segmentation에 사용되는 Markov network로서 각 확률변수는 pixel 혹은 superpixel들의 label을 나타낸다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_cpcs.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로 PGM은 고차원 확률분포로 이루어진 데이터의 구조를 직관적이고 간략하게 표현하는데 사용된다. 또한 확률적 머신 러닝의 다양한 알고리즘을 이용해 주론이 가능하며 변수들간의 관계를 이용해 더 작은 변수를 이용해 각 상태를 표현할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Course overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Representation\n",
    " - Directed and undirected\n",
    " - Temporal and plate models\n",
    "- Inference(Reasoning)\n",
    " - Exact and approximate\n",
    " - Decision making\n",
    "- Learning\n",
    " - Parameters and structure\n",
    " - With and without complete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGM에 대해 본격적으로 알아보기에 앞서       \n",
    "확률분포(probability distribution)가 무엇인지 간단한 예를 통해 리뷰하도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Joint  Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 학생의 지적능력의 높고 낮음(high / low)을 나타내는 확률변수 intelligence, 특정 과목의 난이도의 높고 낮음(high / low)을 표현하는 확률변수 difficulty, 학생의 성적(A, B, C)을 나타내는 확률변수 grade라는 3개의 확률변수가 있고, 이 3개 확률변수의 joint probability distribution을 생각해보자.\n",
    "\n",
    "이 3개의 확률변수의 가능한 모든 조합의 수는 2 * 2 * 3의 12가지이고 각 경우에 대한 확률을 결정해야한다. \n",
    "\n",
    "아래 표에 12가지 경우가 모두 나열되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_joint_dist1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률 분포를 가정하기 때문에 Prob의 모든 값을 더하면 1이 되어야 한다. 따라서 12개의 확률 값 중 11개를 알고 있다면 나머지 하나의 값 또한 알 수 있다. 따라서 위 확률 분포에서 독립적인 파라미터의 수는 11개이다.(자유도, degree of freedom, the number of independent parameters), 이 자유도라는 개념은 나중에 서로 다른 확률 분포의 상대적 설명력을 평가할때 사용될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Conditioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률분포를 이용해 할 수 있는 것 중 하나가 **Conditioning**이라는 것 인데,  \n",
    "예를들어 3개의 확률 변수중 학생의 Grade가 $g^1$라는 것을 알게 되었다고 하자. 이때 3확률변수에 대한 확률 분포($P(I, D ~|~ G=g^1)$)는 어떠할까? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_conditioning1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 표와 같이 $G$가 $g^1$이 아닌 경우는 모두 관측치($G=g^1$)에 부합하지 않으므로 확률이 0이라는 것이 자명해 지고 아래와 같은 새로운 확률 분포 $P(I, D ~|~ G=g^1)$를 얻게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_conditioning2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼 관측결과에 부합하지 않는 확률변수 조합을 제거하는 연산을 **reduction**이라 부른다. 그런데 위 표의 오른쪽 값들도 확률이고 제시된 확률변수 조합이 가능한 모든 경우라면 그 확률 값의 합이 1이 되어야 하는데, 그렇지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 확률 분포로 만들기 위해 아래와 같이 전체의 합으로 각 값들을 나눠주는데 이를 **re-normalization**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_renormalization1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 다수 확률변수들의 결합확률분포가 있을 때, 일부 확률변수들만의 결합확률분포를 구하는 것을 **marginalization**이라 한다. 앞서 예와 같이 전체 $I$와 $D$ 2개의 확률변수가 주어져 있을 때  $D$만의 확률분포(주변 확률 분포)를 아래와 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(D) = \\sum_{I}P(I,D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_marginalization.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let $\\mathbf{D}$ be a set of radom variables. We define a factor $\\phi$ to be a function from $Val(\\mathbf{D})$ to $\\mathbb{R}$. A factor is nonnegative if all its entries are nonnegative. The set of variables $\\mathbf{D}$ is called the scope of the factor and denoted $Scope[\\phi]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률분포를 찾는 것 혹은 이것들을 다루는데 있어서 중요한 building block 중 하나가 바로 factor이다.\n",
    "\n",
    "factor는 다수의 인자(argument, $X_1, \\dots , X_k$)를 받아 인자들의 각 경우에 따른 출력값을 내놓는 어떤 function이나 table이라 할 수 있다. 이 함수가 인자로 받는 값은 $X_1$에서 $X_k$까지 확률변수의 cross product space의 모든 값이고, $X_1, \\dots , X_k$를 이 factor의 scope이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Joint Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 다뤘던 $I$, $D$, $G$에 대한 결합확률분포 또한 $\\{X_1, \\dots , X_k\\}$를 scope으로 하는 factor라 할 수 있다. 이때 factor의 output이 확률분포를 나타내는데, 그것이 확률분포인지 아닌지는 그 함수가 factor인지 아닌지를 결정하는 것과 무관하다. 단지 scope의 모든 조합에 대해 output이 존재하는지가 중요할 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_joint_dist.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Unnormalizaed measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 아래와 같이 unnormalized measure를 output으로 내놓는 함수 또한 factor이다. 이 경우 변수 $G$는 상수값을 갖으므로 scope은 $\\{I, D\\}$이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_unnorm_dist.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: CPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 Conditional Probability Distribution(CPD)를 나타내는 factor가 있다. 아래예와 같이 $I$와 $D$의 모든 경우에 대한 $G$의 확률 분포를 나타내고 있다. 예를들어 Intelligence가 높고 Difficulty가 높은 과목을 수강하는 학생이 각각 $g^1$, $g^2$, $g^3$를 받을 확률은 0.5, 0.3, 0.2이고 그 값을 더해 1이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_cpd.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다고 모든 factor가 확률분포가 되는 것은 아니다. 아래와 같이 모든 출력값의 합이 1도 아니고 각 값이 0과 1 사이에 있지도 않은 경우도 $scope=\\{A, B\\}$의 모든 경우에 대해 실수값을 출력하므로 factor이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: General case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_general_factor.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor를 이용해 다른 Factor를 만드는 연산이 있는데      \n",
    "Factor Product, Factor Marginalization, Factor Reduction에 대해 알아보자.\n",
    "\n",
    "두개의 factor $\\phi_1(A,B)$와 $\\phi_2(B, C)$가 있을 때 Factor product는 아래 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_product.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor $\\phi(A, B, C)$에서 scope $B$를 marginalize out하기 위해 $B$의 모든 가능한 경우에 대해 factor값을 더한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_norm.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C$가 $c^1$라는 것을 관측한 상황에서 scope이 $\\{A, B\\}$인 새로운 factor를 아래와 같이 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_reduction.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Network Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantics & Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reasoning Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of Probabilistic Influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Networks: Independencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Independencies in Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Networks: Knowledge Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application - Medical Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Knowledge Engineering Example - SAMIAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
