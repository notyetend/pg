{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.coursera.org/learn/probabilistic-graphical-models-3-learning/home/week/1\n",
    "\n",
    "Probabilistic-Graphical Models - Learning - Week2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] Learning Undirected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2-1] Parameter Estimation in MNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-1-1] Maximum Likelihood for Log-Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난주에는 MLE에 대해서 그리고 MLE를 Bayesian Networks에 적용하는 것에 대해 알아봤었다. MLE를 BNs에 적용하는 경우 각 노드마다 MLE를 적용할 수 있었고 MLE에 대한 닫힌해를 구할 수도 있었다.      \n",
    "이번주에는 MLE를 Markov Network에 적용해볼 것이고, 특히 log-linear model을 사용하여 그 표현과 계산을 좀더 쉽게 할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 Markov Network로 아래와 같이 $A - B - C$로 연결되는 Undirected model을 살펴보자. 이때 데이터 인스턴스 $[a, b, c]$가 있다면 이 인스턴스가 관측될 확률은 아래와 같다.    \n",
    "(Markov Networks에 대해서는 text Ch 4.2.2를 참고하도록)  \n",
    "$$P(a, b, c) = \\frac{1}{Z(\\theta)} \\phi_1(a, b) \\cdot \\phi_2(b,c)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 $Z(\\theta)$는 Partition function으로서 $\\sum_{a,b,c}\\phi_1(a,b)~\\phi_2(b,c)$이며 $\\theta$에 관한 함수이다. (예를들어 $A, B, C$가 모두 이항변수라면 $\\phi_1$에서 $(A,B)$의 각 경우에 $\\theta_1, \\cdots, \\theta_4$가 대응되고, $\\phi_2$에서 $(B, C)$의 각 경우에 $\\theta_5, \\cdots, \\theta_8$이 대응된다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 $M$건의 $(A, B, C)$쌍을 관측 데이터가 주어졌을 때 $\\theta$에 대한 Likelihood는 아래와 같으며, log-likelihood로 바꾸고 factor $\\phi_1$과 $\\phi_2$의 각 cell에 해당하는 것들을 모아서 표현할수도 있다.(슬라이드 두번째 식)\n",
    "$$L(\\theta~:~\\mathcal{D}) = \\prod_m \\frac{1}{Z(\\theta)_m} \\phi_1(a[m],b[m]) \\cdot \\phi_2(b[m],c[m])$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\sum_{a,b} M[a,b] \\mathrm{ln}\\phi_1(a,b)$와 $\\sum_{b,c} M[b,c] \\mathrm{ln}\\phi_2(b,c)$까지만 있다면 각 factor에 대해 독립적인 계산이 될수 있을 것이다. 하지만 partition function $Z(\\theta)$이 포함되어 있어서 독립적인 계산이 불가하다. 즉 $\\phi_1$이 바뀌면 partition function이 바뀌고 $\\phi_2$도 바뀌게 된다. 또한 이 때문에 $\\theta$에 대한 닫힌해가 존재하지도 않는다. (MLE를 Bayesian Networks에 적용하는 경우 각 node마다 독립적인 MLE 계산이 가능하고 닫힌해가 존재했던 것과 상반되는 부분이다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_01.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 factor의 파라미터 값에 따라 log-likelihood 함수 값이 어떻게 변하는지 살펴보기 위해 $A, B, C$ 변수가 이항 변수라 가정하고, $(a^1, b^1)$과 $(b^0, c^1)$인 경우만 관찰하기 위해 factor를 아래와 같이 구성한다. 이때 관측 데이터가 100건이며 $M[a^1,b^1]=40$이고 $M[b^0, c^1]=40$일 때 log-likelihood를 살펴보자. ($\\phi_{1, 2}=1$이면 $\\mathrm{ln}\\phi_{1, 2} = 0$이므로 나머지 20건 데이터는 고려할 필요가 없음)\n",
    "$$l(\\theta_{a^1,b^1}, \\theta_{b^0,c^1} ~:~ \\mathcal{D})=40~\\mathrm{ln}\\theta_{a^1,b^1} + 40~\\mathrm{ln}\\theta_{b^0,c^1} - 100~\\mathrm{ln}Z(\\theta_{a^1,b^1}, \\theta_{b^0,c^1})\\\\\n",
    ", ~~ Z(\\theta_{a^1,b^1}, \\theta_{b^0,c^1})=2\\theta_{a^1,b^1} + 2\\theta_{b^0,c^1} + 4 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "A & B & \\phi_1 \\\\ \n",
    "\\hline\n",
    "a^1 & b^1 & \\theta_{a^1,b^1} \\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & 1 \\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & 1 \\\\ \n",
    "\\hline\n",
    "a^0 & b^0 & 1 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "B & C & \\phi_2 \\\\ \n",
    "\\hline\n",
    "b^1 & c^1 & 1 \\\\ \n",
    "\\hline\n",
    "b^1 & c^0 & 1 \\\\ \n",
    "\\hline\n",
    "b^0 & c^1 & \\theta_{b^0,c^1} \\\\ \n",
    "\\hline\n",
    "b^0 & c^0 & 1 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$l(\\theta_{a^1,b^1}, \\theta_{b^0,c^1} ~:~ \\mathcal{D})$를 그려보면 아래 그림과 같고,        \n",
    "단일 전역 최대값(single global optimum)이 존재하며       \n",
    "바닥면을 보면 $\\theta_{a^1,b^1}$와 $\\theta_{b^0,c^1}$가 서로 종속되어 log-likelihood 값이 같은 선이 만들어짐을 관찰할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_02.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 scope이 $\\{X_1, \\cdots, X_n\\}$이고     \n",
    "$k$개의 subgraph $D_1, \\cdots, D_k$로 구성되는 네트워크 $\\mathcal{H}$가 있을 때            \n",
    "Gibbs distribution $P(X_1, \\cdots, X_n ~:~ \\theta)$을 아래와 같은 log-linear model로 나타낼 수 있다.      \n",
    "(log-linear model에 관해서는 text ch 4.4.1.2를 참고 바람)    \n",
    "\n",
    "$$P(X_1, \\cdots, X_n ~:~ \\theta)=\\frac{1}{Z(\\theta)} ~ \\mathrm{exp} \\left\\{\\sum_{i=1}^k \\theta_i ~ f_i(D_i) \\right\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "A & B & \\phi_1(A,B) \\\\ \n",
    "\\hline\n",
    "a^1 & b^1 &  100\\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & 1 \\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & 1 \\\\ \n",
    "\\hline\n",
    "a^0 & b^0 & 100 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "B & C & \\phi_2(B,C) \\\\ \n",
    "\\hline\n",
    "b^1 & c^1 & 1 \\\\ \n",
    "\\hline\n",
    "b^1 & c^0 & 100 \\\\ \n",
    "\\hline\n",
    "b^0 & c^1 & 100 \\\\ \n",
    "\\hline\n",
    "b^0 & c^0 & 1 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 factor를 full table 형태로 표현하는 방법이 가장 기본적이지만, 위 두 factor와 같이 어떤 맥락 혹은 패턴(context-specific structure)이 존재하는 factor의 경우, factor를 log-space로 가져와 표현하는 것이 효과적일 때가 있다.\n",
    "\n",
    "우선 아래 두 factor $\\phi_1(A,B)$와 $\\phi_2(B,C)$에 대해 feature를 각각 아래와 같이 정의한다. \n",
    "$$f_1(A,B) = \\begin{cases} 1 & A=B \\\\ 0 & otherwise\n",
    "\\end{cases} \\\\\n",
    "f_2(B,C) = \\begin{cases} 1 & B<>C \\\\ 0 & otherwise\n",
    "\\end{cases} \\\\\n",
    "$$\n",
    "또한 weight은 각각 $\\theta_1 = \\theta_2 = \\ln 100$으로 두면, 아래의 energy function으로 표현된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "A & B & -\\theta_1 \\cdot f_1(A,B) \\\\ \n",
    "\\hline\n",
    "a^1 & b^1 &  -\\ln 100 \\cdot 1 = -4.61\\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & -\\ln 100 \\cdot 0 = 0\\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & 0\\\\ \n",
    "\\hline\n",
    "a^0 & b^0 & -4.61 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "B & C & -\\theta_2 \\cdot f_2(B,C) \\\\ \n",
    "\\hline\n",
    "b^1 & c^1 & 0 \\\\ \n",
    "\\hline\n",
    "b^1 & c^0 & -4.61 \\\\ \n",
    "\\hline\n",
    "b^0 & c^1 & -4.61 \\\\ \n",
    "\\hline\n",
    "b^0 & c^0 & 0 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 $P(A=a^1, B=b^1, C=c^1 ~:~ \\theta)$는 아래와 같이 계산할 수 있고\n",
    "$$\\begin{align}\n",
    "P(A=a^1, B=b^1, C=c^1:\\theta) &= \\frac{1}{Z} \\mathrm{exp}\\left\\{\\theta_1~f_1(a^1, b^1) ~ + ~ \\theta_2 ~ f_2(b^1, c^1)\\right\\}\\\\\n",
    "&= \\frac{1}{Z} \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 1 + \\ln 100 \\cdot 0\\right\\} \\\\\n",
    "&=\\frac{100}{Z}\n",
    "\\end{align}$$\n",
    "\n",
    "$\\tilde{P}(A,B,C)$와 $Z$는 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "A & B & C & \\tilde{P}(A,B,C) \\\\ \n",
    "\\hline\n",
    "a^1 & b^1 & c^1 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 1 + \\ln 100 \\cdot 0\\right\\} = 100\\\\ \n",
    "\\hline\n",
    "a^1 & b^1 & c^0 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 1 + \\ln 100 \\cdot 1\\right\\} = 100^2\\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & c^1 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 0 + \\ln 100 \\cdot 1\\right\\} =100\\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & c^0 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 0 + \\ln 100 \\cdot 0\\right\\} =1\\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & c^1 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 0 + \\ln 100 \\cdot 0\\right\\} =1\\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & c^0 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 0 + \\ln 100 \\cdot 1\\right\\} =100\\\\ \n",
    "\\hline\n",
    "a^0 & b^0 & c^1 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 1 + \\ln 100 \\cdot 1\\right\\} =100^2\\\\ \n",
    "\\hline\n",
    "a^0 & b^0 & c^0 & \\mathrm{exp} \\left\\{ \\ln 100 \\cdot 1 + \\ln 100 \\cdot 0\\right\\} =100\\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "Z &= \\sum_{x} \\exp \\left\\{ \\sum_i \\theta_i f_i(\\mathbf{x}) \\right\\} \\\\\n",
    "&= \\sum_{A,B,C} \\exp \\left\\{ \\theta_1 f_1(A,B) + \\theta_2 f_2(B,C) \\right\\} \\\\\n",
    "&= \\exp(\\ln100) + \\exp(\\ln100 + \\ln 100) + \\exp(\\ln 100) + \\exp(0) + \\exp(0) + \\exp(\\ln 100) + \\exp(\\ln 100 + \\ln 100) + \\exp(\\ln 100)\n",
    "&= 100 + 100^2 + 100 + 1 + 1 + 100 + 100^2 + 100 \\\\\n",
    "&= 20402\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 weight을 변수로 그냥 두면...   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "Z &= \\sum_x \\mathrm{exp} \\left\\{ \\sum_i \\theta_i f_i(\\mathbf{x}) \\right\\} \\\\\n",
    "&= \\mathrm{exp}\\theta_1 + \\mathrm{exp}(\\theta_1 + \\theta_2) + \\mathrm{exp}\\theta_2 + 1 + 1 + \\mathrm{exp}\\theta_2 + \\mathrm{exp}(\\theta_1 + \\theta_2) + \\mathrm{exp}\\theta_1 \\\\\n",
    "&= 2\\exp \\theta_1 + 2 \\exp(\\theta_1 + \\theta_2) + 2\\exp \\theta_2 + 2\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지의 논의는 scope내 확률 분포에 대한 것이었고, 이제 **likelihood**를 살펴보자.\n",
    "\n",
    "\n",
    "log-likelihood는 sample size가 $M$이라 하면, $M$건의 데이터에 대해 $P(X_1, \\cdots, X_n ~:~ \\theta)$들을 곱하고 log를 취하면 아래와 같아진다. ($D$는 factor의 scope이고  $\\mathcal{D}$는 data 임에 주의)\n",
    "$$l(\\theta:\\mathcal{D}) = \\sum_i \\theta_i \\left( \\sum_m f_i (\\mathbf{x}[m]) \\right) - M ~\\mathrm{ln}Z(\\theta)$$\n",
    "\n",
    "또한 유의할 점은 $P(X_1, \\cdots, X_n ~:~ \\theta)$의 계산에서 feature $f_i$의 argument는 $D_i$로서 해당 feature에 사용되는 변수들이 주어지지만, likelihood 계산에서 feature f_i의 argument는 $\\mathbf{x}[m]$으로서 전체 scope의 변수가 argument로 주어진다. 이는 단지 표기를 간단히 하기 위함으로서 실제로는 해당 feature $f_i$가 사용하지 않는 변수는 무시된다. 예를들어 전체 그래프의 scope이 $A,B,C$라도 $f_i$이 $A, B$만 사용하는 feature라면 $f_i(a, b, c)$는 $f_i(a, b)$와 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식에서 $\\theta_i$는 각 feature(=factor)에 대한 가중치이고, $f_i(\\mathbf{x}[m])$는 $m$번째 data sample에 대한 feature function 값이다. 또한 $\\mathrm{ln}Z(\\theta)$ 계산에서 $i$는 각 factor에 대한 index이고, $\\sum_{\\mathrm{x}}$는 factor내 전체 space(위 예에서는 8개)에 대한 합이며, $\\sum_i \\theta_i ~ f_i(\\mathbf{x})$는 해당 factor값들에 $-\\mathrm{log}$를 취한 값들의 합과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 아래와 같은 4건의 데이터가 관측되었다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{array}{rr}\n",
    "\\hline\n",
    "A & B & C \\\\ \n",
    "\\hline\n",
    "a^1 & b^1 & c^1 \\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & c^1 \\\\ \n",
    "\\hline\n",
    "a^1 & b^0 & c^1 \\\\ \n",
    "\\hline\n",
    "a^0 & b^1 & c^1 \\\\ \n",
    "\\hline\n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 likelihood는 아래와 같다.\n",
    "$$\\begin{align}\n",
    "L(\\theta:\\mathcal{D}) &= P(a^1, b^1, c^1)\\cdot P(a^1, b^0, c^1)\\cdot P(a^1, b^0, c^1)\\cdot P(a^0, b^1, c^1) \\\\\n",
    "&=\\frac{1}{Z}\\mathrm{exp}\\{\\theta_1 \\cdot 1 + \\theta_2 \\cdot 1 \\} \\\\\n",
    "&~~~~~ \\cdot \\frac{1}{Z}\\mathrm{exp}\\{\\theta_1 \\cdot 0 + \\theta_2 \\cdot 1 \\} \\\\\n",
    "&~~~~~ \\cdot \\frac{1}{Z}\\mathrm{exp}\\{\\theta_1 \\cdot 0 + \\theta_2\\cdot 1 \\} \\\\\n",
    "&~~~~~ \\cdot \\frac{1}{Z}\\mathrm{exp}\\{\\theta_1 \\cdot 0 + \\theta_2\\cdot 0 \\} \\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-likelihood는 아래와 같다.\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "l(\\theta:\\mathcal{D}) &= \\sum_i \\theta_i \\left( \\sum_m f_i (\\mathbf{x}[m]) \\right) - M ~\\mathrm{ln}Z(\\theta) \\\\\n",
    "&= \\theta_1 \\cdot \\{f_1(a^1, b^1) + f_1(a^1, b^0) + f_1(a^1, b^0) + f_1(a^0, b^1) \\} + \\theta_2 \\cdot \\{f_2(b^1, c^1) + f_2(b^0, c^1) + f_2(b^0, c^1) + f_2(b^1, c^1) \\} - 4~\\mathrm{log}Z\\\\\n",
    "&= \\theta_1 \\cdot (1+0+0+1) + \\theta_2 \\cdot (1+1+1+0) - 4~\\mathrm{log} (2\\exp \\theta_1 + 2 \\exp(\\theta_1 + \\theta_2) + 2\\exp \\theta_2 + 2)\\\\\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_03.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 log-partition function $Z$가 어떤 의미를 갖는지 살펴보자.    \n",
    "$\\ln Z(\\theta)$는 $\\theta_1, \\cdot, \\theta_k$에 관한 함수이므로      \n",
    "$\\frac{\\partial}{\\partial \\theta_i} \\ln Z(\\theta)$는 1차 도함수들의 vector이고 각 원소는 분포 $P(X_1, \\cdots, X_n : \\theta)$에 대한 $f_i$의 기댓값 $\\mathbf{E}_{\\theta}[f_i]$이다.\n",
    "\n",
    "또한 2차 도함수 $\\frac{\\partial^2 }{\\partial \\theta_i \\partial \\theta_j} \\ln Z(\\theta)$는 $P(X_1, \\cdots, X_n : \\theta)$에 대한 $f_i$와 $f_j$사이의 공분산 행렬 $\\mathrm{C}ov_\\theta[f_i;f_j]$ 이며 Hessian이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/image.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 log-likelihood에서 첫번째 항은 $\\theta_i$에 대한 선형함수이고, $Z(\\theta)$는 그것의 2차도함수가 공분산행렬이므로 또한 공분산 행렬은 항상 positive semifefinite이므로 $Z(\\theta)$는 convex function이다. 따라서 $(-\\ln Z(\\theta))$는 concave이다.\n",
    "$$l(\\theta:\\mathcal{D}) = \\sum_i \\theta_i \\left( \\sum_m f_i (\\mathbf{x}[m]) \\right) - M ~\\mathrm{ln}Z(\\theta)$$\n",
    "선형함수와 concave 함수의 합은 concave이므로 $l(\\theta:\\mathcal{D})$또한 concave이다.\n",
    "\n",
    "따라서 log-likelihood는 unimodal이므로 local optima는 존재하지 않고 항상 유일한 global optimum이 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_05.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log-likelihood 가 concave 함수이므로, 그 값이 최대가되는 지점에서 항상 gradient는 0이 된다. 'average log-likelihood'의 gradient는 아래와 같다.\n",
    "$$\\frac{\\partial}{\\partial \\theta_i}\\frac{1}{M} l (\\theta:\\mathcal{D}) = \\frac{1}{M}\\sum_m f_i(\\mathbf{x}[m])) - \\frac{\\partial}{\\partial \\theta_i} \\ln Z(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 첫번째 항은 $f_i$에 대한 경험적 기댓값(emphirical expectation) 혹은 해당 데이터 $\\mathcal{D}$내 $f_i$의 발생빈도 $\\mathbf{E}_{\\mathcal{D}}[f_i(\\mathbf{X})]$를 의미하고, 두번째 항은 앞서 알아본 것과 같이 분포 $P(X_1, \\cdots, X_n : \\theta)$에 대한 $f_i$의 기댓값 $\\mathbf{E}_{\\theta}[f_i]$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 gradient가 0이 되기 위해서는 두 항 $\\mathbf{E}_{\\mathcal{D}}[f_i(\\mathbf{X})]$, $\\mathbf{E}_{\\theta}[f_i]$이 모든 $i$에 대해 같아야 한다. 이러한 등식의 비교를 **moment matching**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_06.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 $l(\\theta:\\mathcal{D})$를 최대화 하는 $\\theta$를 찾아야 하는데,    \n",
    "이에 대한 해석적 해(analytical solution)는 존재하지 않는다. 따라서 Gradient Ascent와 같은 반복적인 방법(iterative method)을 사용할 수 밖에 없다.\n",
    "\n",
    "가장 초적인 gradient ascent 알고리즘은 아래와 같다.\n",
    "> 1. Set $\\theta$ to some initial value\n",
    "2. For $t=1, \\cdots, T$:\n",
    " - For $j=1, \\cdots, d:$ set $\\theta_j^t = \\theta_j^{t-1} + \\alpha_t \\times \\frac{\\partial}{\\partial \\theta_j} L(\\theta^{t-1})$,       \n",
    " ($\\alpha_t$ : learning rate)\n",
    "\n",
    "그런데 매 gradient 단계마다 아래 두개의 기댓값을 구해야하는데\n",
    " - empirical count in the data: $\\mathbf{E}_{\\mathcal{D}}[f_i(\\mathbf{X})]$\n",
    " - expected count relative to current $\\theta$: $\\mathbf{E}_{\\theta}[f_i]$       \n",
    "두번째 기댓값을 구하기 위해서는 $P_{\\theta^t}(a,b)$형태의 확률을 구해야 하고 이는 전체 네트워크에 대한 추론이 필요한 것이다. 물론 PGM의 복잡도에 따라 달라지기는 하지만 Markov network에서의 추론은 Bayesian network에서의 MLE에 비해 계산 비용이 상당히 높은 수준이다. \n",
    "\n",
    "실제 추론 계산에는 보다 계산 효율이 좋은 방법으로,    \n",
    "gradient ascent의 변형인 L-BFGS(quasi Newton method) 같은 방법을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_07.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Ising model에 대한 배경 설명은 text p126을 참고 바람)    \n",
    "\n",
    "Ising model에서 energy function은 아래와 같은데\n",
    "$$E(x_1, \\cdots, x_n) = -\\sum_{i<j} w_{i, j} x_i x_j - \\sum_i u_i x_i$$\n",
    "\n",
    "여기서 추정해야하는 모수는 $w_{i,j}$와 $u_i$이다. $w_{i,j}$는 두 인접한 원자의 회전 방향이 같으면 양의 값을 갖고 그렇지 않을 경우 음의 값을 갖는다. 반면 $u_i$는 해당 원자 $x_i$가 (선택된) 양의 방향으로 회전하면 양의 값을 갖고 그렇지 않으면 음의 값을 갖는다. \n",
    "\n",
    "두 모수에 대한 gradient는 각각 앞서 등장했던 아래 gradient와 같이 계산된다.\n",
    "$$\\frac{\\partial}{\\partial \\theta_i} \\frac{1}{M} l(\\theta:\\mathcal{D}) = \\mathbf{E}_{\\mathcal{D}}[f_i(\\mathbf{X})] - \\mathbf{E}_{\\theta}[f_i]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_08.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Undirected graphical model에서는 (directed graphical model과 달리) partition function $Z(\\theta)$가 전체 parameter들에 얽혀 있다. 따라서 max-likelihood를 $D_i$별로 독립적인 계산할 수 없다.\n",
    "\n",
    "- max-log-likelihood에 대한 닫힌해가 존재하지 않는다. 하지만 log-likelihood 함수가 convex이므로 convex optimization 방법을 사용할 수 있고, global optimum이 항상 존재한다. 이를 위해 gradient ascent와 같은 iterative method를 사용해야 하며 보통 L-BFGS를 사용한다.\n",
    "\n",
    "- 하지만 iterative method에서 매 반복 단계에서 전체 네트워크에 대한 기댓값 계산이 필요한 문제가 있다.\n",
    "\n",
    "- ???\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/531_09.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-1-2] Maximum Likelihood for Conditional Random Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고자료: \n",
    "https://people.cs.umass.edu/~mccallum/papers/crf-tutorial.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 MRFs(Markov Random Fields)에서의 MLE에 대해 알아봤었다. 이런 논의가 (MRFs의 변형이라 할 수 있는) CRFs(Conditional Random Fields)에는 어떻게 적용될 수 있는지 알아보도록 하자. (CRF에 대해서는 text 4.6.1 참고 바람)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRFs에서는 $P(\\mathbf{Y}, \\mathbf{X})$에 관심이 있었다. 반면 CRFs에서는 어떤 관측 데이터 $\\mathbf{x}$가 주어졌을 때 미지의 변수들 $\\mathbf{Y}$의 확률 분포, $P(\\mathbf{Y} ~|~ \\mathbf{x})$를 알고자 한다. \n",
    "\n",
    "관측 변수 $x$가 주어졌을 때, 관찰하고자 하는 변수 $Y$의 확률 분포는 아래와 같다. \n",
    "$$\\begin{align}\n",
    "P_{\\theta}(\\mathbf{Y}|\\mathbf{x}) &= \\frac{1}{Z_{\\mathbf{x}}(\\theta)} \\tilde{P}_{\\theta}(\\mathbf{x}, \\mathbf{Y}) \\\\\n",
    "\\tilde{P}(\\mathbf{Y},\\mathbf{x}) &= \\prod_{i=1}^m \\phi_i(\\mathbf{D}_i), ~ \\mathbf{D}_i \\nsubseteq \\mathbf{X}\\\\\n",
    "Z_{\\mathbf{x}}(\\theta) &= \\sum_\\mathbf{Y} \\tilde{P}(\\mathbf{x}, \\mathbf{Y}) \n",
    "\\end{align}$$\n",
    "\n",
    "위 두번째 식에서 $\\mathbf{D}_i \\nsubseteq \\mathbf{X}$라는 조건이 있는데, 이는 CRF에서는 분포를 표현함에 있어 $\\mathbf{X}$ 들만을 포함하는 factor가 사용되지 않는다는 것을 말한다. 이는 CRF의 중요한 장점이라 할 수 있는데, 모형에 포함되어야 하는 **관측된** 변수이지만 분포 표현이 복잡하거나,  종속관계가 명확하지 않거나, 간단한 모수적 분포로 표현되지 않는 연속형 변수도 모형에 포함시킬 수 있다는 것이다. (이런 다루기 어려운 관측변수를 조건부($\\mathbf{X}$)에 넣어버리면 결합확률분포를 고민할 필요가 없기 때문).. (Text p144 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "X = np.array([1, 2, 3, 10, 11, 12]); X.shape = (6, 1)\n",
    "Y = [0, 0, 0, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coef :  [[ 2.4507514]] , intercept:  [-15.4046607]\n"
     ]
    }
   ],
   "source": [
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "logreg.fit(X, Y)\n",
    "print(\"coef : \", logreg.coef_, \", intercept: \", logreg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(np.array([2]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추론하고자 하는 $Y$에 대한 확률 분포는 위와 같고,    \n",
    "추론에 사용하는 데이터는 $\\mathcal{D} = \\{(x[m], y[m])\\}_{m=1}^M$와 같이 $M$개의 $x[m], y[m])$쌍으로 주어진다. \n",
    "\n",
    "이 데이터에 대한 'log conditional likelihood'는 아래와 같다.\n",
    "$$l_{Y|X}(\\theta : \\mathcal{D}) = \\sum_{m=1}^M \\ln P_{\\theta}(y[m] ~|~ x[m], \\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>특정 데이터 인스턴스에 대한</u> 'log conditional likelihood'를 log-linear model로 표현하면 아래와 같다.\n",
    "$$l_{Y|X}( \\theta ~:~ (x[m], y[m]) ) = \\left( \\sum_i \\theta_i ~ f_i (x[m], y[m])\\right) - \\ln Z_{x[m]}(\\theta)$$\n",
    "위 식에서 $\\sum_i \\theta_i ~ f_i (x[m], y[m])$는 MRF에서의 그것과 같고, $\\ln Z_{x[m]}(\\theta)$는 $x[m]$에 대한 조건부 분포에수 구하는 값이라는 것이 MRF에서와 다르다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 전체 데이터 $\\mathcal{D}$에 대한 'log conditional likelihood'의 $\\theta_i$에 대한 1차 편미분을 구할 수 있으며, 첫번째 항은 emperical expectation, 두번째 항은 model based expectation이라 할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/532_01.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/532_02.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/532_03.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/532_04.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/532_05.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2-1-3] MAP Estimation for MRFs and CRFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/533_01.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/533_02.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/533_03.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/533_04.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
