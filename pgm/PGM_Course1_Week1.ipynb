{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Introduction and Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Graphical Model이 뭔지 알기 위해       \n",
    "우선 이것이 쓰일만한 예를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번 째 예로 의사가 환자를 진찰하는 상황은 그 환자에 대한 여러 요인, 증상, 검사결과가 주어졌을 때 이 환자의 질병이 무엇인지 또는 어떤 처치에 대한 결과가 어떨지를 찾아내려는 것이다.        \n",
    "\n",
    "또 다른 예로 이런 그림이 주어져 있을 때 각 pixel 혹은 그림의 조각들이 각각 어떤 사물(grass, sky, cow, horse) 을 나타내는지 알아내는 문제를 생각해볼 수 있다.\n",
    "\n",
    "이 두가지 예의 공통점은 무엇일까? 우선 두 문제 모두 추론해야 하는 대단히 많은 변수들이 있다는 점이다. 두번째 공통점은 이런 문제의 정답이 불확실하다는 점이고, PGM은 이런 문제를 다루기 위한 framework라고 할 수 있다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/111_ex1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic Graphical <u>Model</u> \n",
    "\n",
    "모형은 어떤 상황을 구성하는 변수들이 무엇이고 이들이 서로 어떤 상호작용을 하는지를 나타내는 선언적 표현(declarative representation)이라 할 수 있다. 여기서 선언적(declarative)라는 표현을 쓴 것은 모형이 알고리즘 혹은 모형을 학습시키는 것과 독립적이라서 그 자체로 의미가 있다는 것이다.   \n",
    "\n",
    "모형이 그 자체로 의미를 갖는 다는 것은 몇가지 장점을 갖는데 우선 하나의 모형이 주어졌을 때 이 모형을 기반으로 해당 상황을 풀 수 있는 다양한 알고리이 존재할 수 있다는 것을 의미한다. 즉 어떤 알고리즘은 정확도가 높은 장점이 있고 다른 알고리즘은 설명력이 높은 장점이 있을 수 있고 혹은 정확도와 설명력이 적절히 균형작힌 알고리즘을 사용할 수도 있다는 것이다.\n",
    "\n",
    "또 다른 장점은 알고리즘과 독립적으로 모형을 만들 수 있다는 것인데, 어떤 업에 대한 전문가의 노하우 혹은 통계적 기계학습 방법을 이용한 지식 혹은 이 둘을 결합한 모형을 만들 수 있게 되는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/111_model1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Probabilistic</u> Graphical Model\n",
    "\n",
    "이는 PGM이 많은 불확실성(uncertainty)를 모형화하기 위해 사용되기 때문이다.     \n",
    "그렇다면 불확실성의 원인은 무엇일까?     \n",
    "- Partial knowledge of state of the world: 예를들어 의사는 환자에 대한 모든 증상을 알 수는 없는 상황 때문에 그 환자의 질병을 정확히 진단할 수 없다.\n",
    "- Noisy observations: 예를들어 환자의 혈압을 측정할 수 있지만 이런 측정 결과 또한 알수 없는 여러 요인에 의해 측정할 때마다 다른 값을 얻게 된다.\n",
    "- Phenomena not covered by our model: 가능한 모든 상황을 모형에 포함시킬수는 없는  한계(modeling limitations) 때문에 불확실성이 나타나기도 한다. 예를들어 우리 모형에 포함되어 있지 않은 (아주 드문 혹은 고려 대상이 아닌) 질병이 환자의 증상을 유발했을 수도 있다. \n",
    "- Inherent stochasticity: 세상은 원래 불확실성으로 가득차 있을지도 모를 일이다.  이때문에 알수 없는 많은 것들이 작은 원인이 되어 서로 영향을 주고 받고, 결국 우리는 이 모든 것을 모형에 포함시킬 수 없게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률론은 이런 불확실성을 다룰 수 있게 해 주는       \n",
    "어떤 원칙과 도구들을 제공하는 틀(framework)이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probabilistic Graphical Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 Probabilistic Graphical Model을 이용해 세상의 어떤 상태에 대한 선언적 모형을 만들 수 있고 그 현상에 대한 불확실성을 확률분포로 표현하게 된다. 또한 이 모형을 이용해 다양한 근거가 주어졌을 때 미지의 상태에 대한 추론이 가능하게 된다.\n",
    "\n",
    "또한 PGM은 확률론 및 통계 이론에 근간에 두고 있기 때문에 이미 연구된 통계적 학습방법의 다양한 학습 기법들을 사용하여 PGM의 모형들을 학습시킬 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probabilistic <u>Graphical</u> Model \n",
    "\n",
    "PGM은 불확실성을 다루는 확률론의 아이디어와 많은 원인이 포함된 문제를 **연결**로 표현하는 아이디어가 혼합된 것이라서, Graphical 이란 단어에는 현상을 모형화하는 CS의 관점이 반영된 것이라 할 수 있다.\n",
    "\n",
    "앞서 의사의 진단 문제와 그림을 판별하는 문제에서와 같이 많은 변수를 포함하는 문제는      \n",
    "각각 continuous, categorical 혹은 binary일 수 있는 확률변수들(random variables) $X_1, X_2, \\dots X_n$에 대한        \n",
    "결합 확률 분포(joint probability distribution) $P(X_1, X_2, \\dots X_n)$를 추론하는 것이 그 핵심이다. \n",
    "\n",
    "예를들어 $n$개의 확률변수가 모두 이항변수일 경우, $2^n$개의 가능한 상황이 있기 때문에 이 모든 상황에 대한 확률을 알아내는 것은 쉬운 일이 아니다. 이를 보다 쉽게 다루기 위해 우리는 Probabilistic Graphical Model이라는 방법을 사용할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGM은 크게 Bayesian networks와 Markov networks로 나눌 수 있는데,     \n",
    "아래 그림은 아주 간단한 Bayesian network이다.\n",
    "\n",
    "그림은 node(원)과 directed edge(선)로 구성되는데,          \n",
    "각 node는 확률변수(random variable) $X_i$를 나타내고      \n",
    "edge는 변수간의 확률적 연결(probabilistic connections)를 나타낸다.\n",
    "\n",
    "아래 예는 어떤 학생이 어떤 과목에서 어떤 학점(Letter)을 받을지를 bayesian network로 모형화 한 것이다. 이때 학생이 받을 학점은 확률변수라 할 수 있고, 이에 영향을 줄 수 있는 Difficulty, Intelligence, Grade, SAT라는 다른 확률변수들도 모형에 포함되어 있다.\n",
    "\n",
    "얼핏 보기에 과목의 난이도와 학생의 지적 능력이 해당 과목의 시험 점수에 영향을 주고 이것이 학점에 영향을 주며, 또한 학생의 지적 능력은 그 학생의 SAT 성적에도 영향을 주는 것으로 보인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_bayes_net.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 제시된 다른 종류의 PGM은 Markov network이다.      \n",
    "앞서 bayesian network와 다른 점은 undirected connection을 사용한다는 점 이다.\n",
    "\n",
    "아래 예에서는 A, B, C, D 4개의 확률변수가 undirected graph를 구성하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_markov_net.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 두 graphical model은 아주 간단한 예이고,    \n",
    "실제 사용되는 Bayesian network 모형은 아래 왼쪽과 같이 복잡할 수 있다. 이 모형은 Computer-based Patient Case Simulation system, CPCS라 불리며 480개의 node와 900개 이상의 edge로 구성되어 환자 진단을 모형화 한 것이다. \n",
    "\n",
    "아래 우측의 예는 image segmentation에 사용되는 Markov network로서 각 확률변수는 pixel 혹은 superpixel들의 label을 나타낸다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_01_cpcs.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Graphical Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결론적으로 PGM은 고차원 확률분포로 이루어진 데이터의 구조를 직관적이고 간략하게 표현하는데 사용된다. 또한 확률적 머신 러닝의 다양한 알고리즘을 이용해 추론이 가능하며 변수들간의 관계를 이용해 더 작은 변수를 이용해 각 상태를 표현할 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Course overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Representation\n",
    " - Directed and undirected\n",
    " - Temporal and plate models\n",
    "- Inference(Reasoning)\n",
    " - Exact and approximate\n",
    " - Decision making\n",
    "- Learning\n",
    " - Parameters and structure\n",
    " - With and without complete data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 2.1.1 to 2.1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PGM에 대해 본격적으로 알아보기에 앞서       \n",
    "확률분포(probability distribution)가 무엇인지 간단한 예를 통해 리뷰하도록 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Joint  Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 학생의 지적능력의 높고 낮음(high / low)을 나타내는 확률변수 intelligence, 특정 과목의 난이도의 높고 낮음(high / low)을 표현하는 확률변수 difficulty, 학생의 성적(A, B, C)을 나타내는 확률변수 grade라는 3개의 확률변수가 있고, 이 3개 확률변수의 joint probability distribution을 생각해보자.\n",
    "\n",
    "이 3개의 확률변수의 가능한 모든 조합의 수는 2 * 2 * 3의 12가지이고 각 경우에 대한 확률을 결정해야한다. \n",
    "\n",
    "아래 표에 12가지 경우가 모두 나열되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_joint_dist1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률 분포를 가정하기 때문에 Prob의 모든 값을 더하면 1이 되어야 한다. 따라서 12개의 확률 값 중 11개를 알고 있다면 나머지 하나의 값 또한 알 수 있다. 따라서 위 확률 분포에서 독립적인 파라미터의 수는 11개이다.(자유도, degree of freedom, the number of independent parameters), 이 자유도라는 개념은 나중에 서로 다른 확률 분포의 상대적 설명력을 평가할때 사용될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Conditioning & Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률분포를 이용해 할 수 있는 것 중 하나가 **Conditioning & Reduction**인데,  \n",
    "예를들어 3개의 확률 변수중 학생의 Grade가 $g^1$라는 것을 알게 되었다고 하자. 이때 3확률변수에 대한 확률 분포($P(I, D ~|~ G=g^1)$)는 어떠할까? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_conditioning1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 표와 같이 $G$가 $g^1$이 아닌 경우는 모두 관측치($G=g^1$)에 부합하지 않으므로 확률이 0이라는 것이 자명해 지고 아래와 같은 새로운 확률 분포 $P(I, D ~|~ G=g^1)$를 얻게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_conditioning2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이를 확률 분포로 만들기 위해 아래와 같이 전체의 합으로 각 값들을 나눠주는데 이를 **re-normalization**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_renormalization1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Probability: Marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음으로 다수 확률변수들의 결합확률분포가 있을 때, 일부 확률변수들만의 결합확률분포를 구하는 것을 **marginalization**이라 한다. 앞서 예와 같이 전체 $I$와 $D$ 2개의 확률변수가 주어져 있을 때  $D$만의 확률분포(주변 확률 분포)를 아래와 같이 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(D) = \\sum_{I}P(I,D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_02_marginalization.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3. Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 4.2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let $\\mathbf{D}$ be a set of radom variables. We define a factor $\\phi$ to be a function from $Val(\\mathbf{D})$ to $\\mathbb{R}$. A factor is nonnegative if all its entries are nonnegative. The set of variables $\\mathbf{D}$ is called the scope of the factor and denoted $Scope[\\phi]$.(Definition 4.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "확률분포를 찾는 것 혹은 이것들을 다루는데 있어서 중요한 building block 중 하나가 바로 factor이다.\n",
    "\n",
    "factor는 다수의 인자(argument, $X_1, \\dots , X_k$)를 받아 인자들의 각 경우에 따른 출력값을 내놓는 어떤 function이나 table이라 할 수 있다. 이 함수가 인자로 받는 값은 $X_1$에서 $X_k$까지 확률변수의 cross product space의 모든 값이고, $X_1, \\dots , X_k$를 이 factor의 scope이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Joint Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 다뤘던 $I$, $D$, $G$에 대한 결합확률분포 또한 $\\{X_1, \\dots , X_k\\}$를 scope으로 하는 factor라 할 수 있다. 이때 factor의 output이 확률분포를 나타내는데, 그것이 확률분포인지 아닌지는 그 함수가 factor인지 아닌지를 결정하는 것과 무관하다. 단지 scope의 모든 조합에 대해 output이 존재하는지가 중요할 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_joint_dist.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Unnormalizaed measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 아래와 같이 unnormalized measure를 output으로 내놓는 함수 또한 factor이다. 이 경우 변수 $G$는 상수값을 갖으므로 scope은 $\\{I, D\\}$이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_unnorm_dist.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: CPD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 Conditional Probability Distribution(CPD)를 나타내는 factor가 있다. 아래예와 같이 $I$와 $D$의 모든 경우에 대한 $G$의 확률 분포를 나타내고 있다. 예를들어 Intelligence가 높고 Difficulty가 높은 과목을 수강하는 학생이 각각 $g^1$, $g^2$, $g^3$를 받을 확률은 0.5, 0.3, 0.2이고 그 값을 더해 1이 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_cpd.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다고 모든 factor가 확률분포가 되는 것은 아니다. 아래와 같이 모든 출력값의 합이 1도 아니고 각 값이 0과 1 사이에 있지도 않은 경우도 $scope=\\{A, B\\}$의 모든 경우에 대해 실수값을 출력하므로 factor이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: General case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_general_factor.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor를 이용해 다른 Factor를 만드는 연산이 있는데      \n",
    "Factor Product, Factor Marginalization, Factor Reduction에 대해 알아보자.\n",
    "\n",
    "두개의 factor $\\phi_1(A,B)$와 $\\phi_2(B, C)$가 있을 때 Factor product는 아래 그림과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_product.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Marginalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor $\\phi(A, B, C)$에서 scope $B$를 marginalize out하기 위해 $B$의 모든 가능한 경우에 대해 factor값을 더한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_norm.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factors: Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C$가 $c^1$라는 것을 관측한 상황에서 scope이 $\\{A, B\\}$인 새로운 factor를 아래와 같이 얻을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/01_01_03_factor_reduction.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Bayesian Network Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Semantics & Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapters 3.2.1, 3.2.2. If you are unfamiliar with genetic inheritance, please watch this short <a href='http://www.khanacademy.org/video/introduction-to-heredity'>Khan Academy video</a> for some background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Student example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 앞으로 사용하게될 예제 하나를 살펴보자.   \n",
    "\n",
    "학생이 어떤 수업을 수강했을 때 어떤 학점과 추천서를 받게 될지에 대한 것으로     \n",
    "\n",
    "수강후 받게 될 학점(Grade)를 확률변수(random variable) $G$, 강의의 난이도(Difficulty)를 $D$, 학생의 지적능력(Intelligence)를 $I$, 학생의 SAT점수를 $S$, 받게될 추천서(Referene Letter)의 quality를 $L$이라 하자.    \n",
    "\n",
    "문제를 간단하게 만들기 위해 $G \\in \\{ A, B, C\\}$를 제외하고는 모두 binary variable라고 가정하자.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExampleGDISL.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 5개 변수들의 관계는 (아마도) 강의의 난이도와 학생의 지적능력이 학점을 결정하고      \n",
    "(단순하게 생각하여) 학점에 의해 추천서가 결정되며, SAT 점수는 (다른 변수와는 무관하게) 학생의 지적능력에만 영향을 받을 것이다.     \n",
    "이런 관계를 아래와 같은 graph로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExample.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 graph를 probability distribution으로 나타내보자.    \n",
    "\n",
    "우선 각 node에 대한 CPD를 아래와 같이 만들어볼 수 있다.    \n",
    "$P(D)$와 $P(I)$의 경우 degenerate form으로서 unconditional probability distribution이고, 다른 factor들은 모두 conditional probability distribution이다. 또한 각 table의 row의 합이 1임을 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExample_cpd.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5개의 CPD를 이용해 전체 graph에 대한 joint probability distribution을 아래와 같이 표현할 수 있다.    \n",
    "즉 각 node의 CPD를 모두 곱하면 모든 node에 대한 joint probability distribution를 얻게 된다. 이렇게 되는 것은 BN chain rule에 의해 설명되는 부분인데, 실제 각 곱은 앞서 다뤘던 factor product이고 그 결과 또한 (scope이 $\\{D, I, G, S, L\\}$인) factor이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExample_joint.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시로 $P(d^0, i^1, g^3, s^1, l^1)$을 구해보면 아래와 같다.   \n",
    "$$\\begin{align}P(d^0, i^1, g^3, s^1, l^1) &= \n",
    "P(d^0) ~ \n",
    "P(i^1) ~ \n",
    "P(g^3 ~ | ~ d^0, i^1) ~ \n",
    "P(s^1 ~ | ~ i^1) ~ \n",
    "P(l^1 ~ | ~ g^3)\\\\\n",
    "&= 0.6 \\cdot 0.3 \\cdot 0.02 \\cdot 0.8 \\cdot 0.01\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExample_joint_ex.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bayesian Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian Network의 정의는?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각 node가 확률변수 $X_1, \\dots , X_n$를 나타내는      \n",
    "directed acyclic graph(DAG) $\\mathcal{G}$를 **Bayesian Network**(BN)라한다.(Definition 3.1)          \n",
    "(acylic이므로 시작점으로 다시 돌아가는 것, 순환, cycle이 없음)      \n",
    "\n",
    "\n",
    "- 각 **node**는 확률변수 $X_i$를 나타내며 **factor(CPD)**이다.   \n",
    "\n",
    "\n",
    "- 전체 Bayesian network $\\mathcal{G}$은 **BN chain rule**을 통해 어떤 **joint distribution** $P(X_1, ... , X_n)$을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BN Is a Legal Distribution?: $P \\geq 0$, $\\sum{P}=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN graph가 나타내는 joint distribution $P(X_1, ... , X_n)$가 과연 확률분포인가?\n",
    "\n",
    "우선 $P \\geq 0$인가?     \n",
    "$P(X_1, ... , X_n)$은 factor들의 곱인데, 각 factor들은 non-negative이므로 그 곱 또한 non-negative이다.\n",
    "\n",
    "다음으로 $\\sum{P}=1$인가?   \n",
    "앞서 student example을 이용해 과연 그런지 확인해봐자.     \n",
    "이를 위해 $P(D, I, G, S, L)$의 모든 가능한 경우의 확률을 더해보자.   \n",
    "(eq1) BN chain rule을 이용해 첫번째 식과 같이 factorize할 수 있고    \n",
    "(eq2) $L$에 대한 합을 안쪽으로 집어넣으면 $\\sum_{L}P(L~|~G)$는 1이 되며 사라진다.(eq3)     \n",
    "$~~~~$ ($G$가 어떤 값이더라도 factor $L$의 각 행을 더하면 1)     \n",
    "(eq4) $S$에 대한 합을 안쪽으로 집어넣으면 마찬가지로 $\\sum_{S}P(S~|~I)$는 1이 되며 사라진다.    \n",
    "(eq5) $G$에 대한 합을 안쪽으로 집어넣으면 마찬가지로 $\\sum_{G}P(G~|~I,D)$는 1이 되며 사라진다.     \n",
    "$\\sum_{D,I}P(D)~P(I) = \\sum_D P(D) ~ \\sum_I P(I)$또한 1이 된다.   \n",
    "결국 $\\sum{P}=1$이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_isLegalDist.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### $P$ Factorizes over $\\mathcal{G}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathcal{G}$가 변수 $X_1, \\dots , X_n$들에 대한 BN graph라 할때,      \n",
    "분포 $P$가 아래의 곱으로 표현되면      \n",
    "분포 $P$는 같은 space에서 $\\mathcal{G}$에 의해 **factorize**된다고 한다.\n",
    "$$P(X_1, ... , X_n) = \\prod^n_{i=1}P(X_i ~ | ~ Pa^{\\mathcal{G}}_{X_i})$$\n",
    "위 식을 Bayesian networks의 chain rule이라 하며,      \n",
    "$X_i$의 부모들을 $Pa^{\\mathcal{G}}_{X_i}$라 하면 각 node에 대한 factor $P(X_i ~ | ~ Pa^{\\mathcal{G}}_{X_i})$를         \n",
    "conditional probability distribution(CPD) 혹은 local probability model이라 한다.(Definition 3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 어떤 분포 $P$가 BN $\\mathcal{G}$에 **factorize**된다는 것은      \n",
    "분포 $P$를 $\\mathcal{G}$의 factor들 곱으로 나타낼 수 있다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Genetic Inheritance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제로 통계적 유전학자들이 정의했던 혈액형(blood type) 유전에 대한 graph 모형을 살펴본다.\n",
    "\n",
    "(우선 관련 지식을 상기해보면... )     \n",
    "- 생물체의 염색체(chromosome)는 모양과 크기가 같은 염색체가 2개씩 존재하므로       \n",
    "유전자형(genotype)은 두개의 변수에 의해 결정된다. \n",
    "- 혈액형을 결정하는 염색체는 A, B, O의 3가지 종류(변수)가 있다.\n",
    "- 위 3가지 변수에 의해 인간의 혈액형 유전자형은 AA, AB, AO, BO, BB, OO의 6가지가 있다.\n",
    "- 하지만 혈액형의 표현형(phenotype)은 A, B, AB, O의 4가지이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 가계도의 혈액형 유전을 BN을 이용해 어떻게 나타낼 수 있을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_Genetic11.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$G_{person}$는 person의 유전자형(Genotype, AA/AB/AO/BO/BB/OO)을 나타내며    \n",
    "$B_{person}$은 person의 혈액형(Bloodtype, A/B/AB/O)를 나타낸다. \n",
    "\n",
    "예를들어 Marge의 Genotype은 아버지 Clancy의 Genotype($G_{Clancy}$)과 어머니 Jackie의 Genotype($G_{Jackie}$)에 영향을 받으며, Marge의 Bloodtype은 자신의 Genotype에만 영향을 받는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_Genetic2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Reasoning Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 3.2.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 Bayesian network를 이용해 Bayesian network에서의 reasoning pattern(추론 유형)에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_01_studentExample_joint_ex.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Causal Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원인이 주어졌을 때(conditioned) 결과가 발생할 확률의 변화를 추론할 수 있다.\n",
    "\n",
    "- Intelligence -> Grade -> Letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 좋은 추천서를 받을 확률은 $P(I^1) \\approx 0.5$라는 것을 계산할 수 있고, \n",
    "$$P(L) = \\sum_G P(L ~ | ~ G)$$\n",
    "\n",
    "\n",
    "학생의 지적능력이 높지 않을 때($I=i^0$) 좋은 추천서를 받을 확률은 $P(l^1 ~ | ~ i^0)\\approx 0.39$ 이고\n",
    "$$P(L ~ | ~ I) = \\sum_{G, D} P(L, G, D ~ | ~ I) = \\sum_{G, D} P(D)~P(G ~ | ~ I, D) ~ P(L ~|~G)$$\n",
    "\n",
    "\n",
    "거기에 과목이 쉬웠을 때 좋은 추천서를 받을 확률은 $P(l^1 ~ | ~ i^0, d^0) \\approx 0.51$이다.\n",
    "$$P(L, G ~|~ I, D) = P(G~|~I,D)~P(L~|~G)$$\n",
    "\n",
    "직관적으로 지적능력이 좋지 않을 경우 좋은 추천서를 받을 확률이 낮아질 것이고, 과목이 쉬운 경우 학점이 높아질 것이므로 추천서 또한 좋아질 것이다.\n",
    "\n",
    "이처럼 parent node가 given일때 child node의 확률을 구해볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_inter.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evidential Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과적인 증거가 주어졌을 때 원인이 사실일 확률의 변화를 추론할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Grade -> Intelligence\n",
    "- Grade -> Difficulty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 관찰된 결과가 없을 때에는 $P(d^1) = 0.4$이고 $P(i^1)=0.3$인데      \n",
    "Grade가 $g^3$(C학점)로 주어졌을 때 이들 확률은 어떠할까?      \n",
    "즉 $P(d^1|g^3)$와 $P(i^1|g^3)$은 어떤 값일까?     \n",
    "\n",
    "계산해보면 $P(d^1 | g^3) \\approx 0.63$으로 학점이 낮다는 것이 주어지면 과목이 어려웠을 확률은 올라가게 된다.    \n",
    "$P(i^1|g^3) \\approx 0.08$인데 이는 학점이 낮다는 것이 주어졌으므로 학생의 지적능력이 높을 확률이 급격하게 떨어졌다는 것을 반영한다.    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@0.63?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_evidential_.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Inter-causal reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "원인들끼리 영향을 주는 경우를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Difficulty -> Grade -> Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서의 예에 추가로 과목이 어려웠다는 증거가 추가되면 $P(i^1|g^3, d^1) \\approx 0.11$이고 이를 이는 과목이 어려웠으므로 낮은 학점이 어느정도 설명되어 학생의 지적능력이 높을 확률이 다시 올라감 반영한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_inter_cau.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 만약 학점이 $g^2$(B)라면 각 확률은 조금식 올라가게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_inter_cau2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 intercausal graph를 살펴보자.    \n",
    "$x_1$과 $X_2$는 각각 binary 확률변수로서 0일 확률과 1일 확률이 50%로 같다.     \n",
    "\n",
    "이 두 요인은 $Y$에 영향을 주는데, $Y$는 요인에 영향을 받는 확률 변수가 아니라 단지 두 요인의 값을 $OR$연산하는 결정된(deterministic) node이다.    \n",
    "(이처럼 deterministic node는 double line으로 나타낼 것이다.)\n",
    "\n",
    "$Y$는 deterministic이므로 전체 4가지 경우의 확률은 0.25로 동일하다.   \n",
    "또한 $X_1$과 $X_2$는 서로 독립적이다.(independent each other)      \n",
    "\n",
    "그런데 만약 $Y=1$이라는 것이 주어질 경우 첫번째 경우의 확률은 0이 되고    \n",
    "나머지 경우의 확률은 0.33이 된다.    \n",
    "그리고 $P(X_1 = 1) = \\frac{2}{3}$이고 $P(X_2 = 1) = \\frac{2}{3}$이다.\n",
    "\n",
    "그런데 이때 $X_1 = 1$이 주어진 경우 $X_2 = 1$의 확률 $P(X_2 = 1 ~|~ X_1 =1)$은 $0.5$가 된다.\n",
    "\n",
    "좀더 직관적으로 생각해보면...    \n",
    "$Y=1$이라는 사실이 주어졌다는 것은 $X_1=1$이거나 $X_2 = 1$이기 때문일 것이다.\n",
    "그런데 만약 추가로 $X_1=1$이라는 사실이 알려지면, 이 사실이 $Y=1$의 원인을 모두 설명하게 되어     \n",
    "$X_2 = 1$이 어떤지에 대해서는 어떤 정보도 남지 않게 되어 원래의 $P(X_2 = 1) = \\frac{1}{2}$로 돌아간다는 것이다. 이런 것을 **explaining away**라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_inter_cau_exp.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reasoning pattern한가지를 더 살펴보면  \n",
    "- SAT -> Intelligence -> Grade -> Difficulty \n",
    "\n",
    "아래와 같이 $P(i^1 | g^3) \\approx 0.08$일 때    \n",
    "학생의 SAT 점수는 매우 높다는 사실일 알려지면 \n",
    " $P(i^1 | g^3, s^1) \\approx 0.58$로 확률이 올라가게 된다.\n",
    " \n",
    " 또한 학점이 C일때 과목이 어려웠을 확률은 0.63인데  \n",
    " 추가로 SAT 점수가 매우 높다는 사실이 알려지면       \n",
    " (좋은 학생임에도 학점이 낮았다는 것은 과목이 더더욱 어려웠다는 증거이므로)    \n",
    " 그 확률은 0.76으로 올라가게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_01_02_reasoning_inter_cau_3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Flow of Probabilistic Influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 3.3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When can $X$ influence $Y$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 reasoning pattern을 설명하면서 한 node가 다른 node에 영향을 주는 다양한 유형에 대해 알아봤다. 이런 논의를 좀 더 엄밀하게 살펴보도록 한다.     \n",
    "여기에서 $A$가 $B$에 영향(influence)을 준다는 것은 $A$에 대한 조건이 주어지면 $B$에 대한 믿음(belief) 혹은 확률이 변화한다는 것이다.      \n",
    "\n",
    "- $X \\to Y$ : Direct causal influence       \n",
    "  Difficulty -> Grade   \n",
    "  \n",
    "  \n",
    "- $X \\leftarrow Y$ : Direct evidential influence   \n",
    "  Difficulty <- Grade\n",
    "  \n",
    "  \n",
    "- $X \\to W \\to Y$ : : Indirect causal influence(if and only if $W$ is not observed)        \n",
    "  Difficulty -> Grade -> Letter       \n",
    "  만약 Grade를 관측했다면 Difficulty에 대한 정보는 Letter에 영향을 주지 않는다.    \n",
    "  \n",
    "\n",
    "- $X \\leftarrow W \\leftarrow Y$ : Indirect evidential influence(if and only if $W$ is not observed)         \n",
    "  Difficulty <- Grade <- Letter    \n",
    "  만약 Grade를 관측 했다면 Letter에 대한 정보는 Difficulty에 영향을 주지 않는다.   \n",
    "  \n",
    "- $X \\leftarrow W \\to Y$ : Common cause(if and only if $W$ is not observed)     \n",
    "  SAT -> Intelligence -> Grade  \n",
    "  만약 Intelligence를 관측했다면 SAT는 Grade에 영향을 주지 않는다.     \n",
    "  \n",
    "  \n",
    "- $X \\to W \\leftarrow Y$ : Common effect(if and only if either $Z$ or one of $Z$'s descendants is observed)      \n",
    "  Grade가 관측되지 않았다면 Difficulty와 Intelligence는 서로 독립적이다. 즉 서로 영향을 주지 못한다. 서로 영향을 주기 위해서는 Grade가 관측되거나, Difficulty 혹은 Intelligence중 하나가 관측되어야 한다. (refers to text p71)\n",
    "\n",
    "\n",
    "즉 증거(evidence)가 없는 상황에서  $X \\to W \\leftarrow Y$의 influence는 성립하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/213_inf1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Active Trails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayesian network내에서 node간에 영향을 주고 받는 것이 가능한 경우를 아래와 같은 **Active Trail**로 정의할 수 있다.(influence는 undirected이다. 즉 양방향으로 influence를 주고 받을 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/213_activeTrail3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 (관측된 node가 없는 상황에서) v-structure가 없어야 한다는 것인데,     \n",
    "관측된 node가 v-structure의 $X_i$이거나 $X_i$의 자손인 경우 여전히 active trail이다.(Definition 3.6, P71)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### When can $X$ influence $Y$ given evidence about $Z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Z$가 관측된 경우(given evidence about $Z$) active trail은 어떤 경우일까?    \n",
    "앞서 살펴본것과 같이 v-structure가 아닌 경우 $Z$가 관측되지 않은 경우 active trail이고     \n",
    "v-structure인 경우 $Z$가 관측되어야만 active trail이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/213_activeTrail2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Bayesian Networks: Independencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 강의에서는 graph structure를 이용해 어떤 probability distrubution을 factorized form으로 나타내는데 사용 했었다. \n",
    "\n",
    "graph structure에 대한 이와 조금 다른 관점이 있는데,     \n",
    "어떤 probability distribution이 만족해야만 하는 independence들을 표현하는 방법으로 graph structure를 사용할 수 있다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1. Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapters 2.1.4, 3.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 indepencence에 대한 용어들을 간단히 다뤄보자.    \n",
    "(참고로 $\\models$는 safisfies, $\\perp$는 independence를 나타낸다.)\n",
    "\n",
    "> We say that an event $\\alpha$ is independent of event $\\beta$ in $P$, denoted $P \\models (\\alpha \\perp \\beta), if P(\\alpha ~|~ \\beta) = P(\\alpha) ~ or ~ if~  P(\\beta) = 0$ (Definition 2.2, p23)\n",
    "\n",
    "> A distrubution $P$ safisfies $\\alpha \\perp \\beta ~if ~ and ~ only ~ if~ P(\\alpha \\cap \\beta) = P(\\alpha) P(\\beta)$ (Proposition 2.1, p23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 random variable에 관한 정의는 두가지 관점에서 생각해볼 수 있는데   \n",
    "첫번째는 $P(X, Y) = P(X)~P(Y)$는 $X$와 $Y$의 수많은 event $x_i$, $y_j$에 대해 $P(x_i, y_j) = P(x_i)~P(y_j)$이 성립한다는 것이다.   ($P(x, y) = p(x)~p(y), ~~ \\forall ~ Val(X) = x, Val(Y) = y$)      \n",
    "두번째는 $X$와 $Y$에 대한 joint probability distribution $P(X, Y)$은 factor $P(X)$와 factor $P(Y)$를 곱으로 표현가능하다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_independence1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example of Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student BN 예제를 통해 factor를 이용해 Independence가 어떻게 표현되는지 살펴보자.    \n",
    "Intelligence, Difficulty, Grade의 joint probability distribution $P(I, D, G)$가 아래와 같이 주어져 있다.     \n",
    "\n",
    "우선 $P(I, D)$를 구하기 위해 $G$에 대해 marginalize($\\sum_{G}$)하고     \n",
    "다시 $P(I)$와 $P(D)$를 구하기 위해 각각 $D$와 $I$에 대해 marginalize한다.\n",
    "\n",
    "이제 $P(I) \\times P(D)$와 $P(I,D)$를 비교해보면   \n",
    "서로 같으므로 random variable $I$와 $D$는 서로 독립인 것을 확인할 수 있다.    \n",
    "(실제 graph 상으로도 독립임을 알 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_independence2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조건부 독립은 아래와 같이 정의된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We say that an event $\\alpha$ is conditionally independent of event $\\beta$ given event $\\gamma$ in $P$, denoted $P \\models (\\alpha \\perp \\beta ~ | ~ \\gamma), ~ if ~ P(\\alpha ~|~ \\beta ~ \\cap ~ \\gamma) = P(\\alpha ~|~ \\gamma) ~ or ~ if ~ P(\\beta \\cap \\gamma) = 0$. (Definition 2.3, p24)\n",
    "\n",
    "> $P$ satisfies $(\\alpha \\perp \\beta ~|~ \\gamma) ~ if ~ and ~ only ~ if ~ P(\\alpha \\cap \\beta ~|~ \\gamma) = P(\\alpha ~|~ \\gamma) ~ P(\\beta ~|~ \\gamma)$ (Proposition 2.2, p24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 식 마지막 식은 factor product이며 비례관계임에 주의하자.(normalizing constant가 생략되어 있으므로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_cond_independence.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Coin Example of Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주머니에 두개의 coin이 있다. coin 하나는 fair하고 다른 하나는 앞면이 90%가 나오는 unfair한 coin이다. 물론 두 coin의 외형은 똑같다.     \n",
    "\n",
    "주머니에서 coin하나를 뽑고 이 coin을 두번 던진다고 해 보자.   \n",
    "아래 BN graph에서 Coin node는 어떤 coin을 뽑게될지에 관한 확률변수이고    \n",
    "$X_1$은 첫번째 던진 동전이 앞면인지 뒷면인지에 관한 확률변수이고    \n",
    "$X_2$는 두번째 던진 동전이 앞면인지 뒷면인지에 관한 확률변수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_cond_independence_coin.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coin을 하나 뽑았고 이것이 fair coin인지 unfair coin인지 모른 상태에서   \n",
    "\n",
    "(아직 한번도 coin을 던지기 전에) 두번째 던진 coin이 앞면이 나올 확률은 $P(X_2 = H ~|~ Coin)$이다.\n",
    "\n",
    "이제 처음으로 coin을 던저 앞면이 나왔다면, 두번째 coin을 던졌을 때 앞면이 나올 확률 $P(X_2 = H ~|~ Coin, X_1 = H)$은 $P(X_2 = H ~|~ Coin)$에 비해 어떠한가?     \n",
    "unfair coin이 90%확률로 앞면이 나오므로 $P(X_2 = H ~|~ Coin, X_1 = H)$은 $P(X_2 = H ~|~ Coin)$에 비해 클 것이다.\n",
    "\n",
    "그런데 이때 앞서 뽑았던 coin이 fair coin이라는 정보를 얻게 된다면 $P(X_2 = H ~|~ Coin, X_1 = H)$은 $X_1 = H$라는 정보와 무관해진다. 즉 첫번째에 앞면이 나왔는지 뒷면이 나왔는지가 두번째 던질 동전의 확률에 어떤 영향도 주지 못하게 된다.\n",
    "\n",
    "마찬가지로 뽑았던 coin이 unfair coin이라는 정보를 얻게 된다해도, 두번째 던질 coin의 앞뒷면 확률에 영향을 주지 못한다.\n",
    "\n",
    "어떤 coin을 뽑았는지에 대한 정보가 없을 때에는 $P(X_1)$과 $P(X_2)$가 서로 dependent하지만,     \n",
    "어떤 coin을 뽑았는지에 대한 정보가 주어지면 $P(X_1)$과 $P(X_2)$가 서로 independent 관계가 된다. \n",
    "\n",
    "즉 $X_1$과 $X_2$는 conditional independence 관계이다. 이를 아래와 같이 표현할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "P &\\not\\models X_1 \\perp X_2\\\\\n",
    "P &\\models (X_1 \\perp X_2 ~|~ C)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Student Example of Conditional Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student example에서 Intelligence, Grade, SAT만을 생각해보면 Intelligence는 Grade와 SAT에 대한 common cause이다. \n",
    "\n",
    "$P(I, S, G)$, $P(S, G ~|~ i^0)$, $P(S ~|~ i^0)$, $P(G ~|~ i^0)$을 차례로 계산해보면 아래와 같고    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(S, G ~|~ i^0) = P(S ~|~ i^0) \\times P(G ~|~ i^0)$임을 확인할 수 있다.    \n",
    "즉 $P \\models (S \\perp G ~|~ i^0 )$ 이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_cond_independence_coin2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반면 conditioning을 할 경우 indepencence를 상실하는 경우도 있다.      \n",
    "(앞서 다뤘던 v-structure인 경우)    \n",
    "\n",
    "아래 표와 같이 $P(I, D ~|~ g^1) \\not= P(I ~|~ g^1) ~ P(D ~|~ g^1)$ 인것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/214_cond_independence_coin_lose.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2. Independencies in Bayesian Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 3.2.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Independence & Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "independence와 factorization간의 관계에 대해 알아본다.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_ind_factor.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 식은 $X$와 $Y$가 서로 independence라는 것을 의미하여    \n",
    "동시에 joint distribution $P(X, Y)$를 factor $P(X)$와 $P(Y)$간의 factor product로 factorize할 수 있다는 것을 나타낸다.\n",
    "\n",
    "두번째 식은 $X$와 $Y$가 $Z$이 주어졌을 때 conditional indepencent 하다는 것을 의미하여    \n",
    "동시에 joint distribution $P(X, Y, Z)$이 factor $\\phi_1(X, Z)$와 factor $\\phi_2(Y, Z)$간의 factor product에 비례함을 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 분포 $P$가 어떻게 factorize되느냐가 분포 $P$내에 존재하는 independence들을 나타낸다고 할 수 있다. 따라서 어떤 분포 $P$가 BN $\\mathcal{G}$에 대해 factorize된다면, graph의 형태를 통해 $P$내에 존재하는 independence들을 확인 할수 있지 않을까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Flow of influence & d-seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 [Flow of Probabilistic Influence]에서 active trail과 inactive trail에 대해 알아봤었다. student example에서 Trail [SAT -> Intelligence -> Grade -> Difficulty]의 경우    \n",
    "다른 모든 node가 관측되지 않고 Grade나 Letter가 관측된 경우 active trail이다.\n",
    "\n",
    "$\\mathbf{X}$, $\\mathbf{Y}$, $\\mathbf{Z}$를 BN $\\mathcal{G}$내의 node set이라 할 때,            \n",
    "$\\mathbf{Z}$가 주어지면 $\\mathbf{X}$내의 node와 $\\mathbf{Y}$내의 node간에 active trail이 없다면 $\\mathbf{X}$와 $\\mathbf{Y}$가 **d-separated**라 하며 아래와 같이 표현한다.(Definition 3.7, p72)\n",
    "$$\\mathcal{I}(\\mathcal{G}) = \\{ ( \\mathbf{X} \\perp \\mathbf{Y} ~ | Z ) : \\mathrm{  \\operatorname{d-sep}}_{\\mathcal{G}} {(\\mathbf{X}; \\mathbf{Y} ~ | ~ \\mathbf{Z})} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 graph structure만으로 node set간의 independence를 확인할 수 있다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_d_seperated.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student example에서 $D$와 $S$가 d-separated이려면     \n",
    "$D$와 $S$를 연결하는 유일한 trail인 Trail [SAT -> Intelligence -> Grade -> Difficulty]이    \n",
    "inactive이어야 한다.\n",
    "\n",
    "이를 위해서는 $G$가 관측되지 않았거나 $I$가 관측되어야만 한다.\n",
    "\n",
    "$G$가 관측되지 않은 상황에서 $D$와 $S$가 독립인지 아래와 같이 chain rule을 이용해 확인할 수 있다.   \n",
    "($X$를 지나치지만 않으면 다른 변수들을 지나 $\\sum_X$을 안쪽으로 넣을 수 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_d_seperated_std.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 아래와 같이 $D$와 $S$가 독립임을 알 수 있다.\n",
    "$$\\begin{align}\n",
    "P(D, S) &= P(D) ~ \\left(\\sum_I P(I)~P(S~|~I)\\right)\\\\\n",
    "&=P(D)~P(S)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### One more statement(명제) about d-seperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 node든지 그것의 부모 node들이 주어진 상황에서는    \n",
    "자식이 아닌 node들과 d-separated이다.\n",
    "\n",
    "예를들어 아래 graph에서 node [Letter]는        \n",
    "부모 node들([Coherence], [Difficulty], [Intelligence], [Grade])이 주어진 상황에서        \n",
    "자식([Happy], [Job])이      \n",
    "아닌 node([SAT])와 d-separated이다.\n",
    "\n",
    "실제로 [Letter]와 [SAT]간에는 trail이 두개가 있는데, \n",
    "- 첫번째는 [SAT] - [Intelligence] - [Grade] - [Letter]이고,      \n",
    "  [Grade]가 관측되었으므로 이는 inactive trail이다.    \n",
    "- 두번째는 [SAT] - [Job] - [Letter] 이고,          \n",
    "  이는 v-structure이고 [Job]이 관측되지 않았으므로 이 또한 inactive trail이다.    \n",
    "\n",
    "따라서 [Letter]와 [SAT]는 서로 독립이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_d_seperated_std3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 어떤 분포 $P$가 BN $\\mathcal{G}$에 대해 factorize된다면,      \n",
    "어떤 변수든지 그것의 부모가 주어지면 그것의 자식이 아닌 변수와는 독립이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### I-maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BN graph $\\mathcal{G}$내의 d-sepration들은    \n",
    "분포 $P$의 independence statement($\\mathbf{X} \\perp \\mathbf{Y} ~|~ Z$와 같은 명제)에 해당한다.(correspond to)\n",
    "\n",
    "> Let $P$ be a distribution over $\\chi$. We define $\\mathcal{I}(P)$ to be the set of independence assertions of the form $(\\mathbf{X} \\perp \\mathbf{Y} ~|~ Z)$ that hold in $P$. (Definition 3.2, p60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let $\\mathcal{K}$ be any graph object associated with a set of independencies $\\mathcal{I}(\\mathcal{K})$. We say that $\\mathcal{K}$ is an I-map for a set of independencies $\\mathcal{I} ~ if ~ \\mathcal{I}(\\mathcal{K}) \\subseteq \\mathcal{I}$. (Definition 3.3, p60) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_i_map1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 식에서 $\\mathcal{I}(\\mathcal{G})$는 BN graph $\\mathcal{G}$내에 존재하는 모든 independent statement들의 집합이다.      \n",
    "그리고 분포 $P$에 존재하는 independent statement의 집합을 $\\mathcal{I}(\\mathcal{P})$라 할 때     \n",
    "만약 $\\mathcal{I}(\\mathcal{K}) \\subseteq \\mathcal{I}(P)$이면 $\\mathcal{G}$는 분포 $P$의 **I-map**이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example of I-maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 예를 살펴보자.     \n",
    "\n",
    "아래오 같이 분포 $P_1$과 분포 $P_2$가 존재할 때 각각의 경우 가능한 graph가 아래와 같다고 하자.   \n",
    "\n",
    "첫번째 graph는 $D$와 $I$사이에 connection이 없고 이는 $D$와 $I$가 서로 독립임을 의미한다.($\\mathcal{I}(\\mathcal{G}_1) = \\{D \\perp I \\}$)      \n",
    "두번째 그래프는 $D$와 $I$사이에 edge가 있고 이는 두 변수가 dependent함을 의미한다.\n",
    "($\\mathcal{I}(\\mathcal{G}_2) = \\emptyset$)\n",
    "\n",
    "즉 $\\mathcal{G}_1$은 $P_1$의 Independence를 모두 표현하므로 $P_1$의 I-map이고, $\\mathcal{G}_2$는 $P_2$의 Independence를 모두 표현하므로 $P_2$의 I-map이다.    \n",
    "반면 $\\mathcal{G}_1$은 $P_2$의 Independence를 표현하지 못하므로 $P_2$의 I-map이 아니고, $\\mathcal{G}_2$은 $P_1$의 Independence set에는 $\\emptyset$이 포함되어 있으므로 $P_1$의 independence를 일부 표현하므로 $P_1$의 I-map이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_i_map1_example.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factorization -> Independence: BNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 분포 $P$가 BN graph $\\mathcal{G}$에 대해 factorize된다면, $\\mathcal{G}$는 분포 $P$의 I-map이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let $\\mathcal{G}$ be a BN structure over a set of random variables $\\mathcal{X}$ and let $P$ be a joint distribution over the same space. If $P$ factorizes according to $\\mathcal{G}$, then $\\mathcal{G}$ is an I-map for $P$. (Theorem 3.2, p63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Independence -> Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 BN graph $\\mathcal{G}$가 분포 $P$의 I-map이라면, 분포 $P$는 BN graph $\\mathcal{G}$로 factorize된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Let $\\mathcal{G}$ be a BN structure over a set of random variables $\\mathcal{X}$, and let $P$ be a joint distribution over the same space. If $\\mathcal{G}$ is an I-map for $P$, then $P$ factorizes according to $\\mathcal{G}$. (Theorem 3.5, p62)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아래 예를 살펴보면   \n",
    "첫번째 식과 같이 $P(D, I, G, S, L)$을 chain rule for probability를 이용해 아래 5개의 독립인 확률들의 곱으로 나타낼 수 있다.(BN chain rule이 아님에 주의)      \n",
    "\n",
    "이제 이 확률곱(첫번째 식)에 우측 하단의 BN graph에 존재하는 independencies를 반영해보자.   \n",
    "- $D$와 $I$는 독립이므로 $P(I~|~D) = P(I)$\n",
    "- $I$가 주어졌을 때, $S$는 $G$와 $D$에 독립이므로 $P(S~|~D, I, G) = P(S~|~I)$\n",
    "- $G$가 주어졌을 때, $L$은 $D$, $I$, $S$와 독립이므로 $P(L ~|~ D, I, G, S) = P(L~|~G)$ \n",
    "이런 관계들을 이용하면 아래 두번째 식을 얻게 된다.\n",
    "\n",
    "이렇게 $P(D, I, G, S, L)$의 independent statement(첫번째 식)을 이용해    \n",
    "분포 $P$가 BN graph와 같이 factorize된다는 것을 증명했다.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_i_map1_stu.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/215_summary.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 3.1.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Bayesian Networks: Knowledge Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.1. Application - Medical Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference: Chapter 3.2: Box 3.D (p. 67)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 Bayesian network는 아래와 같으며, 평균적으로 4개의 상태값을 갖는 변수 500여개로 구성되어 있고, 만약 full-joint distribution으로 나타낼경우 $4^500$개의 parameter가 필요하므로 이런 모형이 아니면 분포를 표현하기 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/217_cpcs.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 연구는 점점 발전해서 상용 시스템까지 개발되는데,   \n",
    "아래와 같은 Microsoft의 진단 시스템이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/217_medical_ms.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application - Fault Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 문제상황을 해결하는 시스템을 설계하는데 BN을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예를들어 컴퓨터의 문제를 해결하는 과정을 아래와 같은 BN으로 나타내볼 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/217_ms_trouble.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이밖에도 다양한 예가 있으며    \n",
    "\n",
    "이런 시스템은 여러 장점이 있는데 예를들어 여러 응답란 중 나중에 응답하고 싶은 것이 있다면 그 응답에 대한 변수는 단지 나중에 conditional 변수로 설정하면 되는 것과 같은 사용자 편의성이 있다. 또한 단지 변수를 추가/삭제하고 변수들간의 관계를 조절하는 것만으로 전체 시스템을 컨트롤 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/217_fault.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.2. Knowledge Engineering Example - SAMIAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UCLA의 Adnan Darwiche 교수 그룹이 개발한 Bayesian network를 모델링할 수 있는 프로그램이다. \n",
    "\n",
    "http://reasoning.cs.ucla.edu/samiam/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
