{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이해해야 하는 것들\n",
    "> - Bayesian inference\n",
    "- Factor graph\n",
    "- Expectation Propagation for truncated gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고자료 - TrueSkill\n",
    "> - Intro to TrueSkill by Kevin Murphy       \n",
    "p793~798, Machine Learning A probabilistic Perspective, Kevin Murphy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고자료 - Expectation Propagation\n",
    "\n",
    "> - A roadmap to research on EP    \n",
    "https://tminka.github.io/papers/ep/roadmap.html\n",
    "\n",
    "\n",
    "> - Expectation Propagation, Theory and Application by Dong Guo   \n",
    "https://www.slideshare.net/guo_dong/expectation-propagation-researchworkshop\n",
    "\n",
    "\n",
    "> - An introduction to Expectation Propagation(Video)        \n",
    "http://sms.cam.ac.uk/media/2132075\n",
    "\n",
    "\n",
    "> - Leature note, Message passing on Factor Graphs\n",
    "http://mlg.eng.cam.ac.uk/teaching/4f13/1112/lect13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "http://mlg.eng.cam.ac.uk/teaching/4f13/1112/lect13.pdf\n",
    "\n",
    "\n",
    "Intro to TrueSkill by Kevin Murphy\n",
    "p793~798, Machine Learning A probabilistic Perspective, Kevin Murphy\n",
    "\n",
    "Math Behind TrueSkill\n",
    "\n",
    "TrueSkill: A Bayesian Skill Rating System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Expectation Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Factor graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 factor graph는 bayesian 방법론과 직접 연관된 것은 아니며, 단지 어떤 함수가 어떻게 분해(factorize)될 수 있는지를 시각적으로 표현하는 방법이라 할 수 있다.\n",
    "\n",
    "factor graph는 작은 함수들의 곱으로 분해(factorize)가능한 어떤 함수를 graphical model로 표현하는 방법인데, 예를들어 함수 $f()$가 아래와 같다면, $x$, $y$, $z$를 각각 variable node로 하고 $(x+y)$, $(y+z)$, $(x+z)$를 각각 factor node로 하는 graphical model을 생각해볼 수 있다.\n",
    "$$f(x, y, x) = (x+y)(y+z)(x+z)$$\n",
    "그런데 어떤 함수를 표현하는 방법은 유일하지 않을 수 있다. 앞서 함수 $f$를 $x$, $y$, $z$의 variable node 3개와 이들이 모두 연결된 $(x+y)(y+z)(x+z)$를 표현하는 factor node 하나만으로 구성될 수도 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example factor graph(Parameter estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 예로 정규분포에서 $n$개의 샘플을 추출하여 이 분포의 평균 $x$를 추정하는 문제를 베이지안 접근법에서 생각해보자.(분산은 1이라 가정)\n",
    "\n",
    "평균 $x$의 사전분포를 $p(x)$라 할 때, 전체 샘플과 평균 $x$의 결합확률 분포는 아래와 같다. \n",
    "$$\\begin{align}\n",
    "p(x, y_1, \\cdots, y_n) &= p(x) \\prod_i p(y_i | x)\\\\\n",
    "p(y_i|x) &= N(y_i; x, 1)\n",
    "\\end{align}$$\n",
    "\n",
    "앞서 소개한 factor graph의 관점에서 $p(x, y_1, \\cdots, y_n)$를 아래와 같이 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 factor graph로 표현하는 것의 장점은 graph만 보더라도 $y_i$들이 각각 서로 독립이라는 것을 알 수 있고, 이러한 graph 구조를 이용해 이밖에도 다양한 추론과 계산 방법 사용이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Example factor graph(Markov chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래와 같은 markov chain 모형을 factor graph로 나타내볼 수 있다.\n",
    "$$p(x_1, \\cdots, x_n) = p(x_1) \\prod_i p(x_i ~|~ x_{i-1})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Two tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graphical model을 이용해 어떤 문제를 풀어가는 과정은 크게 두가지로 나뉜다.\n",
    "- Modeling : 이 데이터 문제를 풀기 위해서는 어떤 graph를 사용해야 할까\n",
    "- Inference : graph가 정해졌다면 여러 변수중 알고자 하는 변수 $x$의 주변확률 분포를 어떻게 구할 것인가? 이를 구하는 방법은 아래와 같이 다양하다.\n",
    "  - Monte Carlo\n",
    "  - Variable elimination\n",
    "  - Message-passing (Expectation Propagation, Variational Bayes, ...)\n",
    " \n",
    " 여기에서는 Message-passing 알고리즘을 중심으로 살펴볼 것이다. 특히 multi-stage inference과 대비되는 부분을 알아볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
