Spark
is
a
fast
and
general
cluster
computing
system
for
Big
Data.
It
provides
<http://spark.apache.org/>
and
[project
wiki](https://cwiki.apache.org/confluence/display/SPARK).

##
Interactive
Scala
Shell





./bin/pyspark



Testing
first
requires
[building
Spark](#building-spark).
Once
Spark
is
built,
tests

Please
refer
to
the
build
documentation
at
Please
refer
to
the
[Configuration
Guide](http://spark.apache.org/docs/latest/configuration.html)
