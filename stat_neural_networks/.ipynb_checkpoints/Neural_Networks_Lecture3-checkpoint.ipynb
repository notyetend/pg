{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coursera의 Neural Networks for Machine Learning 강의를 정리한 내용임.   \n",
    "2016.10.24. by Dongwan Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week3. The backpropagation learning procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**사전 지식**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convex set**   \n",
    ": 유클리디안 공간에서 convex set이란, 어떤 set $A$에 포함되는 어떤 두 점 $x$와 $y$를 연결하는 직선상의 모든 점 또한 set $A$에 포함되는 set을 말한다.\n",
    "[https://en.wikipedia.org/wiki/Convex_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_Convex_polygon_illustration1.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Non-convex set**   \n",
    ": Concave set이라고도 하며, convex하지 않은 set을 의미. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_Convex_polygon_illustration2.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Convex function**   \n",
    ": epigraph가 convex set인 구간에서 정의된 실함수(real-valued function)\n",
    "[https://en.wikipedia.org/wiki/Epigraph_(mathematics)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_200px-Epigraph_convex.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3a, Learning the weights of a <u>linear neuron</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Why the perceptron learning procedure cannot be generalised to hidden layers</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Week2에서는 Perceptron에서의 learning procedure에 대해서 알아봤었다.     \n",
    "\n",
    "\n",
    "> 기억을 상기해보면 <u>**Perceptron learning procedure**</u>에서는     \n",
    "'Netwok의 output'과 'true output'을 비교하여     \n",
    "'current weight'에 'input vector'를 더하거나 빼거나 혹은 그대로 두는 방식으로    \n",
    "'current weight'이 'good set of weights'에 항상 가까워지는 형태로 learning이 진행되었다.\n",
    "\n",
    "> 그런데 이런 접근 방식은 단순히 weight간의 거리만을 염두해 두기 때문에, 두 개의 good weight의 평균 값이 bad weight인 경우(non-convex problem)에는 효과적이지 않다.\n",
    "\n",
    "> 특히 hidden layer를 포함하는 등 network가 복잡해 질 경우, good weights space가 convex하지 않는 경우가 다반사 라서, perceptron learning procedure를 사용할 수 없는 경우가 많다.\n",
    "\n",
    "> 따라서 multi-layer NN을 multi-layer perceptrons라고 표현하는 것은 맞지 않다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그렇다면 feasible weight과의 거리가 아니라 다른 learning measure가 필요한데,   \n",
    "\n",
    "> 이번에는 실제 결과값(target value, $t$)이     \n",
    "모델의 결과값(network output, $y$)과     \n",
    "차이(error)가 얼마나 작아지는지를 기준으로 잡기로 하자.       \n",
    "\n",
    "> 구체적으로 training data를 set $training$으로 정의하고,    \n",
    "set $training$의 원소인 각 data record를 $n$이라 하자.       \n",
    "이때 각각의 data record에 대한 error의 합을 아래와 같이 정의하고, \n",
    "이 값을 최소화 하는 것을 최적화 목표로 잡아보자.\n",
    "\n",
    "$$E = \\frac{1}{2}\\sum_{n \\in training } (t^n - y^n )^2$$\n",
    "\n",
    "> Neural network 모형에서 저 $E$를 최소화 하기 위해서   \n",
    "우리가 컨트롤 할 수 있는 부분은 weight($w$)들인데,     \n",
    "\n",
    "> 어떤 weight $w_i$가 1단위 증가함에 따라 $E$가 $\\Delta E$만큼 증가하는 상황이라면    \n",
    "$w_i$가 지나치게 커서 error를 증가시키고 있으므로    \n",
    "$w_i$를 $\\Delta E$에 비례하여 줄여주는 것이 합리적이라 할 수 있다.\n",
    "\n",
    "\n",
    "> 이를 위해서 각 weight($w_i$)에 따라 $E$가 얼마나 변화하는지를 나타내는     \n",
    "$\\frac{\\partial E}{\\partial w_i}$ 값이 필요하고, 이 값에 비례하여 $w_i$를 줄일 것 이므로        \n",
    "비례상수(learning rate)를 $\\epsilon$라 하여, $\\Delta w_i$를 아래와 같이 표현할 수 있다.\n",
    "\n",
    "$$\\Delta w_i = -\\epsilon \\frac{\\partial E}{\\partial w_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그런데 $\\frac{\\partial E}{\\partial w_i}$ 값은 아래에서 볼 수 있는 것 처럼,     \n",
    "NN을 구성하는 neuron(unit)의 function($y=f(x)$)에 따라 달라진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align} E &= \\frac{1}{2}\\sum_{n \\in training } (t^n - y^n )^2 \\\\ \\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} \\frac{dE^n}{dy^n} \\\\ &= - \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} (t^n - y_n)  \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Linear neurons</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> 우선 unit의 간단한 예로, input들을 받아 weighted sum을 출력하는 형태인       \n",
    "linear neurons(=linear filters)를 살펴보기로 하자.(Week1에서 다뤘었음)\n",
    "\n",
    "$$y = \\sum_i w_i x_i = \\textbf{w}^T \\textbf{x}$$\n",
    "\n",
    "> 위에서는 Week1의 내용과 달리 bias($b$)를 w_0로 하고, $x_0$값은 항상 1로 고정하여 $\\sum$에 포함시켰다. 또한 $\\textbf{w}$는 weight vector이고 $\\textbf{x}$는 input vector이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다시 error function $E$로 돌아가보면, \n",
    "\n",
    "$$\\begin{align} y &= \\sum_i w_i x_i \\\\ \\frac{\\partial y}{\\partial w_i} &= x_i \\end{align}$$\n",
    "> 이므로..\n",
    "\n",
    "$$\\begin{align} \\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} \\frac{dE^n}{dy^n} \\\\ &= - \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} (t^n - y_n)  \\\\ &= - \\sum_{n} x_{i}^{n} (t^n - y_n) \\end{align}$$\n",
    "\n",
    "> 이고, 따라서 $\\Delta w_i$는 아래와 같다.\n",
    "\n",
    "$$\\begin{align} \\Delta w_i &= -\\epsilon \\frac{\\partial E}{\\partial w_i} \\\\ &= \\sum_{n} \\epsilon x_{i}^{n} (t^n - y_n) \\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<u>Meal price example</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 매일 레스토랑에 가서 fish, chips, ketchup을 각각 $x_{fish}$, $x_{chips}$, $x_{ketchup}$개식 시켜 먹는다. 그런데 이 식당에서는 계산할 때에 총액만을 알려준다고 한다.\n",
    "\n",
    "> 여러 번의 식사 기록을 토대로 fish, chips, ketchup의 개별 가격($w_{fish}$, $w_{chips}$, $w_{ketchup}$)을 알 수있는 방법이 없을까?\n",
    "\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 물론 이 문제의 경우 데이터가 적절한 경우 최소 3건의 데이터를 이용해 해석적으로(analytically) 방정식을 풀어, $w_i$들에 대한 닫힌 해(closed solution)를 구할 수도 있다. (data sample record 하나당 하나의 방정식을 세우고, 모두를 연립으로 풀어 해를 구함)     \n",
    "\n",
    "> 반면 **iterative approach**는 $w_i$들에 대한 (random) 초기값에서 시작하여, 점차 error $E$가 줄어들도록 $w_i$를 수정해 나가는 방식이다.\n",
    "\n",
    "> 그런데 복잡한 시스템(more hidden layers)에서는     \n",
    "해석적으로 솔루션을 구할 수 없는 경우가 다반사라서     \n",
    "우리는 해석적 방법이 아니라      \n",
    "반복적인 방법(iterative approach)으로 문제를 풀어볼 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 다시 예제로 돌아와서,      \n",
    "한번의 식사에서 주문하는 fish, chips, ketchup의 수를 각각 $x_{fish}$, $x_{chips}$, $x_{ketchup}$이라 하고,       \n",
    "개별 가격을 $w_{fish}$, $w_{chips}$, $w_{ketchup}$ 이라 하면,      \n",
    "한끼 식사의 가격 $price$는 아래와 같다.\n",
    "\n",
    "$$price = x_{fish} w_{fish} + x_{chips} w_{chips} + x_{ketchup} w_{ketchup}$$\n",
    "\n",
    "> 우선 첫번째 training data record가 $y_1 = 850$, $\\textbf{x} = (2, 5, 3)^T$ 이라 할 때,  $w_i$들에 대한 random guess $\\textbf{w}_{guess} = (50, 60, 70)^T$에서 출발해 보자.    \n",
    "(즉 첫 끼니에 fish를 두개 chips를 5개 ketchup을 3개 시켰고, 850원을 개산 했다. 그리고 우선 fish, chips, ketchup 모두 50원 일 것이라고 대충? 추측을 했다.)\n",
    "\n",
    "> $\\textbf{w}_{guess} = (50, 60, 70)^T$일때, $price_{guess} = 610$이므로, 이때 오차($t - y$)는 240이 된다.\n",
    "\n",
    "> 앞서 $\\Delta w_i$를 아래와 같이 정의 했으므로  $$\\begin{align} \\Delta w_i &= -\\epsilon \\frac{\\partial E}{\\partial w_i} \\\\ &= \\sum_{n} \\epsilon x_{i}^{n} (t^n - y_n) \\end{align}$$\n",
    "> $\\Delta w_i = \\epsilon \\cdot x_i \\cdot 240$ 이 된다.\n",
    "> 이때 learning rate $\\epsilon$을 $\\frac{1}{24}$라고 하면,      \n",
    "> $\\Delta w_1 = 20$, $\\Delta w_2 = 50$, $\\Delta w_1 = 30$ 이 된다.\n",
    "\n",
    "> 즉 수정된 $\\textbf{w}$는 $(70, 110, 100)^T$이 된다.\n",
    "\n",
    "> 이후, 두번째 training data record와 수정된 weight $\\textbf{w} = (70, 110, 100)^T$를 이용하여 이 과정을 반복하게 된다.  \n",
    "\n",
    "> (사실 이 방법은 online version of delta-rule이며, Batch 방식으로도 문제를 풀 수 있다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Behaviour of the iterative learning procedure</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 과연 iterative method로 정답을 구할 수 있을까?     \n",
    "또한 얼마나 빨리 혹은 적은 iteration으로 정답에 도달하게 될까?\n",
    "\n",
    "> - 이에 대한 답은 learning rate $\\epsilon$값을 얼마로 하는지 또 어떻게 변화시켜 가는지에 따라 달라진다.    \n",
    "  (예를들어 learning rate을 크게 하면 빨리 정답 근처에 갈 수 있겠지만, 정답을 지나칠 가능성도 커진다. 반면 learning rate를 작게 하면 정답에 도달할 가능성은 커지겠지만 도달 속도가 느릴 수 있다.)\n",
    "> - 또한 input data가 feature간 correlation이 어떠한가에도 큰 영향을 받는다.    \n",
    "  (예를들어 매일 같은 수의 fish, chips, ketchup를 시켜 먹는다면 영영 각각의 가격을 알 수 없다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3b, The error surface for a linear neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> week2에서 $n$ 차원 공간(space)의 한 점이      \n",
    "길이가 $n$인 weight vector하나를 의미하는   \n",
    "**weight space**에 대해 배웠었다.\n",
    "\n",
    "> 이제 이 공간에 차원을 하나 추가하여 $n+1$ 차원 공간을 만들고        \n",
    "추가된 차원에 각 weight vector에 대한 error를 표현한다고 해 보자.\n",
    "\n",
    "> 예를들어 weight이 두개 있어서, weight space는 $x$, $y$축으로 구성된 평면이고     \n",
    "$z$축을 추가하여 여기에 error $E$를 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 linear neuron에 대한 error $E$는 아래와 같이 정의 됐었는데\n",
    " $$E = \\frac{1}{2}\\sum_{n \\in training } (t^n - y^n )^2$$\n",
    " \n",
    "> 이는 $w_i$들에 대한 2차식(quadratic function)이므로,    \n",
    "3차원 공간에서 아래로 볼록한 사발(bowl)과 같은 모양일 것이다.\n",
    "\n",
    "> 즉 아래 그림과 같이 수직으로 자르면 포물선(parabola) 모양이고     \n",
    "수평으로 자르면 타원형(ellipse)일 것이다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_error_surface.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 최적화(optimize)는 $E$를 최소로 하는 $\\textbf{w}$를 찾는 혹은 변화 시켜가는 과정인데    \n",
    "(위 예에서는 error surface가 $x-y$평면에 가장 가까워지는 지점 혹은 구간을 찾는 것)\n",
    "\n",
    "> 그 과정은 최적화 방법론이나 여러 파라미터에 따라 달라진다. 여기서 달라진다는 것은 $\\textbf{w}$의 궤적의 다양성을 의미한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모형에 data를 얼마만큼 투입하여 최적화를 진행할지도 여러가지 방법이 있는데,    \n",
    "\n",
    "> 한건 혹은 몇건식 투입할 때마다 $\\textbf{w}$를 갱신해 나가는 방법을    \n",
    "**Online learning**이라 하고,       \n",
    "\n",
    "> 전체 데이터를 한꺼번에 투입할 때마다 $\\textbf{w}$를 갱신해 나가는 방법을     \n",
    "**Batch learning**이라 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Online learning의 경우 아래와 같이 zig-zag 형태로 $min_{\\textbf{w}} \\left[ E \\right]$를 찾아가게 된다. 물론 data에 따라 steepest descent과 반대 방향으로 갈때도 있지만, 데이터가 충분할 경우 $min_{\\textbf{w}} \\left[ E \\right]$를 찾게 된다고 알려져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_online_optimization.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Batch learning의 경우 아래와 같이 $\\textbf{w}$의 궤적이 곧바로 steepest descent방향으로 향하게 된다. 다만 데이터량이 클 경우 그 연산량이 많아질 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_batch_optimization.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이런 optimization에서 또 한가지 문제가 되는 것은     \n",
    "feature간 correlation이 큰 경우이다.    \n",
    "이런 경우 weight ellipse가 아래 그림과 같이 대단히 찌그러져 있게 되고(elongated)      \n",
    "$min_{\\textbf{w}} \\left[ E \\right]$를 찾는 것이 쉽지 않게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_elongated.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3c, Learning the weights of a logistic output neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 [Lecture 3a, Learning the weights of a linear neuron]에서    \n",
    "network를 구성하는 unit이 linear neuron일 경우의      \n",
    "$\\frac{\\partial E}{\\partial w_i}$를 아래와 같이 구했었다.\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial w_i} = - \\sum_{n} x_{i}^{n} (t^n - y_n)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이번에는 linear neuron이 아니라 **logistic neuron**에 대한 $\\frac{\\partial E}{\\partial w_i}$를 구해보도록 하자.\n",
    "\n",
    "> logistic neuron의 output $y$는 아래와 같이 정의된다.\n",
    "\n",
    "$$ y = \\frac{1}{1 + e^{-z}} ~~, ~~ z = b + \\sum_{i} x_i w_i $$\n",
    "\n",
    "> 또한 각 변수에 대한 편미분은 아래와 같다.\n",
    "$$\\frac{\\partial z}{\\partial w_i} = x_i ~~, ~~ \\frac{\\partial z}{\\partial x_i} = w_i$$\n",
    "\n",
    "> 마지막으로 $\\frac{dy}{dz}$ 가 아래와 같이 아름다운? 형태를 갖는다.   \n",
    "$$\\frac{dy}{dz} = y(1-y)$$\n",
    "\n",
    "> 그 때문에 $\\frac{\\partial y}{\\partial w_i}$ 또한 아래와 같이 더욱 아름다운? 형태가 된다.\n",
    "\n",
    "$$\\frac{\\partial y}{\\partial w_i} = \\frac{\\partial z}{\\partial w_i} \\frac{dy}{dz} = x_i y (1-y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이제 $\\frac{\\partial E}{\\partial w_i}$를 조합해 보면 아래 결과를 얻을 수 있다.    \n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{n} \\frac{\\partial y^n}{\\partial w_i} \\frac{dE^n}{dy^n} \\\\\n",
    "&= - \\sum_{n} x_{i}^{n} y^{n} (1-y^{n}) (t^n - y_n) \n",
    "\\end{align}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3d, The backpropagation algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Learning by pertubing weights</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> hidden layer의 weight을 적절히 조절(learning)하는 것은 쉬운 일이 아니다.\n",
    "\n",
    "> 한가지 아이디어로 무작위로 weight을 변화 시키고     \n",
    "그 결과 모델의 성능이 좋아졌다면 변화된 weight을 선택하는 방법을 생각해 볼 수 있다.    \n",
    "(강의에서는 Learning by pertubing weights라고 표현함)\n",
    "\n",
    "> 사실 일종의 reinforcement learning이라 할 수 있는데,       \n",
    "매우 비효율적인 방법이라 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>The idea behind back-progagation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> hidden layer $i$의      \n",
    "k번째 unit의 activity($y_{ik}$)가        \n",
    "전체 error $E$에 얼마나 영향을 주는지 알 수 있다면      \n",
    "$y_{ik}$를 결정하는 weight vector $\\textbf{w}_i$가 $E$에 주는 영향도 알 수 있고     \n",
    "이에 맞춰 $w_{i1}, w_{i2}, w_{i3}, \\cdots$를 조절할 수 있을 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 즉 **forward propagation**이 input value에 weight만큼의 가중치를 주고     \n",
    "이 값을 output layer까지 전파 시켜 가는 과정이라면    \n",
    "\n",
    "> **back-propagation**은 output layer에서의 error에 대한     \n",
    "각 layer & unit의 영향도를 계산하고     \n",
    "그 영향이 비례하여 weight들을 조절하는 과정이다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이를 위해 $\\frac{\\partial E}{\\partial y_i}$를 구하고, $\\frac{\\partial E}{\\partial w_{ij}}$ 또한 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/03_idea_bp_2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Sketch of the backpropagation algorithm on a single case</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\frac{\\partial E}{\\partial y_j} $ : error derivative w.r.t. output activity($y_j$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 Lecture 3a에서 전체 n건의 training data에 대해,      \n",
    "하나의 output unit에서 발생하는 error $E$를 아래와 같이 정의 했었다.\n",
    "$$E = \\frac{1}{2}\\sum_{n \\in training } (t^n - y^n )^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이번에는 단 하나의 training case(record 하나)에 대해,      \n",
    "output layer j의 모든 output unit에서 발생하는 error $E$를 아래와 같이 표현할 수 있다.\n",
    "$$E = \\frac{1}{2}\\sum_{j \\in output } (t_j - y_j )^2$$\n",
    "\n",
    "> 또한 layer j의 어떤 unit의 activity $y_j$에 대한 'error derivative'는 아래와 같다.\n",
    "$$\\frac{\\partial E}{\\partial y_j} = - (t_j - y_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 output layer j에 output unit이 3개 있다면, (subscript jk는 layer j의 k번째 unit을 의미)\n",
    "$$E = \\frac{1}{2} \\left[ (t_{j1} - y_{j1})^2 + (t_{j2} - y_{j2})^2 + (t_{j3} - y_{j3})^2\\right]$$\n",
    "\n",
    "> error function은 위와 같고, 두번째 unit의 activity에 대한 'error derivative'는 아래와 같다.\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial y_{j2}} = -(t_{j2} - y_{j2})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\frac{\\partial E}{\\partial z_j}$ : error derivative w.r.t. sum of weighted inputs($z_j$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $$\\begin{align}\n",
    "\\frac{\\partial E}{\\partial z_j} &= \\frac{dy_j}{dz_j} \\frac{\\partial E}{\\partial y_j} \\\\\n",
    "&= y_j (1-y_j) \\frac{\\partial E}{\\partial y_j}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\frac{\\partial E}{\\partial y_i}$ : error derivative w.r.t. activity of a hidden unit($y_i$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\n",
    "\\frac{\\partial E}{\\partial y_i} &= \\sum_{j} \\frac{dz_j}{dy_i} \\frac{\\partial E}{\\partial z_j} \\\\\n",
    "&= \\sum_{j} w_{ij} \\frac{\\partial E}{\\partial z_j}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $\\frac{\\partial E}{\\partial w_{ij}}$ : error derivative w.r.t. weight from unit of layer i to unit of layer j($w_{ij}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $$\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_{ij}} &= \\frac{\\partial z_j}{\\partial w_{ij}} \\frac{\\partial E}{\\partial z_j} \\\\\n",
    "&= y_i \\frac{\\partial E}{\\partial z_j}\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $$\\begin{align}\n",
    "\\frac{\\partial E}{\\partial w_{ij}} &= y_i \\frac{\\partial E}{\\partial z_j} \\\\\n",
    "&= - y_i y_j (1 - y_j) (t_j - y_j)\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 $\\textbf{x} = (x_1, x_2, \\cdots , x_n)^T$ 와 같은 training case가 하나 있고,    \n",
    "여기에 대한 true output $t$가 있다고 하자.\n",
    "\n",
    "> 그리고 NN은 $n$개의 unit으로 구성된 input layer와 (hidden layer 없이) 단 하나의 logistic neuron으로 구성된 output layer로 이루어져 있고,     \n",
    "loss function은 아래와 같을 때\n",
    "$$E = \\frac{1}{2} (t - y )^2$$\n",
    "\n",
    "> back-propagation을 이용한 $w_i$의 수정치 $\\Delta w_i$의 값은? (learning rate은 $\\epsilon$이라 하자.)\n",
    "\n",
    "> $y_i$가 $x_i$이고, $\\Delta w_i$는 $- \\epsilon \\frac{\\partial E}{\\partial w_{ij}}$이므로\n",
    "$$\\Delta w_i = \\epsilon x_i y_j (1 - y_j) (t_j - y_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 3e, How to use the derivatives computed by the backpropagation algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> error derivatives를 구하긴 했으나,        \n",
    "좋은 모델을 만들기 위해서는     \n",
    "아직 결정 해야할 것들이 너무도 많다.\n",
    "\n",
    "> 우선 얼마나 자주 weights를 갱신할 것인가의 문제이다.\n",
    "> - Online 방식이라면 매 record마다 update을 할것이고\n",
    "> - Full batch 방식이라면 전체 데이터를 한번 스켄 할 때마다 update을 하고\n",
    "> - Mini-batch 방식이라면 한건보다 크고 전체보다 작은 적당한 건수의 데이터를 읽을 때마다 update을 하게 된다.\n",
    "\n",
    "> 그리고 update 주기를 정했다 하더라도, 한번 갱신 시 얼마나 weight을 업데이트 할지    \n",
    "혹은 가중치를 동일하게 할지 다르게 할지 등의 문제들도 남아 있다.\n",
    "\n",
    "> 물론 다른 많은 ML 모델과 마찬가지로 Overfitting 문제도 해결해야하는 과제중의 하나이다.    \n",
    "아래와 같이 overfitting을 극복하기 위한 다양한 방법이 있는데, lecture 7에서 구체적으로 다룰 것이다.\n",
    "> - Weight-decay\n",
    "> - Weight-sharing\n",
    "> - Early stopping\n",
    "> - Model averaging\n",
    "> - Bayesian fitting of neural nets\n",
    "> - Dropout\n",
    "> - Generative pre-training\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
