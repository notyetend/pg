{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2016-10-17 - 최초 작성 / 김동완    \n",
    "> 2017-07-26 - 내용 추가 / 김동완"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week2. The Perceptron Learning Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2주차에서는 뉴럴 네트워크(neural network)의 종류(4가지)와   \n",
    "1세대 뉴럴 네트워크라 할 수 있는 퍼셉트론(Perceptron)에 대해서 알아볼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시작전에 몇가지 용어에 대해 알아보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 유닛(Unit): 앞서 배웠던 '뉴런'으로서 하나의 함수(function) / 커널(kernel) 이라 할 수 있다. 이 함수를 엑티베이션 함수(activation function)이라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_unit.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 레이어(Layer): 동일 단계의 유닛들을 지칭한다.\n",
    "- 입력값을 받는 레이어를 입력 레이어(input layer), 출력값을 내놓는 layer를 출력레이어(output layer), 입력레이어와 출력레이어 사이에 하나 이상의 레이어들을 히든레이어(hidden layer)라 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_neural_net.jpeg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2a. An overview of the main types of neural network architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장에서는 뉴럴 네트워크의 다양한 구조에 대해 알아볼 것이다. 여기서 구조라는 것은 뉴런들이 어떻게 연결되는지를 의미한다.\n",
    "\n",
    "- 유닛 혹은 뉴런(neuron)들이 연결되는 방식에 따라 뉴럴 네트워크의 구조를 크게 아래 4가지로 나눠 볼 수 있다.\n",
    "\n",
    " - Feed-forward neural networks\n",
    " - Recurrent networks\n",
    " - Symmetrically connected networks\n",
    " - Symmetrically connected networks with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (1) Feed-forward neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feed-forward neural network는 가장 일반적인 뉴럴 네트워크 구조로서 입력 레이어로 입력을 받아 몇개의 히든 레이어를 따라 정보가 전달되어 출력 레이어까지 한 방향으로 정보 전달이 진행되는 형태이다.     \n",
    "(히든 레이어가 하나 이상일 경우, 딥 뉴럴 네트워크(deep neural networks)라 부른다.)\n",
    "\n",
    "- 각 레이어마다 서로 상이한 입/출력 연결과 상이한 선형/비선형 함수가 사용되므로, 각 레이어마다 입력 정보에 대한 서로 다른 표현(representation)을 갖는다. 이 때문에 이전 레이어(layer)에서 비슷한 표현이 다음 레이어에서 보다 덜 비슷한 표현으로 바뀌거나, 이전 레이어에서 서로 상이한 표현이 다음 레이어에서 보다 덜 상이한 표현으로 바뀌기도 한다.\n",
    "\n",
    "- 예를들어 음성인식에서 서로 다른 사람이 말한 동일한 단어(에 대한 음성)가 히든 레이어들을 거치면서 동일한 표현으로 바뀔 수 있고, 한 사람이 말한 서로 다른 단어(에 대한 음성)가 히든 레이어들을 거치면서 서로 다른 표현으로 바뀔 수 있다. 이를 위해 비선형 함수가 각 레이어의 엑티베이션 함수로 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_feed_forward.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (2) Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent neural networks는 유닛간의 방향성 연결(directed connection)을 갖는다. 이는 어떤 유닛의 출력값이 다른 유닛을 거처 다시 입력으로 들어올 수도 있다는 것을 의미한다.\n",
    "- 이런 구조적 특성 때문에 각 유닛의 출력값은 상당히 복잡하고 다이나믹하게 변화하며, 모형을 학습시키는 것도 단순하지 않다. (최근에는 좋은 학습 방법들이 나와 있다.)\n",
    "- 네트워크 내에 어떤 상태 값이 기억되는 특성을 갖는다.\n",
    "- 여러 히든 레이어를 갖는 recurrent neural network는 히든 레이어 내에서 유닛간 연결이 없는 특별한 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_recurrent_network.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent neural network를 이용해 순차적 데이터(sequential data)를 모델링할 수 있다.\n",
    "- 예를들어 아래 그림과 같이 각 시점마다의 input/hidden/output이 존재하며 각 히든 레이어가 연결된 형태로서, 각 시점의 히든 유닛의 상태값이 다음 시점의 히든 유닛의 상태값을 결정하게 된다. 또한 (노란, 빨간, 녹색 화살표와 같이) 각 시점마다 동일한 가중치(weight)이 사용되며, 매 시점마다 입력과 출력이 존재하는 특성이 있다.\n",
    "- 히든 레이어의 상태값이 기억되는 특성이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_sequential_data.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent neural network를 사용한 사례로는 2011년 일리야 서스키바(Ilya Sutskever)가 발표한 '<a href='http://www.cs.utoronto.ca/~ilya/pubs/2011/LANG-RNN.pdf' target='_blank'>문자열에서 다음 문자를 예측하는 연구</a>'가 있는데, 위키피디아의 몇억개 단어를 이용해 모형을 학습시키고 다음 문자열을 예측하도록 했다.\n",
    "- 구두점, 숫자, 대소문자를 포함하여 86개 문자를 사용했으며 아래에 생성 문자열 예시에서 볼 수 있는 것처럼 그럴듯한 영문장을 생성하고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_ilya_text.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Week7에서 RNN에 대해 다시 다루게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (3) Symmetrically connected networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recurrent network의 특별한 케이스로서 unit간에 동일한 weight의 상호 연결을 갖는 형태이다.\n",
    "- Recurrent network에 비해 분석하기 쉬우나, energy function을 따르기 때문에 활용 범위에 제약이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_symmetric.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Hopfield network**는 Hidden unit이 없는 symmetrically connected network이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Hopfield-net.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (4) Symmetrically connected networks with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Boltzmann machine**은 Hidden unit을 포함하는 symmetrically connected network이다.\n",
    "(파랑색 unit이 hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Boltzmannexamplev2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Boltzmann machine에서 hidden unit간 연결을 제거한 **Restricted Boltzmann machine(RBM)**도 있다.\n",
    "(나중에 배우게 됨)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_Restricted_Boltzmann_machine.svg.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2b. Perceptrons: The first generation of neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 통계적 패턴 인식(Statistical pattern recognition)에서의 패러다임은 아래와 같다.\n",
    " 1. raw input vector를 feature activation으로 바꾼다.(이 과정은 도메인 지식에 의한 수작업으로 진행됨)\n",
    " 2. feature activation에 어떤 weight들로 가중합 하여 어떤 스칼라 값을 결정하는데, 이 값을 (알려진) target class와 비교하여 weight들을 학습시킨다.\n",
    " 3. weight들이 결정되고, 각 입력 vector에 대한 가중합을 확인하여 이 값이 특정 기준값(threshold)를 넘어설 경우, 목표로 하는 값(target class)에 부합하는 입력이라 판단하고 그렇지 않을 경우 부합하지 않는 값이라 판단한다.\n",
    " \n",
    "- Perceptrons는 통계적 패턴 인식(Statistical pattern recognition)의 특별한 예 라고 할 수 있다. 즉 앞서 설명한 과정을 통해 학습하고 입력 값에 대한 판단을 내린다. 다양한 버전의 Perceptron이 존재하는데, alpha perceptron이라 불리는 표준 버전은 아래 그림과 같으며 앞서 설명한 1/2/3의 과정이 동일하게 사용된다. (즉 input vector가 수작업(hand-coded weights or programs)으로 feature input으로 바뀌고, target class에 따라 weight을 학습시킨다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_perceptron.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@@@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 이제 **Perceptrons의 역사**에 대해서 예기해 보면...        \n",
    "1957년 프랑크 로젠블라트(Frank Rosenblatt)가 제안한 feedforward network로서Input layer와 output layer만을 갖는 형태\n",
    "\n",
    "\n",
    "> - 'Principle of Neurodynamitcs'(Rosenblatt, Frank (1962)) 이 책에서 다양한 종류의 Perceptron과 강점을 소개함\n",
    "\n",
    "\n",
    "> - 1969년 Minsky와 Papert이 'Perceptrons'라는 책에서 Perceptrons의 한계를 밝힘, 그런데 사람들은 이런 한계가 모든 Neural network에도 적용되는 것이라고 생각하게 되고, Neural network의 암흑기가 오게 됨.\n",
    "\n",
    "\n",
    "> - 1970년대 Geoffrey Hinton이 Neural network를 연구하기 시작했을때, AI 분야의 사람들이 '그건 틀렸다는게 밝혀 졌자나' 라고 했다고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 <u>'여기 모인 사람들이 오늘 야식을 먹을까 말까'</u> 예측한다고 해 보자.   \n",
    "주어진 데이터는    \n",
    "'오늘 점심 메뉴'(한식, 중식, 일식 중 하나),   \n",
    "'스트레스 지수(-5~5)',     \n",
    "'배고픔 지수(-5~5)' 라고 해 보자. (raw input data / matrix)\n",
    "\n",
    "> 이때 feature vector는 점심 메뉴($x_1, x_2$), 스트레스 지수($x_3$), 배포픔 지수($x_4$)가 되고,   \n",
    "여러 데이터 point에 아래 조건을 잘 만족시키는 $w_i$들을 찾게 됨\n",
    "\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위에서 threshold $\\theta$ 가 등장하는데, 이 값을 모델에 넣어서 같이 추론할 수 있음    \n",
    "(Week1에서 Binary threshold neurons page에 나옴)\n",
    "> threshold는 사실 -1 * bias로 바꿔 생각하면 모형은 아래와 같음.($b = -\\theta)$\n",
    "\n",
    "> $$z = b + w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq 0 \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> 또한 bias unit은 입력값이 1인 unit이라 할 수 있음.($bias = b = b \\cdot x_0, ~x_0 = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_bias.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그렇다면 $w_i$들을 어떻게 구할 것인가?   \n",
    "\n",
    "> 앞서와 같은 binary output neuron에서는    \n",
    "input에 따라 model output과 true output을 비교하여 3가지 경우로 나뉠 수 있다.\n",
    "\n",
    "> - true output = model output (correct)\n",
    "> - true output = 1, but model output = 0 (incorrect, false negative)\n",
    "> - true output = 0, but model output = 1 (incorrect, false positive)\n",
    "\n",
    "> 첫번째 경우에는 기존의 $w_i$를 그대로 두고     \n",
    "두번째 경우 $z$값이 실제보다 작게 나온 것 이므로, $w_i$를 $w_i + x_i$로 수정     \n",
    "세번째 경우 $z$값이 실제보다 크게 나온 것 이므로, $w_i$를 $w_i - x_i$로 수정\n",
    "\n",
    "> 이 방법을 사용하면 (물론 해가 존재한다면)    \n",
    "모든 training cases에 들어맞는 $w_i$들을 찾을 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2c. A geometrical view of perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **hyper-plane** 이란?\n",
    "\n",
    "> n차원 유클리드 공간에서의 hyperplane이란, n차원 주변공간(ambient space)을 둘로 나누는 n-1차원인 부분공간(subspace)을 의미한다.\n",
    "\n",
    "> 즉 1차원인 선을 둘로 나누는 것은 점이고\n",
    "2차원인 평면을 둘로 나누는 것은 선이고\n",
    "3차원인 공간을 둘로 나누는 것은 평면이다.  \n",
    "여기서 점, 선, 평면이 각 차원에서의 hyperplane이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Weight space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - weight 하나당 차원 하나로 구성되는 space.\n",
    "\n",
    "\n",
    "> - 이 space의 점 하나는 weight 쌍 하나를 의미.\n",
    "\n",
    "\n",
    "> - threshold를 제거하고 생각하면,   \n",
    "하나의 training case(or sample)은 원점을 지나는 hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 예를들어 아래와 같은 모델을 생각 해보자.\n",
    "> $$z = w_1 x_1 + w_2 x_2$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq 0 \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> weight이 두개($w_1, w_2$)이므로 weight space는 2차원 공간, 즉 평면이다.     \n",
    "> 또한  $z$값은 $vector~(w_1, w_2)$와 $vector~(x_1, x_2)$의 내적이라 할 수 있다.   \n",
    "\n",
    "\n",
    "> 즉 두 vector의 사잇각이 90도 보다 작다면 그 내적값은 양수가 되고, 모델 예측값 $y$는 1이 된다.   \n",
    "반면 사잇각이 90도 보다 크다면 그 내적값은 음수가 되고, 모델 예측값 $y$는 0이 된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 아래 그림과 같이 대략 $y=1$, $x_1 = 1, x_2 = 3$의 training data 하나가 있을 때,   \n",
    "$z = w_1 x_1 + w_2 x_2$ 값이 0보다 커야 1으로 예측하게 되므로,   \n",
    "'good weight vector'들은 hyperplane 윗쪽에 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 반면 아래와 같이 대략 $y=0$, $x_1 = 3, x_2 = 3$의 training data 하나가 있을 때,    \n",
    "$z = w_1 x_1 + w_2 x_2$ 값이 0보다 작아야 0으로 예측하게 되므로,   \n",
    "'good weight vector'들은 hyperplane 아래쪽에 존재한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space2.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 모든 data sample에 들어맞는 weight point를 찾아야 하므로,   \n",
    "(앞서의 경우에서는) 두 가지 경우를 모두 만족시키는 weight vector들이 찾아야 한다.    \n",
    "따라서 아래와 같이 두 hyper-plane의 사잇 공간의 점들이 적절한 weight이라 할 수 있다.    \n",
    "Perceptron과 같은 선형-이항 분류에서는 weight들이 존재하는 공간이 꼭지점(apex)이 원점인 hyper-cone 형태이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space3.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2d. Why the learning works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 Perceptron이 옳은 예측을 하게 되면, 현재의 weight vector에 input vector를 더하고,    \n",
    "그렇지 않을 경우 input vector을 뺀다고 했었다.\n",
    "\n",
    "> 이런 과정이 결국 feasible weights(적절한? 괜찮은? weights)에 도달하게 해주는 이유를 생각 해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 우선 현재의 weight이 괜찮은 녀석인지를 판단하기 위한 기준 혹은 measure가 필요한데,    \n",
    "여기에서는 feasible weight과 현재의 weight 사이의 **squared distance** ($d_{a}^2 + d_{b}^2$)를 기준으로 잡는다.    \n",
    "결국 이 squared distance가 줄어들면 점차 좋은 weight에 근접해 간다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그런데 아래 그림에서처럼 '노란색 weight'과 같이    \n",
    "경계(검은 선)와의 거리가 input vector의 길이보다 작을 경우     \n",
    "current weight에 input vector를 더해도 squared distance가 줄어들지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space4.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 그래서 모든 weight들과 current weight을 비교하는 것이 아니라      \n",
    "경계(검은 선)에서 최소한 input vector만큼은 떨어져 있는 weight들과 비교하게 되는데,    \n",
    "이 강의에서는 이들을 **generously feasible weight vector**라 한다.\n",
    "\n",
    "> 이렇게 margin을 갖게 되면 percrptron이 잘못된 예측을 하게 될 때마다, weight을 수정하게 되고     \n",
    "모든 'generously feasible weight vector'들과의 거리가 줄어들게 된다.\n",
    "\n",
    "> 결국 일정 횟수의 mistake이후에는 적절한 weight(space)를 찾게 된다. (물론 이런 space가 존재한다는 가정 하에서)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_weight_space5.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture 2e. What perceptrons can't do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이제 Perceptrons의 한계에 대해 알아본다.\n",
    "\n",
    "> 사실 모든 input case에 대해 각각의 unit을 사용하도록, feature를 coding한다면 Perceptrons으로 모든 문제를 풀 수 있다.    \n",
    "하지만 이런 방식은 실용적이지도 않고 일반적인 룰을 적용할수도 없다.  \n",
    "또한 feature가 한번 결정되고 나면, 이 Perceptron이 풀 수 있는 문제가 매우 제한된다. \n",
    "\n",
    "> 두가지 예를 통해 어떤 한계가 있는지 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex1 - XOR Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> (1, 1) -> 1; (0, 0) -> 1; (1, 0) -> 0; (0, 1) -> 0\n",
    "\n",
    "> 위와 같이 두 입력값이 1로 같을 경우 1이 output이고,    \n",
    "두 입력값이 다를 경우 0을 output으로 하는 데이터가 있다.   \n",
    "이 데이터를 Perceptrons으로 풀어보면... 모형은 아래와 같고, \n",
    "\n",
    "> $$z = w_1 x_1 + w_2 x_2$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "> 각각의 training case를 위 식에 넣어주면 \n",
    "$$1 \\cdot w_1 + 1 \\cdot w_2 \\geq \\theta$$\n",
    "$$0 \\cdot w_1 + 0 \\cdot w_2 \\geq \\theta$$\n",
    "$$1 \\cdot w_1 + 0 \\cdot w_2  <   \\theta$$\n",
    "$$0 \\cdot w_1 + 1 \\cdot w_2  <   \\theta$$\n",
    "위와 같은 부등식을 얻게 되는데,    \n",
    "이런 조건을 만족시키는 $(w_1, w_2)$는 존재하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 이를 기하학적으로 살펴볼텐데, 이번에는 data-space에서 생각해 보기로 한다.   \n",
    "\n",
    "> 앞서는 weight-space, 즉 공간에 weight-point가 존재하고,    \n",
    "input hyper-plane이 이들을 'good weights'와 'bad weights'로 나누는 형태 였고(**weight-space**)    \n",
    "\n",
    "> 이번에는 공간에 data-point가 존재하고, weight plane이    \n",
    "data-point들을 $y=1$인 경우와 $y=0$인 경우로 나누려 하는 형태이다. (**data-space**)\n",
    "\n",
    "> 아래 그림에서 weight plane은 weight vector와 수직이고 원점에서 $\\theta$만큼 떨어진 직선이다.   \n",
    "그런데 4개의 점을 $y=0$인 점들과 $y=1$인 점들로 나누는 직선은 존재하지 않는다.    \n",
    "> 즉 linearly seperable 하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_data_space1.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 물론 feature coding을 조금 바꿔서,     \n",
    "(1, 1) -> 1을 (0, 1, 0, 0) -> 1으로   \n",
    "(0, 0) -> 1을 (0, 0, 0, 0) -> 1으로    \n",
    "(1, 0) -> 0을 (0, 0, 1, 0) -> 0으로    \n",
    "(0, 1) -> 0을 (0, 0, 0, 1) -> 0으로 바꾸면,  \n",
    "\n",
    "> 모델은 아래와 같이 바뀌고\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "> 아래와 같은 weight solution을 찾을 수 있다.\n",
    "> $$w_2 \\geq \\theta$$\n",
    "$$0 \\geq \\theta$$\n",
    "$$w_3 < \\theta$$\n",
    "$$w_4 < \\theta$$\n",
    "\n",
    "\n",
    "> <u>Feature learning이 미리 잘 되어 있다면 Perceptrons로도 많은 것을 할 수 있다는 의미. -> 결국 hidden layer를 써야 한다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ex2 - Discriminating simple patterns under translation with wrap-around"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 1969년 Minsky와 Papert이 'Perceptrons'라는 책에서 'Group Invariance Theorem'으로 밝힌 내용임,\n",
    "\n",
    "> 16개 pixel로 구성된 흑/백 pattern이 존재하는데,    \n",
    "아래의 pattern A는 4개의 pixel이 표시되어 있고,     \n",
    "전체 패턴을 회전/순환 할 경우 나타날 수 있는 16가지의 패턴을 모두 pattern A로 간주한다.   \n",
    "또한 pattern A에 대한 output은 $y=1$이라 하자.\n",
    "\n",
    "> pattern B는 pattern A와 마찬가지로 4개 pixel이 표시되어 있으나    \n",
    "pattern A를 회전/순환하여 얻을 수 없으므로 pattern A와는 다른 pattern이다.      \n",
    "pattern B에 대한 output은 $y=0$이라 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img  src=\"./_images/02_simple_pattern.PNG\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 각 pixel을 feature라 생각하면 모델은 아래와 같다.\n",
    "> $$z = w_1 x_1 + w_2 x_2 + w_3 x_3 + ~...~ + w_{14} x_{14} + w_{15} x_{15} + w_{16} x_{16}$$   \n",
    "$$y = \\begin{cases} 1 & \\rm{if} ~ z \\geq \\theta \\\\ 0 & \\rm{otherwise}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "> 우선 pattern A의 모든 경우를 이용하여 모델을 풀어보면,      \n",
    "첫번째 case를 이용하여 $w_3 + w_6 + w_7 + w_{10} \\geq \\theta$을 얻을 수 있고,   \n",
    "나머지 15가지 회전/순환 case를 이용하여 총 16개의 부등식을 얻을 수 있다.   \n",
    "또한 이들 부등식 다 더하면 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) \\geq \\theta$를 얻게 된다.\n",
    "\n",
    "> 다음으로 pattern B의 모든 경우를 이용하여 모델을 풀어보면,     \n",
    "첫번째 case를 이용하여 $w_3 + w_4 + w_8 + w_9 \\geq \\theta$을 얻을 수 있고,   \n",
    "나머지 15가지 회전/순환 case를 이용하여 총 16개의 부등식을 얻을 수 있다.   \n",
    "또한 이들 부등식 다 더하면 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) < \\theta$를 얻게 된다.\n",
    "\n",
    "\n",
    "> 결국 $4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) \\geq \\theta$와    \n",
    "$4(w_1 + w_2 + ~...~ + w_{15} + w_{16}) < \\theta$ 를     \n",
    "모두 만족시키는 solution은 존재하지 않다는 것을 알 수 있다.\n",
    "\n",
    "> <u>Translation with wrap-around가 허용되는 상황에서는 Perceptrons로 패턴을 구분할 수 없다.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 위 문제를 Perceptrons로 풀기 위해,     \n",
    "예를들어 각 pattern에서 검은 pixel들의 분산?과 같의 추가 정보를 feature로 입력 해 줘야 한다.(단순히 A, B의 경우에 한함)    \n",
    "이렇게 필요한 feature를 직접 추가하는 것을    \n",
    "강의에서는 'hand-coded feature detectors'라고 표현함.   \n",
    "(문제가 해결되기는 하지만 옳바른 접근 방법은 아니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###### Solution? - Learning with hidden units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 앞서 hand-coded feature detectors를 이용하면 문제를 풀수 있다고 했는데,   \n",
    "이런 부분들 까지 모델에 포함하여 문제를 해결하는 것이 좋을 것이다.   \n",
    "\n",
    "> 즉 'adaptive, non-linear hidden unit'추가하여       \n",
    "모델에서 feature detecting을 할 수 있도록 하는 것(to make learn feature detector)이 좋을 것이다.\n",
    "다만 이런 모델을 어떻게 train할 것인지가 문제이고,\n",
    "\n",
    "> 이어지는 강의에서 이런 내용들을 배우게 될 것이다."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
